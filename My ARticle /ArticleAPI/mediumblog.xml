<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title>
            <![CDATA[Stories by RAVI SHEKHAR TIWARI on Medium]]>
        </title>
        <description>
            <![CDATA[Stories by RAVI SHEKHAR TIWARI on Medium]]>
        </description>
        <link>https://medium.com/@tiwari11-rst?source=rss-439a66e298ba------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*sSheeOdnpgK2kNfM94oPzQ.jpeg</url>
            <title>Stories by RAVI SHEKHAR TIWARI on Medium</title>
            <link>https://medium.com/@tiwari11-rst?source=rss-439a66e298ba------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Mon, 15 Aug 2022 03:48:26 GMT</lastBuildDate>
        <atom:link href="https://medium.com/@tiwari11-rst/feed" rel="self" type="application/rss+xml"/>
        <webMaster>
            <![CDATA[yourfriends@medium.com]]>
        </webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title>
                <![CDATA[Transfer Learning -Part -7.0 !! Dense net]]>
            </title>
            <link>https://becominghuman.ai/transfer-learning-part-7-0-dense-net-bd23d9f6d4fd?source=rss-439a66e298ba------2</link>
            <guid isPermaLink="false">https://medium.com/p/bd23d9f6d4fd</guid>
            <category>
                <![CDATA[tensorflow2]]>
            </category>
            <category>
                <![CDATA[transfer-learning]]>
            </category>
            <category>
                <![CDATA[densenet]]>
            </category>
            <category>
                <![CDATA[pytorch]]>
            </category>
            <category>
                <![CDATA[artificial-intelligence]]>
            </category>
            <dc:creator>
                <![CDATA[RAVI SHEKHAR TIWARI]]>
            </dc:creator>
            <pubDate>Fri, 22 Jul 2022 18:55:00 GMT</pubDate>
            <atom:updated>2022-07-22T18:55:00.398Z</atom:updated>
            <content:encoded>
                <![CDATA[<h3>Transfer Learning -Part -7.0 !! Dense net</h3><p>In Part 6 Series of the Transfer Learning series we have discussed the Mobile Nets in depth along with hands-on application of these pre-trained neural nets in Keras and PyTorch API’s. The datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch which is discussed in Part 6 of this series. In this, article we will discuss theoretically about the Densenet and in article 7.1 and 7.2 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>For the repository and document please follow below two mentioned links:</p><p><strong>Keras:</strong></p><p><a href="https://keras.io/guides/transfer_learning/">Keras documentation: Transfer learning &amp; fine-tuning</a></p><p><strong>PyTorch:</strong></p><p><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial - PyTorch Tutorials 1.12.0+cu102 documentation</a></p><h3>1. Introduction</h3><p>DenseNet is one of the new discoveries in neural networks for visual object recognition. DenseNet is quite similar to ResNet with some fundamental differences. ResNet uses an additive method (+) that merges the previous layer (identity) with the future layer, whereas DenseNet concatenates (.) the output of the previous layer with the future layer. DenseNet (Dense Convolutional Network) is reviewed. This is the paper in 2017 CVPR which got<strong> </strong>Best Paper Award<strong> </strong>with over 2000 citations. It is jointly invented by Cornwell University, Tsinghua University and Facebook AI Research (FAIR).</p><h3>2. Need For DenseNets?</h3><p>DenseNet was specially developed to improve accuracy caused by the vanishing gradient in high-level neural networks due to the long distance between input and output layers &amp; the information vanishes before reaching its destination.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/973/1*_Dqv1GTRFjyXnGTYrV2_cQ.png" /><figcaption><strong>Fig .1. </strong>DenseNet Architecture VS ResNet Architecture.</figcaption></figure><p>This image shows a 5-layer dense block with a <em>growth rate</em> of k = 4 and the standard ResNet structure, we have a capital L number of layers, In a typical network with L layers, there will be L connections, that is, connections between the layers. However, in a DenseNet, there will be about L<br>and L plus one by two connections L(L+1)/2. hENCE dense net, we have less number of layers than the other model, so here we can train more than 100 layers of the model very easily by using this technique.</p><h3>3. DenseNet Architecture</h3><p>In this section we will discuss the various architecture of Densenet.</p><h4>3.1 Building Block of Densenet</h4><p>As we all know ConvNet, input image goes through multiple convolution layer to extract high-level features whereas in <a href="https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">ResNet</a>, identity mapping is proposed to increase the gradient propagation i.e<strong> </strong>Element-wise addition<strong> </strong>is employed.</p><p>In DenseNet, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers.<strong> </strong>Concatenation<strong> </strong>is used and each layer is receiving a “collective knowledge” from all preceding layers.<strong> </strong>Since each layer receives feature maps from all preceding layers, network can be thinner and compact, i.e. number of channels can be fewer. The growth rate<em>k</em> is the additional number of channels for each layer.</p><p>So, it have higher computational efficiency and memory efficiency. The following figure shows the concept of concatenation during forward propagation:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/600/1*7bq-dmm1Q8z3eIiqlVLZaQ.gif" /><figcaption><strong>Fig. 2.</strong> Concatenation during Forward Propagation</figcaption></figure><p>As shown in Fig.2. n output of the previous layer acts as an input of the second layer by using <em>composite function operation.</em> This composite operation consists of the convolution layer, pooling layer, batch normalization, and non-linear activation layer. These connections mean that the network has L(L+1)/2 direct connections. L is the number of layers in the architecture.</p><p>Be it adding or concatenating, the grouping of layers by the above equation is only possible if feature map dimensions are the same. What if dimensions are different? The DenseNet is divided into DenseBlocks where a number of filters are different, but dimensions within the block are the same. Transition Layer applies batch normalization using downsampling; it’s an essential step in CNN.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/1*iromWVD4WOfC3lGUNiAyGQ.png" /><figcaption><strong>Fig. 3.</strong><em>Densely Connected Convolutional Networks</em></figcaption></figure><p>The number of filters changes between the DenseBlocks, increasing the dimensions of the channel. The growth rate (k) helps in generalizing the l-th layer. It controls the amount of information to be added to each layer as shown in below equation.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/222/0*BKlQ3MdP3M22g0Ya.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*mmVYGozgrK8SRoTxgSa4TA.png" /><figcaption><strong>Fig.4.</strong> Full Architechture<em>Densely Connected Convolutional Networks</em></figcaption></figure><p>The DenseNet has different versions, like DenseNet-121, DenseNet-160, DenseNet-201, etc. The numbers denote the number of layers in the neural network. The number 121 is computed as follows:</p><blockquote><strong>No- of layers</strong> = 5+(6+12+24+16)</blockquote><blockquote><strong>5</strong>- Convolution and Pooling</blockquote><blockquote><strong>3</strong>- Transition Layer ( 6+12+24)</blockquote><blockquote><strong>1</strong>- Classification Layer (16)</blockquote><blockquote><strong>2</strong>- DenseBlock (1*1 and 3*3 conv)</blockquote><h4>3.2. Basic DenseNet Composition Layer</h4><p>For each composition layer, Pre-Activation <a href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651">Batch Norm (BN)</a> and ReLU, then 3×3 Conv are done with output feature maps of<em>k</em> channels, say for example, to transform<em>x</em>0,<em>x</em>1,<em>x</em>2,<em>x</em>3 to<em>x</em>4.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/600/1*1yy9ezN1b7eNxrOJXAB1Mw.gif" /><figcaption><strong>Fig. 5.</strong> DenseNet Composition Layer</figcaption></figure><h4>3.3. DenseNet-B</h4><p>Here “B” represents the BottleNeck layers To reduce the model complexity and size, BN-ReLU-1×1 Conv is done before<strong> BN-ReLU-3×3 Conv.</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HceJlvtQRMZegpV_7F_pLw.png" /><figcaption><strong>Fig. 6. </strong>DenseNet-B</figcaption></figure><h4>3.4. Multiple Dense Blocks with Transition Layers</h4><p>Here, 1×1 Conv followed by 2×2 average pooling are used as the transition layers between two contiguous dense blocks. Feature map sizes are the same within the dense block so that they can be concatenated together easily. At the end of the last dense block, a global average pooling is performed and then a softmax classifier is attached.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*RhxaNgBi3NgrCAlSIIhVmQ.png" /><figcaption><strong>Fig. 7. </strong>Multiple Dense Blocks</figcaption></figure><h4>3.5. DenseNet-BC (Further Compression)</h4><p><strong>If a dense block contains <em>m</em> feature-maps, The transition layer generate<em>θm</em> output feature maps,</strong>where <em>0&lt;θ≤1</em> is referred to as the compression factor.When<em> θ=1</em>, the number of feature-maps across transition layers remains unchanged. DenseNet with <em>θ&lt;1</em> is referred as<strong> </strong>DenseNet-C,<strong> </strong>and<em>θ=0.5</em> in the experiment.</p><p>When both the bottleneck and transition layers with  <em>θ</em>&lt;1 are used, the model is referred as<strong> </strong>DenseNet-BC<strong>. </strong>Finally, DenseNets with/without B/C<strong> </strong>and with different<em>L</em> layers and<em>k</em> growth rate are trained.</p><h3><strong>4. Advantages of theDensenet.</strong></h3><ul><li><strong>Parameter efficiency</strong> — Every layer adds only a limited number of parameters- for e.g. only about 12 kernels are learned per layer</li><li><strong>Implicit deep supervision </strong>— Improved flow of gradient through the network- Feature maps in all layers have direct access to the loss function and its gradient.</li><li><strong>More Diversified Features — </strong>Since each layer in DenseNet receive all preceding layers as input, more diversified features and tends to have richer patterns.</li><li>Maintains Low Complexity Features — In Standard ConvNet, classifier uses most complex features. In DenseNet, classifier uses features of all complexity levels. It tends to give more smooth decision boundaries. It also explains why DenseNet performs well when training data is insufficient.</li></ul><h3><strong>5. DenseNet Terminology</strong></h3><p><strong>Growth rate</strong> — This determines the number of feature maps output into individual layers inside dense blocks.</p><p><strong>Dense connectivity</strong> — By dense connectivity, we mean that within a dense block each layer gets us input feature maps from the previous layer as seen in this figure.</p><p><strong>Composite functions</strong> — So the sequence of operations inside a layer goes as follows. So we have batch normalization, followed by an application of Relu, and then a convolution layer (that will be one convolution layer)</p><p><strong>Transition layers </strong>— The transition layers aggregate the feature maps from a dense block and reduce its dimensions. So Max Pooling is enabled here.</p><p>In this article we have discussed about the Densenet architecture theoretically in next article i.e. 7.1 and 7.2 we will have hands on experience with Keras and PyTorch API’s.</p><h3>Stay Tuned !!! Happy Learning :)</h3><h4>Special Thanks:</h4><blockquote><em>As we say “Car is useless if it doesn’t have a good engine” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja</em></strong><em>” and “</em><strong><em>A. Helen Victoria</em></strong><em>”- guided me throughout the journey, from the bottom of my heart. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><blockquote><em>Pytorch: </em><a href="https://pytorch.org/get-started/locally/#windows-python"><em>Link</em></a></blockquote><blockquote><em>Keras: </em><a href="https://keras.io/"><em>Link</em></a></blockquote><blockquote><em>ResNet:</em><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiz__vNp93zAhUBxzgGHTtVBvcQFnoECAQQAQ&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1512.03385&amp;usg=AOvVaw0ko2RV0WsEDskyH0kl1EHN"><em> Link</em></a></blockquote><blockquote><em>Tensorflow: </em><a href="https://www.tensorflow.org/guide/keras/sequential_model"><em>Link</em></a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote><em>YouTube : </em><a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ"><em>Lin</em></a><em>k</em></blockquote><blockquote><em>Website: </em><a href="http://www.rstiwari.com/"><em>www.rstiwari.com</em></a></blockquote><blockquote><em>Medium: </em><a href="https://tiwari11-rst.medium.com/"><em>https://tiwari11-rst.medium.com</em></a></blockquote><blockquote><em>Github Pages: </em><a href="https://happyman11.github.io/"><em>https://happyman11.github.io/</em></a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Contact Me: <a href="https://contactmerstiwari.herokuapp.com/contact/">https://contactmerstiwari.herokuapp.com/contact/</a></blockquote><blockquote><em>Google Form: </em><a href="https://forms.gle/mhDYQKQJKtAKP78V7"><em>https://forms.gle/mhDYQKQJKtAKP78V7</em></a></blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=bd23d9f6d4fd" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-7-0-dense-net-bd23d9f6d4fd">Transfer Learning -Part -7.0 !! Dense net</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Python in the Web Browser: PyScript]]>
    </title>
    <link>https://medium.datadriveninvestor.com/python-in-the-web-browser-pyscript-551ef13c76c1?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/551ef13c76c1</guid>
    <category>
        <![CDATA[pyscript]]>
    </category>
    <category>
        <![CDATA[web-development]]>
    </category>
    <category>
        <![CDATA[python-web-developer]]>
    </category>
    <category>
        <![CDATA[html5]]>
    </category>
    <category>
        <![CDATA[python3]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Sat, 09 Jul 2022 20:21:06 GMT</pubDate>
    <atom:updated>2022-07-21T10:44:50.394Z</atom:updated>
    <content:encoded>
        <![CDATA[<p>PyScript is a brand-new framework that caused a lot of excitement when <a href="https://twitter.com/pwang">eter Wang</a>, the CEO and co-founder of<a href="https://www.anaconda.com/">Anaconda, Inc.</a>, revealed it during his<a href="https://anaconda.cloud/pyscript-pycon2022-peter-wang-keynote">keynote speech</a> at<a href="https://realpython.com/real-python-pycon-us-2022/">PyCon US 2022</a>. Although this project is just an experiment in an early phase of development, people on<a href="https://twitter.com/pyscript_dev">social media</a> seem to have already fallen in love with it. This tutorial will get you up to speed with PyScript, while the official documentation is still in the making.</p><p>PyScript is a Python front-end framework that enables users to construct Python programs using an HTML interface in the browser.It was developed using the power of <a href="https://emscripten.org/">Emscripten</a>,<a href="https://pyodide.org/en/stable/">Pyodide</a>,<a href="https://webassembly.org/">WASM</a>, and other modern web technologies to provide the following abilities in line with its goals:</p><ul><li>To provide a simplistic and clean API.</li><li>To provide a system of pluggable and extensible components.</li><li>To support and extend standard HTML to read opinionated and dependable custom components in order to reach the mission “Programming for the 99%.”</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*QrKYiBgfBud2dzxRjERwEQ.png" /><figcaption>Source: <a href="https://www.anaconda.com/blog/pyscript-python-in-the-browser">Anaconda Blog</a></figcaption></figure><p>In the last couple of decades, Python and advanced UI languages like modern HTML, CSS, and JavaScript have not worked in collaboration. Python lacked a simple mechanism to create appealing UIs for simply packaging and deploying apps, while current HTML, CSS, and JavaScript can have a steep learning curve.Allowing Python to utilize HTML, CSS, and JavaScript conventions solves not only those two problems but also those related to web application development, packaging, distribution, and deployment.</p><p>PyScript isn’t meant to take the role of JavaScript in the browser, though — rather, it’s meant to give Python developers, particularly data scientists, more flexibility and power.</p><h3>Why PyScript?</h3><p>PyScript gives you a programming language with consistent styling conventions, more expressiveness, and ease of learning by providing the following:</p><ul><li><strong>Support on the browser: </strong>PyScript enables support for Python and hosting without the need for servers or configuration.</li><li><strong>Interoperability: </strong>Programs can communicate bi-directionally between Python and JavaScript objects and namespaces.</li><li><strong>Ecosystem support: </strong>PyScript allows the use of popular Python packages such as Pandas, NumPy, and many more.</li><li><strong>Framework flexibility: </strong>PyScript is a flexible framework that developers can build on to create extensible components directly in Python easily.</li><li><strong>Environment Management: </strong>PyScript allows developers to define the files and packages to include in their page code to run.</li><li><strong>UI Development: </strong>With PyScript, developers can easily build with available UI components such as buttons and containers, and many more.</li></ul><p><a href="https://pyscript.net/">Pyscript.net</a></p><h3>How to Get Started with PyScript??</h3><h3><strong>1. Html with PyScript</strong></h3><p><strong><em>Step 1: </em></strong>Make .html file as shown below</p><pre>&lt;!DOCTYPE html&gt;</pre><pre>  &lt;html lang=&quot;en&quot;&gt;</pre><pre>     &lt;head&gt;<br>         &lt;meta charset=&quot;UTF-8&quot;&gt;<br>         &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user      <br>                      scalable=no, initial-scale=1.0, maximum-<br>                      scale=1.0, minimum-scale=1.0&quot;&gt;<br><br>         &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;<br>   </pre><pre>      &lt;title&gt;Title: PyScript with HTML &lt;/title&gt;</pre><pre>     &lt;/head&gt;</pre><pre>     &lt;body&gt;</pre><pre>         &lt;h1&gt; Pyscript in Html&lt;/h1&gt;</pre><pre>    &lt;/body&gt;</pre><pre>&lt;/html&gt;</pre><p><strong><em>Step 2: </em></strong>Link PyScript CDN</p><p>After creating the HTML file, we’ll need to link PyScript in your HTML file to have access to the PyScript interface. This will be placed in the &lt;head&gt; tag.</p><pre>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://pyscript.net/alpha/pyscript.css&quot; /&gt;</pre><pre>&lt;script defer src=&quot;https://pyscript.net/alpha/pyscript.js&quot;&gt;&lt;/script&gt;</pre><p>The full code for the HTML file is below:</p><pre>&lt;!DOCTYPE html&gt;</pre><pre>&lt;html lang=&quot;en&quot;&gt;</pre><pre>&lt;head&gt;<br>         &lt;meta charset=&quot;UTF-8&quot;&gt;<br>         &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user      <br>                      scalable=no, initial-scale=1.0, maximum-<br>                      scale=1.0, minimum-scale=1.0&quot;&gt;<br><br>         &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;</pre><pre>&lt;title&gt;Title: PyScript with HTML &lt;/title&gt;</pre><pre>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://pyscript.net/alpha/pyscript.css&quot; /&gt;</pre><pre>&lt;script defer src=&quot;https://pyscript.net/alpha/pyscript.js&quot;&gt;&lt;/script&gt;</pre><pre>&lt;/head&gt;</pre><pre>&lt;body&gt;</pre><pre>&lt;h1&gt; Pyscript in Html&lt;/h1&gt;</pre><pre>&lt;p&gt;&lt;py-script&gt; print(&quot;PyScript in Browser!!!!!&quot;) &lt;/py-script&gt;&lt;/p&gt;</pre><pre>&lt;/body&gt;<br>&lt;/html&gt;</pre><p>Finally, open the file in your browser!!!!! and you will see the magic.</p><h4>2. <strong>Calling Custom Python functions in Html.</strong></h4><p>One of the functions PyScript provides is flexibility. In PyScript you can import local files, inbuilt modules, or third-party libraries. This process uses the &lt;py-env&gt; tag. This tag is for declaring the dependencies needed.</p><p>For local Python files on your system, you can place the code in a .py file and the paths to local modules are provided in the paths: key in the &lt;py-env&gt; tag.</p><p>Let’s create a Python file examplefunction.py to contain some functions:</p><pre>from random import randint<br><br>def add_two_numbers(x, y):<br>    return x + y<br><br>def generate_random_number():<br>    x = randint(0, 10)<br>    return x</pre><p>Then the Python file will be imported into the HTML with the &lt;py-env&gt; tag. You should place this tag in the the &lt;head&gt; tag, above the &lt;body&gt; tag.</p><pre>&lt;html lang=&quot;en&quot;&gt;</pre><pre>&lt;head&gt;<br>         &lt;meta charset=&quot;UTF-8&quot;&gt;<br>         &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user      <br>                      scalable=no, initial-scale=1.0, maximum-<br>                      scale=1.0, minimum-scale=1.0&quot;&gt;<br><br>         &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;</pre><pre>&lt;title&gt;Title: Using custom code &lt;/title&gt;</pre><pre>&lt;link rel=&quot;stylesheet&quot;<br>href=&quot;https://pyscript.net/alpha/pyscript.css&quot; /&gt;<br><br>&lt;script defer src=&quot;https://pyscript.net/alpha/pyscript.js&quot;&gt;&lt;/script&gt;<br>     </pre><pre>&lt;py-env&gt;<br>        - paths:<br>          - /examplefunction.py<br>      &lt;/py-env&gt;</pre><pre>&lt;/head&gt;</pre><pre>&lt;body&gt;<br>   </pre><pre>      from examplefunction import generate_random_number</pre><pre>       pyscript.write(&#39;lucky&#39;, generate_random_number())</pre><pre>    &lt;/py-script&gt;</pre><pre>   &lt;p&gt; Addition of two number 5 and 6 is :</pre><pre>  &lt;py-script&gt;print(add_two_numbers(5,6)) &lt;/py-script&gt; &lt;/p&gt;</pre><pre>  &lt;/body&gt;</pre><pre>&lt;/html&gt;</pre><p>Finally, open the file in your browser!!!!! and you will see the magic.</p><h4>3. Importing Python Modules in Html.</h4><p>One of the functions PyScript provides is flexibility. In PyScript you can import python library, inbuilt modules, or third-party libraries. This process uses the &lt;py-env&gt; tag. This tag is for declaring the dependencies needed.</p><p>For library of Python you can place the code in a key in the &lt;py-env&gt; tag. Then the Python file will be imported into the HTML with the &lt;py-env&gt; tag. You should place this tag in the the &lt;head&gt; tag, above the &lt;body&gt; tag.</p><pre>&lt;html lang=&quot;en&quot;&gt;</pre><pre>&lt;head&gt;<br>         &lt;meta charset=&quot;UTF-8&quot;&gt;<br>         &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user      <br>                      scalable=no, initial-scale=1.0, maximum-<br>                      scale=1.0, minimum-scale=1.0&quot;&gt;<br><br>         &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;</pre><pre>&lt;title&gt;Title: Using custom code &lt;/title&gt;</pre><pre>&lt;link rel=&quot;stylesheet&quot;<br>href=&quot;https://pyscript.net/alpha/pyscript.css&quot; /&gt;<br><br>&lt;script defer src=&quot;https://pyscript.net/alpha/pyscript.js&quot;&gt;&lt;/script&gt;</pre><pre>&lt;py-env&gt;<br>            - numpy<br>            - requests<br>            - humanize</pre><pre>&lt;/py-env&gt;</pre><pre>&lt;/head&gt;</pre><pre>&lt;body&gt;</pre><pre>&lt;py-script&gt;<br>	import numpy as np<br>	import requests<br>        from datetime import datetime<br>        import humanize</pre><pre><br><br><br>        now_int = int(datetime.timestamp(datetime.now()))<br>        now_fmt = humanize.intcomma(now_int)<br>        print(&quot;It has been&quot;, now_fmt, &quot;seconds since the epoch.&quot;)<br></pre><pre>&lt;/py-script&gt;</pre><pre>&lt;/body&gt;</pre><pre>&lt;/html&gt;</pre><p>Finally, open the file in your browser!!!!! and you will see the magic. timedate of the system in browser from PyScript.</p><h4>4. The REPL tag.</h4><p>Python users ought to be familiar with <a href="https://www.infoworld.com/article/3347406/what-is-jupyter-notebook-data-analysis-made-easier.html">Jupyter Notebook</a>, the in-browser live coding environment for Python typically used for mathematics and statistics. PyScript offers a primitive building block for such an environment, the py-repl tag.</p><p>py-repl generates an input field on a web page that functions like a very basic version of a Jupyter Notebook environment. Here&#39;s an example from Anaconda&#39;s own demos:</p><pre>&lt;html lang=&quot;en&quot;&gt;</pre><pre>&lt;head&gt;<br>         &lt;meta charset=&quot;UTF-8&quot;&gt;<br>         &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user      <br>                      scalable=no, initial-scale=1.0, maximum-<br>                      scale=1.0, minimum-scale=1.0&quot;&gt;<br><br>         &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;</pre><pre>&lt;title&gt;Title: Using custom code &lt;/title&gt;</pre><pre>&lt;link rel=&quot;stylesheet&quot;<br>href=&quot;https://pyscript.net/alpha/pyscript.css&quot; /&gt;<br><br>&lt;script defer src=&quot;https://pyscript.net/alpha/pyscript.js&quot;&gt;&lt;/script&gt;</pre><pre>&lt;/head&gt;</pre><pre>&lt;body&gt;</pre><pre><strong>&lt;</strong>py-repl id=&quot;my-repl&quot; auto-generate=&quot;true&quot;<strong>&gt;</strong><strong>&lt;/</strong>py-repl<strong>&gt;</strong></pre><pre>&lt;/body&gt;</pre><pre>&lt;/html&gt;</pre><p>Run this code and you’ll be presented with an input field, which works like the Python REPL.</p><p>Currently, the REPL tag has very little in the way of documented customization. For instance, if you want to programmatically access the contents of a cell or its results, there’s no clear documentation for how to do that.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6TJq9wfZ18rtDy4F-P76Mg.jpeg" /><figcaption>Sample REPL</figcaption></figure><h3>Conclusion</h3><p>In this article, you learned what PyScript is all about and how to use it in HTML files to run Python code on the browser. You also learned about the various operations/functionalities you can do with PyScript.</p><p>With PyScript, it’s easier to run and perform Python operations on the web, as this wasn’t easy before. This is a great tool for anyone who’s looking forward to using Python on the web.</p><p>PyScript is still in its early stages and under heavy development. It is still in its alpha stage and faces known issues like the load time which can affect usability (some other operations can’t be shown at the time of this writing due to performance issues). So you shouldn’t use it in production yet as there will likely be a lot of breaking changes.</p><h3>Special Thanks:</h3><blockquote><em>As we say “Car is useless if it doesn’t have a good engine” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote><a href="https://pyscript.net/">The PyScript official website</a>.</blockquote><blockquote><a href="https://www.anaconda.com/blog/pyscript-python-in-the-browser">Anaconda blog</a>.</blockquote><blockquote><a href="https://github.com/pyscript/pyscript">PyScript source code</a>.</blockquote><blockquote><a href="https://github.com/pyscript/pyscript/blob/main/docs/tutorials/getting-started.md">Guide on getting started with PyScript</a>.</blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote><em>YouTube : </em><a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ"><em>Lin</em></a><em>k</em></blockquote><blockquote><em>Website: </em><a href="http://www.rstiwari.com/"><em>www.rstiwari.com</em></a></blockquote><blockquote><em>Medium: </em><a href="https://tiwari11-rst.medium.com/"><em>https://tiwari11-rst.medium.com</em></a></blockquote><blockquote><em>Github Pages: </em><a href="https://happyman11.github.io/"><em>https://happyman11.github.io/</em></a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote><em>Google Form: </em><a href="https://forms.gle/mhDYQKQJKtAKP78V7"><em>https://forms.gle/mhDYQKQJKtAKP78V7</em></a></blockquote><p>Subscribe to DDIntel <a href="https://ddintel.datadriveninvestor.com/">Here</a>.</p><p>Join our network here: <a href="https://datadriveninvestor.com/collaborate">https://datadriveninvestor.com/collaborate</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=551ef13c76c1" width="1" height="1" alt=""><hr><p><a href="https://medium.datadriveninvestor.com/python-in-the-web-browser-pyscript-551ef13c76c1">Python in the Web Browser: PyScript</a> was originally published in<a href="https://medium.datadriveninvestor.com">DataDrivenInvestor</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 6.2!! Implementing Mobilenet in PyTorch]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-6-2-implementing-mobilenet-in-pytorch-2d3f3851a15b?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/2d3f3851a15b</guid>
    <category>
        <![CDATA[pretrained-model]]>
    </category>
    <category>
        <![CDATA[pytorch]]>
    </category>
    <category>
        <![CDATA[artificial-intelligence]]>
    </category>
    <category>
        <![CDATA[mobilenetv2]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Sun, 05 Jun 2022 08:36:46 GMT</pubDate>
    <atom:updated>2022-06-05T08:36:46.537Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 6.2!! Implementing Mobilenet in PyTorch</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*7MSNFouzb3NXxAVG.jpg" /><figcaption><strong>Figure.1 </strong>Transfer Learning</figcaption></figure><p>In Part 6.0 of the Transfer Learning series we have discussed about Mobilenet pre-trained model in depth so in this series we will implement the above mentioned pre-trained model in PyTorch. This part is going to be little long because we are going to implement Mobilenet in PyTorch with Python. We will be implementing the per-trained Mobilenet model in 4 ways which we will discuss further in this article. For setting- up the Colab notebook it will be advisable to go through the below mentioned article of Transfer Learning Series.</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>It is also advisable to go through the article of ResNet before reading this article which is mentioned below:</p><p><a href="https://tiwari11-rst.medium.com/transfer-learning-part-6-0-mobile-net-a7e7467a27f">Transfer Learning — Part — 6.0!! Mobile net</a></p><p><strong>1.Implementing Mobilenet Pre-trained model</strong></p><p>In this section we will see how we can implement Mobilenet model in PyTorch to have a foundation to start our real implementation .</p><p><strong>1.1. Image to predict</strong></p><p>We will use the image of the coffee mug to predict the labels with the Mobilenet architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import torch                                          <strong>#Line 1<br></strong>import torchvision.models as models                   <strong>#Line 2<br></strong>from PIL import Image                                 <strong>#Line 3<br></strong>import torchvision.transforms.functional as TF        <strong>#Line 4<br></strong>from torchsummary import summary                      <strong>#Line 5<br></strong>!pip install torchviz                                 <strong>#Line 6<br></strong>from torchviz import make_dot                         <strong>#Line 7<br></strong>import numpy as np</pre><p><strong>Line 1:</strong> The above snippet is used to import the PyTorch library which we use use to implement Mobilenet work.</p><p><strong>Line 2:</strong> The above snippet is used to import the PyTorch pre-trained models.</p><p><strong>Line 3:</strong> The above snippet is used to import the PIL library for visualization purpose.</p><p><strong>Line 4:</strong> The above snippet is used to import the PyTorch Transformation library which we use use to transform the dataset for training and testing.</p><p><strong>Line 5:</strong> The above snippet is used to import library which shows the summary of models.</p><p><strong>Line 6:</strong> The above snippet is used to install torchviz to visualise the network.</p><p><strong>Line 7:</strong> The above snippet is used to import torchviz to visualize the network.</p><pre>image = Image.open(link_of_image)   <strong>#Line 8<br></strong>image=image.resize((224,224))       <strong>#Line 9<br></strong>x = TF.to_tensor(image)             <strong>#Line 10<br></strong>x.unsqueeze_(0)                     <strong>#Line 11<br></strong>x=x.to(device)                      <strong>#Line 12<br></strong>print(x.shape)                      <strong>#Line 13</strong></pre><p><strong>Line 8: </strong>This snippet loads the images from the path.</p><p><strong>Line 9: </strong>This snippet converts the image in the size (224,224) required by the model.</p><p><strong>Line 10:</strong> This snippet convert the image into array</p><p><strong>Line 11: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 12:</strong> This snippet is used to move the image to the device on which model is registered.</p><p><strong>Line 13: </strong>This snippet use to display the image shape as shown below:</p><pre>torch.Size([1, 3, 224, 224])</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/0*NOtuiLAPXwqGRvZz.jpeg" /><figcaption>Figure. 1 Image to be predicted</figcaption></figure><p><strong>1.2. Mobilenet Implementation</strong></p><p>Here we will use Mobilenet network to predict on the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0<br></strong>mobilenet_pretrained = models.mobilenet_v2(pretrained=True).to(device)   <br><strong>#LINE 1<br></strong>summary(resnet_pretrained, (3, 224, 224))                    <strong>#LINE 2<br></strong>resnet_pretrained                                            <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the Mobilenet model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>----------------------------------------------------------------         Layer (type)               Output Shape         Param # ================================================================             Conv2d-1              [-1, 32, 112, 112]             864        BatchNorm2d-2         [-1, 32, 112, 112]              64              ReLU6-3               [-1, 32, 112, 112]               0             Conv2d-4              [-1, 32, 112, 112]             288        BatchNorm2d-5         [-1, 32, 112, 112]              64              ReLU6-6               [-1, 32, 112, 112]               0             Conv2d-7              [-1, 16, 112, 112]             512        BatchNorm2d-8         [-1, 16, 112, 112]              32   InvertedResidual-9    [-1, 16, 112, 112]               0            Conv2d-10             [-1, 96, 112, 112]           1,536       BatchNorm2d-11        [-1, 96, 112, 112]             192             ReLU6-12              [-1, 96, 112, 112]               0            Conv2d-13               [-1, 96, 56, 56]             864       BatchNorm2d-14          [-1, 96, 56, 56]             192             ReLU6-15                [-1, 96, 56, 56]               0            Conv2d-16               [-1, 24, 56, 56]           2,304       BatchNorm2d-17          [-1, 24, 56, 56]              48  InvertedResidual-18     [-1, 24, 56, 56]               0            Conv2d-19              [-1, 144, 56, 56]           3,456       BatchNorm2d-20         [-1, 144, 56, 56]             288             ReLU6-21               [-1, 144, 56, 56]               0            Conv2d-22              [-1, 144, 56, 56]           1,296       BatchNorm2d-23         [-1, 144, 56, 56]             288             ReLU6-24               [-1, 144, 56, 56]               0            Conv2d-25               [-1, 24, 56, 56]           3,456       BatchNorm2d-26          [-1, 24, 56, 56]              48  InvertedResidual-27     [-1, 24, 56, 56]               0            Conv2d-28              [-1, 144, 56, 56]           3,456       BatchNorm2d-29         [-1, 144, 56, 56]             288             ReLU6-30               [-1, 144, 56, 56]               0            Conv2d-31              [-1, 144, 28, 28]           1,296       BatchNorm2d-32         [-1, 144, 28, 28]             288             ReLU6-33               [-1, 144, 28, 28]               0            Conv2d-34               [-1, 32, 28, 28]           4,608       BatchNorm2d-35          [-1, 32, 28, 28]              64  InvertedResidual-36     [-1, 32, 28, 28]               0            Conv2d-37              [-1, 192, 28, 28]           6,144       BatchNorm2d-38         [-1, 192, 28, 28]             384             ReLU6-39               [-1, 192, 28, 28]               0            Conv2d-40              [-1, 192, 28, 28]           1,728       BatchNorm2d-41         [-1, 192, 28, 28]             384             ReLU6-42               [-1, 192, 28, 28]               0            Conv2d-43               [-1, 32, 28, 28]           6,144       BatchNorm2d-44          [-1, 32, 28, 28]              64  InvertedResidual-45     [-1, 32, 28, 28]               0            Conv2d-46              [-1, 192, 28, 28]           6,144       BatchNorm2d-47         [-1, 192, 28, 28]             384             ReLU6-48               [-1, 192, 28, 28]               0            Conv2d-49              [-1, 192, 28, 28]           1,728       BatchNorm2d-50         [-1, 192, 28, 28]             384             ReLU6-51               [-1, 192, 28, 28]               0            Conv2d-52               [-1, 32, 28, 28]           6,144       BatchNorm2d-53          [-1, 32, 28, 28]              64  InvertedResidual-54     [-1, 32, 28, 28]               0            Conv2d-55              [-1, 192, 28, 28]           6,144       BatchNorm2d-56         [-1, 192, 28, 28]             384             ReLU6-57               [-1, 192, 28, 28]               0            Conv2d-58              [-1, 192, 14, 14]           1,728       BatchNorm2d-59         [-1, 192, 14, 14]             384             ReLU6-60               [-1, 192, 14, 14]               0            Conv2d-61               [-1, 64, 14, 14]          12,288       BatchNorm2d-62          [-1, 64, 14, 14]             128  InvertedResidual-63     [-1, 64, 14, 14]               0            Conv2d-64              [-1, 384, 14, 14]          24,576       BatchNorm2d-65         [-1, 384, 14, 14]             768             ReLU6-66               [-1, 384, 14, 14]               0            Conv2d-67              [-1, 384, 14, 14]           3,456       BatchNorm2d-68         [-1, 384, 14, 14]             768             ReLU6-69               [-1, 384, 14, 14]               0            Conv2d-70               [-1, 64, 14, 14]          24,576       BatchNorm2d-71          [-1, 64, 14, 14]             128  InvertedResidual-72     [-1, 64, 14, 14]               0            Conv2d-73              [-1, 384, 14, 14]          24,576       BatchNorm2d-74         [-1, 384, 14, 14]             768             ReLU6-75               [-1, 384, 14, 14]               0            Conv2d-76              [-1, 384, 14, 14]           3,456       BatchNorm2d-77         [-1, 384, 14, 14]             768             ReLU6-78               [-1, 384, 14, 14]               0            Conv2d-79               [-1, 64, 14, 14]          24,576       BatchNorm2d-80          [-1, 64, 14, 14]             128  InvertedResidual-81     [-1, 64, 14, 14]               0            Conv2d-82              [-1, 384, 14, 14]          24,576       BatchNorm2d-83         [-1, 384, 14, 14]             768             ReLU6-84               [-1, 384, 14, 14]               0            Conv2d-85              [-1, 384, 14, 14]             768             ReLU6-87               [-1, 384, 14, 14]               0            Conv2d-88               [-1, 64, 14, 14]          24,576       BatchNorm2d-89          [-1, 64, 14, 14]             128  InvertedResidual-90     [-1, 64, 14, 14]               0            Conv2d-91              [-1, 384, 14, 14]          24,576       BatchNorm2d-92         [-1, 384, 14, 14]             768             ReLU6-93               [-1, 384, 14, 14]               0            Conv2d-94              [-1, 384, 14, 14]           3,456       BatchNorm2d-95         [-1, 384, 14, 14]             768             ReLU6-96               [-1, 384, 14, 14]               0            Conv2d-97               [-1, 96, 14, 14]          36,864       BatchNorm2d-98          [-1, 96, 14, 14]             192  InvertedResidual-99     [-1, 96, 14, 14]               0           Conv2d-100             [-1, 576, 14, 14]          55,296      BatchNorm2d-101        [-1, 576, 14, 14]           1,152            ReLU6-102              [-1, 576, 14, 14]               0           Conv2d-103             [-1, 576, 14, 14]           5,184      BatchNorm2d-104        [-1, 576, 14, 14]           1,152            ReLU6-105              [-1, 576, 14, 14]               0           Conv2d-106              [-1, 96, 14, 14]          55,296      BatchNorm2d-107         [-1, 96, 14, 14]             192 InvertedResidual-108    [-1, 96, 14, 14]               0           Conv2d-109             [-1, 576, 14, 14]          55,296      BatchNorm2d-110        [-1, 576, 14, 14]           1,152            ReLU6-111              [-1, 576, 14, 14]               0           Conv2d-112             [-1, 576, 14, 14]           5,184      BatchNorm2d-113        [-1, 576, 14, 14]           1,152            ReLU6-114              [-1, 576, 14, 14]               0           Conv2d-115              [-1, 96, 14, 14]          55,296      BatchNorm2d-116         [-1, 96, 14, 14]             192 InvertedResidual-117    [-1, 96, 14, 14]               0           Conv2d-118             [-1, 576, 14, 14]          55,296      BatchNorm2d-119        [-1, 576, 14, 14]           1,152            ReLU6-120              [-1, 576, 14, 14]               0           Conv2d-121               [-1, 576, 7, 7]           5,184      BatchNorm2d-122          [-1, 576, 7, 7]           1,152            ReLU6-123                [-1, 576, 7, 7]               0           Conv2d-124               [-1, 160, 7, 7]          92,160      BatchNorm2d-125          [-1, 160, 7, 7]             320 InvertedResidual-126     [-1, 160, 7, 7]               0           Conv2d-127               [-1, 960, 7, 7]         153,600      BatchNorm2d-128          [-1, 960, 7, 7]           1,920            ReLU6-129                [-1, 960, 7, 7]               0           Conv2d-130               [-1, 960, 7, 7]           8,640      BatchNorm2d-131          [-1, 960, 7, 7]           1,920            ReLU6-132                [-1, 960, 7, 7]               0           Conv2d-133               [-1, 160, 7, 7]         153,600      BatchNorm2d-134          [-1, 160, 7, 7]             320 InvertedResidual-135     [-1, 160, 7, 7]               0           Conv2d-136               [-1, 960, 7, 7]         153,600      BatchNorm2d-137          [-1, 960, 7, 7]           1,920            ReLU6-138                [-1, 960, 7, 7]               0           Conv2d-139               [-1, 960, 7, 7]           8,640      BatchNorm2d-140          [-1, 960, 7, 7]           1,920            ReLU6-141                [-1, 960, 7, 7]               0           Conv2d-142               [-1, 160, 7, 7]         153,600      BatchNorm2d-143          [-1, 160, 7, 7]             320 InvertedResidual-144     [-1, 160, 7, 7]               0           Conv2d-145               [-1, 960, 7, 7]         153,600      BatchNorm2d-146          [-1, 960, 7, 7]           1,920            ReLU6-147                [-1, 960, 7, 7]               0           Conv2d-148               [-1, 960, 7, 7]           8,640      BatchNorm2d-149          [-1, 960, 7, 7]           1,920            ReLU6-150                [-1, 960, 7, 7]               0           Conv2d-151               [-1, 320, 7, 7]         307,200      BatchNorm2d-152          [-1, 320, 7, 7]             640 InvertedResidual-153     [-1, 320, 7, 7]               0           Conv2d-154              [-1, 1280, 7, 7]         409,600      BatchNorm2d-155         [-1, 1280, 7, 7]           2,560            ReLU6-156               [-1, 1280, 7, 7]               0          Dropout-157                   [-1, 1280]               0           Linear-158                    [-1, 1000]       1,281,000 ================================================================ Total params: 3,504,872 <br>Trainable params: 3,504,872 <br>Non-trainable params: 0 <br>---------------------------------------------------------------- Input size (MB): 0.57 Forward/backward pass size (MB): 152.87 Params size (MB): 13.37 Estimated Total Size (MB): 166.81 ----------------------------------------------------------------</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the layers which is shown below with types of layer:</p><pre>MobileNetV2(   (features): Sequential(     (0): ConvBNActivation(       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )     (1): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (2): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (3): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (4): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (5): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (6): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (7): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (8): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (9): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (10): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (11): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (12): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (13): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (14): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (15): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (16): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (17): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (18): ConvBNActivation(       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )   )   (classifier): Sequential(     (0): Dropout(p=0.2, inplace=False)     (1): Linear(in_features=1280, out_features=1000, bias=True)</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>mobilenet_prediction=mobilenet_pretrained(x)                       <strong>#Line 4<br></strong>mobilenet_prediction_numpy=mobilenet_prediction.detach().numpy()   <strong>#Line 5<br></strong>predicted_class_max = np.argmax(mobilenet_prediction_numpy)     <strong>#Line 6<br></strong>predicted_class_max                                          <strong>#Line 7</strong></pre><p><strong>Line 4:</strong> This snippets send the pre-processed image to the Mobilenet network for getting prediction.</p><p><strong>Line 5: </strong>This line is used to<strong> </strong>move the prediction from the model from GPU to CPU so we can manipulate it and convert the prediction from torch tensor to numpy array.</p><p><strong>Line 6: </strong>This snippet is used to get the array index whose probability is maximum.</p><p><strong>Line 7: </strong>This snippets is used to display the highest probability class.</p><pre>504</pre><p>The below snippets is used to read the label from text file and display the label name as shown below:</p><pre>with open(‘/content/imagenet1000_clsidx_to_labels.txt’, ‘r’) as fp:<br>    line_numbers = [predicted_class_max]<br>    for i, line in enumerate(fp):<br>       if i in line_numbers:<br>           lines.append(line.strip()<br>           breakprint(lines)</pre><pre><strong>Output&gt;&gt;&gt;&gt;<br></strong>[&quot;504: &#39;coffee mug&#39;,&quot;]</pre><p><strong>2.1. As a feature Extraction model.</strong></p><p>Since we have discussed the Mobilenet model in details in out previous article i.e. in part 5.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained Mobilenet to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p>2.1.1<strong> Image to extract feature</strong></p><p>We will use the image of the coffee mug to predict the labels with the Mobilenet architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import torch                                          <strong>#Line 1<br></strong>import torchvision.models as models                   <strong>#Line 2<br></strong>from PIL import Image                                 <strong>#Line 3<br></strong>import torchvision.transforms.functional as TF        <strong>#Line 4<br></strong>from torchsummary import summary                      <strong>#Line 5<br></strong>!pip install torchviz                                 <strong>#Line 6<br></strong>from torchviz import make_dot                         <strong>#Line 7<br></strong>import numpy as np</pre><p><strong>Line 1:</strong> The above snippet is used to import the PyTorch library which we use use to implement Mobilenet network.</p><p><strong>Line 2:</strong> The above snippet is used to import the PyTorch pre-trained models.</p><p><strong>Line 3:</strong> The above snippet is used to import the PIL library for visualization purpose.</p><p><strong>Line 4:</strong> The above snippet is used to import the PyTorch Transformation library which we use use to transform the dataset for training and testing.</p><p><strong>Line 5:</strong> The above snippet is used to import library which shows the summary of models.</p><p><strong>Line 6:</strong> The above snippet is used to install torchviz to visualise the network.</p><p><strong>Line 7:</strong> The above snippet is used to import torchviz to visualize the network.</p><pre>image = Image.open(link_of_image)   <strong>#Line 8<br></strong>image=image.resize((224,224))       <strong>#Line 9<br></strong>x = TF.to_tensor(image)             <strong>#Line 10<br></strong>x.unsqueeze_(0)                     <strong>#Line 11<br></strong>x=x.to(device)                      <strong>#Line 12<br></strong>print(x.shape)                      <strong>#Line 13</strong></pre><p><strong>Line 8: </strong>This snippet loads the images from the path.</p><p><strong>Line 9: </strong>This snippet converts the image in the size (224,224) required by the model.</p><p><strong>Line 10:</strong> This snippet convert the image into array</p><p><strong>Line 11: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 12:</strong> This snippet is used to move the image to the device on which model is registered.</p><p><strong>Line 13: </strong>This snippet use to display the image shape as shown below:</p><pre>torch.Size([1, 3, 224, 224])</pre><p>2.1.2 <strong>Mobilenet Implementation as Feature extraction</strong>(code)</p><p>Here we will use Mobilenet network to extract features of the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <br><strong>#LINE 0<br></strong>mobilenet_pretrained = models.mobilenet_v2(pretrained=True).to(device) <br><strong>#LINE 1<br></strong>mobilenet_pretrained.features                             <br><strong>#LINE 2<br></strong>summary(mobilenet_pretrained, (3, 224, 224))               <br><strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the Mobilenet model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>MobileNetV2(   (features): Sequential(     (0): ConvBNActivation(       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )     (1): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (2): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (3): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (4): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (5): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (6): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (7): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (8): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (9): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (10): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (11): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (12): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (13): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (14): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (15): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (16): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (17): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (18): ConvBNActivation(       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )   )   (classifier): Sequential(     (0): Dropout(p=0.2, inplace=False)     (1): Linear(in_features=1280, out_features=1000, bias=True)</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the feature extractor layers which is shown below :</p><pre>----------------------------------------------------------------         Layer (type)               Output Shape         Param # ================================================================             Conv2d-1              [-1, 32, 112, 112]             864        BatchNorm2d-2         [-1, 32, 112, 112]              64              ReLU6-3               [-1, 32, 112, 112]               0             Conv2d-4              [-1, 32, 112, 112]             288        BatchNorm2d-5         [-1, 32, 112, 112]              64              ReLU6-6               [-1, 32, 112, 112]               0             Conv2d-7              [-1, 16, 112, 112]             512        BatchNorm2d-8         [-1, 16, 112, 112]              32   InvertedResidual-9    [-1, 16, 112, 112]               0            Conv2d-10             [-1, 96, 112, 112]           1,536       BatchNorm2d-11        [-1, 96, 112, 112]             192             ReLU6-12              [-1, 96, 112, 112]               0            Conv2d-13               [-1, 96, 56, 56]             864       BatchNorm2d-14          [-1, 96, 56, 56]             192             ReLU6-15                [-1, 96, 56, 56]               0            Conv2d-16               [-1, 24, 56, 56]           2,304       BatchNorm2d-17          [-1, 24, 56, 56]              48  InvertedResidual-18     [-1, 24, 56, 56]               0            Conv2d-19              [-1, 144, 56, 56]           3,456       BatchNorm2d-20         [-1, 144, 56, 56]             288             ReLU6-21               [-1, 144, 56, 56]               0            Conv2d-22              [-1, 144, 56, 56]           1,296       BatchNorm2d-23         [-1, 144, 56, 56]             288             ReLU6-24               [-1, 144, 56, 56]               0            Conv2d-25               [-1, 24, 56, 56]           3,456       BatchNorm2d-26          [-1, 24, 56, 56]              48  InvertedResidual-27     [-1, 24, 56, 56]               0            Conv2d-28              [-1, 144, 56, 56]           3,456       BatchNorm2d-29         [-1, 144, 56, 56]             288             ReLU6-30               [-1, 144, 56, 56]               0            Conv2d-31              [-1, 144, 28, 28]           1,296       BatchNorm2d-32         [-1, 144, 28, 28]             288             ReLU6-33               [-1, 144, 28, 28]               0            Conv2d-34               [-1, 32, 28, 28]           4,608       BatchNorm2d-35          [-1, 32, 28, 28]              64  InvertedResidual-36     [-1, 32, 28, 28]               0            Conv2d-37              [-1, 192, 28, 28]           6,144       BatchNorm2d-38         [-1, 192, 28, 28]             384             ReLU6-39               [-1, 192, 28, 28]               0            Conv2d-40              [-1, 192, 28, 28]           1,728       BatchNorm2d-41         [-1, 192, 28, 28]             384             ReLU6-42               [-1, 192, 28, 28]               0            Conv2d-43               [-1, 32, 28, 28]           6,144       BatchNorm2d-44          [-1, 32, 28, 28]              64  InvertedResidual-45     [-1, 32, 28, 28]               0            Conv2d-46              [-1, 192, 28, 28]           6,144       BatchNorm2d-47         [-1, 192, 28, 28]             384             ReLU6-48               [-1, 192, 28, 28]               0            Conv2d-49              [-1, 192, 28, 28]           1,728       BatchNorm2d-50         [-1, 192, 28, 28]             384             ReLU6-51               [-1, 192, 28, 28]               0            Conv2d-52               [-1, 32, 28, 28]           6,144       BatchNorm2d-53          [-1, 32, 28, 28]              64  InvertedResidual-54     [-1, 32, 28, 28]               0            Conv2d-55              [-1, 192, 28, 28]           6,144       BatchNorm2d-56         [-1, 192, 28, 28]             384             ReLU6-57               [-1, 192, 28, 28]               0            Conv2d-58              [-1, 192, 14, 14]           1,728       BatchNorm2d-59         [-1, 192, 14, 14]             384             ReLU6-60               [-1, 192, 14, 14]               0            Conv2d-61               [-1, 64, 14, 14]          12,288       BatchNorm2d-62          [-1, 64, 14, 14]             128  InvertedResidual-63     [-1, 64, 14, 14]               0            Conv2d-64              [-1, 384, 14, 14]          24,576       BatchNorm2d-65         [-1, 384, 14, 14]             768             ReLU6-66               [-1, 384, 14, 14]               0            Conv2d-67              [-1, 384, 14, 14]           3,456       BatchNorm2d-68         [-1, 384, 14, 14]             768             ReLU6-69               [-1, 384, 14, 14]               0            Conv2d-70               [-1, 64, 14, 14]          24,576       BatchNorm2d-71          [-1, 64, 14, 14]             128  InvertedResidual-72     [-1, 64, 14, 14]               0            Conv2d-73              [-1, 384, 14, 14]          24,576       BatchNorm2d-74         [-1, 384, 14, 14]             768             ReLU6-75               [-1, 384, 14, 14]               0            Conv2d-76              [-1, 384, 14, 14]           3,456       BatchNorm2d-77         [-1, 384, 14, 14]             768             ReLU6-78               [-1, 384, 14, 14]               0            Conv2d-79               [-1, 64, 14, 14]          24,576       BatchNorm2d-80          [-1, 64, 14, 14]             128  InvertedResidual-81     [-1, 64, 14, 14]               0            Conv2d-82              [-1, 384, 14, 14]          24,576       BatchNorm2d-83         [-1, 384, 14, 14]             768             ReLU6-84               [-1, 384, 14, 14]               0            Conv2d-85              [-1, 384, 14, 14]             768             ReLU6-87               [-1, 384, 14, 14]               0            Conv2d-88               [-1, 64, 14, 14]          24,576       BatchNorm2d-89          [-1, 64, 14, 14]             128  InvertedResidual-90     [-1, 64, 14, 14]               0            Conv2d-91              [-1, 384, 14, 14]          24,576       BatchNorm2d-92         [-1, 384, 14, 14]             768             ReLU6-93               [-1, 384, 14, 14]               0            Conv2d-94              [-1, 384, 14, 14]           3,456       BatchNorm2d-95         [-1, 384, 14, 14]             768             ReLU6-96               [-1, 384, 14, 14]               0            Conv2d-97               [-1, 96, 14, 14]          36,864       BatchNorm2d-98          [-1, 96, 14, 14]             192  InvertedResidual-99     [-1, 96, 14, 14]               0           Conv2d-100             [-1, 576, 14, 14]          55,296      BatchNorm2d-101        [-1, 576, 14, 14]           1,152            ReLU6-102              [-1, 576, 14, 14]               0           Conv2d-103             [-1, 576, 14, 14]           5,184      BatchNorm2d-104        [-1, 576, 14, 14]           1,152            ReLU6-105              [-1, 576, 14, 14]               0           Conv2d-106              [-1, 96, 14, 14]          55,296      BatchNorm2d-107         [-1, 96, 14, 14]             192 InvertedResidual-108    [-1, 96, 14, 14]               0           Conv2d-109             [-1, 576, 14, 14]          55,296      BatchNorm2d-110        [-1, 576, 14, 14]           1,152            ReLU6-111              [-1, 576, 14, 14]               0           Conv2d-112             [-1, 576, 14, 14]           5,184      BatchNorm2d-113        [-1, 576, 14, 14]           1,152            ReLU6-114              [-1, 576, 14, 14]               0           Conv2d-115              [-1, 96, 14, 14]          55,296      BatchNorm2d-116         [-1, 96, 14, 14]             192 InvertedResidual-117    [-1, 96, 14, 14]               0           Conv2d-118             [-1, 576, 14, 14]          55,296      BatchNorm2d-119        [-1, 576, 14, 14]           1,152            ReLU6-120              [-1, 576, 14, 14]               0           Conv2d-121               [-1, 576, 7, 7]           5,184      BatchNorm2d-122          [-1, 576, 7, 7]           1,152            ReLU6-123                [-1, 576, 7, 7]               0           Conv2d-124               [-1, 160, 7, 7]          92,160      BatchNorm2d-125          [-1, 160, 7, 7]             320 InvertedResidual-126     [-1, 160, 7, 7]               0           Conv2d-127               [-1, 960, 7, 7]         153,600      BatchNorm2d-128          [-1, 960, 7, 7]           1,920            ReLU6-129                [-1, 960, 7, 7]               0           Conv2d-130               [-1, 960, 7, 7]           8,640      BatchNorm2d-131          [-1, 960, 7, 7]           1,920            ReLU6-132                [-1, 960, 7, 7]               0           Conv2d-133               [-1, 160, 7, 7]         153,600      BatchNorm2d-134          [-1, 160, 7, 7]             320 InvertedResidual-135     [-1, 160, 7, 7]               0           Conv2d-136               [-1, 960, 7, 7]         153,600      BatchNorm2d-137          [-1, 960, 7, 7]           1,920            ReLU6-138                [-1, 960, 7, 7]               0           Conv2d-139               [-1, 960, 7, 7]           8,640      BatchNorm2d-140          [-1, 960, 7, 7]           1,920            ReLU6-141                [-1, 960, 7, 7]               0           Conv2d-142               [-1, 160, 7, 7]         153,600      BatchNorm2d-143          [-1, 160, 7, 7]             320 InvertedResidual-144     [-1, 160, 7, 7]               0           Conv2d-145               [-1, 960, 7, 7]         153,600      BatchNorm2d-146          [-1, 960, 7, 7]           1,920            ReLU6-147                [-1, 960, 7, 7]               0           Conv2d-148               [-1, 960, 7, 7]           8,640      BatchNorm2d-149          [-1, 960, 7, 7]           1,920            ReLU6-150                [-1, 960, 7, 7]               0           Conv2d-151               [-1, 320, 7, 7]         307,200      BatchNorm2d-152          [-1, 320, 7, 7]             640 InvertedResidual-153     [-1, 320, 7, 7]               0           Conv2d-154              [-1, 1280, 7, 7]         409,600      BatchNorm2d-155         [-1, 1280, 7, 7]           2,560            ReLU6-156               [-1, 1280, 7, 7]               0          Dropout-157                   [-1, 1280]               0           Linear-158                    [-1, 1000]       1,281,000 ================================================================ Total params: 3,504,872 <br>Trainable params: 3,504,872 <br>Non-trainable params: 0 <br>---------------------------------------------------------------- Input size (MB): 0.57 Forward/backward pass size (MB): 152.87 Params size (MB): 13.37 Estimated Total Size (MB): 166.81 ----------------------------------------------------------------</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>resnet_prediction=mobilenet_pretrainedd.features(x)              <strong>#Line 4<br></strong>mobilenet_prediction_numpy=mobilenet_pretrained.detach().numpy()   <strong>#Line 5</strong></pre><p><strong>Line 4: </strong>This snippet is used to feed the image to the feature extractor layer of the Mobilenet network</p><p><strong>Line 5: </strong>This snippet is used to detacht the output from the GPU to CPU.</p><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1000) </em>and for the training set it will be of<em>(50000,1,1000), f</em>or test set it will be of<em>(10000,1,1000) size.</em></p><p>2.2 <strong>Using Mobilenet Architecture(</strong>without weights<strong>)</strong></p><p>In this section we will see how we can implemen tMobilenet as a architecture in Keras. We will use state of the art Mobilenet network architecture and train it with our datasets from scratch i.e. we will not use pre-trained weights in this architecture the weights will be optimized while training from scratch. The code is explained below:</p><p>2.2.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 datasets composed of 60K images, 50K for training and 10K for testing/evaluation.</p><pre>import os<br>import torch<br>import torchvision<br>import torchvision.models as models<br>import tarfilefrom torchvision.datasets.utils <br>import download_url<br>from torch.utils.data import random_splitfrom skimage import io, transformimport torchvision.transforms as transformsfrom torchvision.datasets <br>import ImageFolder<br>from torchvision.transforms import ToTensor,Resize<br>import matplotlib<br>import matplotlib.pyplot as pltfrom torchvision.utils <br>import make_gridfrom torch.utils.data.dataloader <br>import DataLoader%matplotlib inlinematplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;download_url(dataset_url, &#39;.&#39;)with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the datasets from the AWS server in our environment and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)print(dataset.classes)</pre><p>The above snippets is used to transform the datasets into PyTorch datasets by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the datasets into two set i.e. test set and train set.</p><pre>val_size = 5000<br>train_size = len(dataset) - val_sizetrain_ds, <br>val_ds = random_split(dataset, [train_size, val_size])len(train_ds), len(val_ds)<br>batch_size=32<br>train_dl = DataLoader(train_ds, batch_size, shuffle=True)<br>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the datasets as shown below:</p><pre>def show_batch(dl):for images, labels in dl:fig, ax = plt.subplots(figsize=(12, 6))ax.set_xticks([]); ax.set_yticks([])ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))breakshow_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/0*Pywtl5-hi5VV6gsS.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p>2.2.2 <strong>Mobilnet Architecture</strong>(code)</p><p>In this section we will see how we can implement Mobilnet as a architecture in Keras.</p><pre>mobilenet_v2_pretrained = models.mobilenet_v2()<br>mobilenet_v2_pretrained.fc=torch.nn.Linear(mobilenet_v2_pretrained.fc.in_features, 10)<br>for param in mobilenet_v2_pretrained.fc.parameters():<br>    param.requires_grad = True</pre><p>The above snippet is used to initiate the object for the Mobilnet model.Since we are using the Mobilnet as a architecture with our custom datasets so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The line has 10 neurons with Softmax activation function which allow us to predict the probabilities of each classes from the neural network. the architecture is shown below:</p><pre>ResNet(   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   (relu): ReLU(inplace=True)   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)   (layer1): Sequential(     (0): Bottleneck(       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer2): Sequential(     (0): Bottleneck(       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer3): Sequential(     (0): Bottleneck(       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (4): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (5): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer4): Sequential(     (0): Bottleneck(       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))   (fc): Linear(in_features=2048, out_features=10, bias=True) )</pre><p>Now after creating model we have to test the model that it is producing the correct output which can be done with the help of below codes:</p><pre>for images, labels in train_dl:<br>    print(&#39;images.shape:&#39;, images.shape)<br>    out = mobilenet_v2_pretrained(images)<br>    print(&#39;out.shape:&#39;, out.shape)<br>    print(&#39;out[0]:&#39;, out[0])break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3<br>best_accuracy = 0.0<br>import torch.optim as optimi<br>mport torch.nn.functional as F<br>optimizer = optim.SGD(resnet_pretrained.parameters(), lr=0.001, momentum=0.9)<br>for epoch in range(NUM_EPOCHS):<br>    print(epoch)    <br>    a=0<br>    for images, labels in iter(train_dl):<br>         print(epoch,a)<br>         a=a+1<br>         optimizer.zero_grad()<br>         outputs = mobilenet_v2_pretrained(images)<br>         loss = F.cross_entropy(outputs, labels)           <br>         loss.backward()<br>         optimizer.step()<br>         a=a+1<br>         test_error_count = 0.0<br>         for images, labels in iter(test_dl):<br>             outputs =mobilenet_v2_pretrained(images)      <br>             test_error_count += float(torch.sum(torch.abs(labels -   <br>                                 outputs.argmax(1))))     <br>             test_accuracy = 1.0 - float(test_error_count) /    <br>             float(len(test_dataset))    <br>             print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have trained our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  mobilenet_v2_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used Mobilnet architecture to train on our custom datasets.</p><h3>2.3. Fine Turning Mobilnet Architecture with Custom Fully Connected layers</h3><p>In this section we will see how we can implementMobilnet as a architecture in PyTorch. We will use state of the art Mobilnet network architecture and train it with our dataset from scratch i.e. we will use pre-trained weights in this architecture the weights will be optimised while training from scratch only for the fully connected layers but the code for the pre-trained layers remains as it is. The code is explained below:</p><p>2.3.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>import os<br>import torch<br>import torchvision<br>import torchvision.models as models<br>import tarfile from torchvision.datasets.utils <br>import download_urlfrom torch.utils.data <br>import random_splitfrom skimage <br>import io, transform<br>import torchvision.transforms as transformsfrom torchvision.datasets import ImageFolderfrom torchvision.transforms <br>import ToTensor,Resizeimport matplotlib<br>import matplotlib.pyplot as plt<br>from torchvision.utils import make_grid<br>from torch.utils.data.dataloader <br>import DataLoader%matplotlib inlinematplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;download_url(dataset_url, &#39;.&#39;)with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the dataset from the AWS server in our enviromenet and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)print(dataset.classes)</pre><p>The above snippets is uded to tranform the dataset into PyTorch dataset by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the dataset into two set i.e. test set and train set.</p><pre>val_size = 5000<br>train_size = len(dataset) - val_sizetrain_ds, val_ds = random_split(dataset, [train_size, val_size])len(train_ds), len(val_ds)<br>batch_size=32<br>train_dl = DataLoader(train_ds, batch_size, shuffle=True)<br>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the dataset as shown below:</p><pre>def show_batch(dl):for images, labels in dl:fig, ax = plt.subplots(figsize=(12, 6))ax.set_xticks([]); ax.set_yticks([])ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))breakshow_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/0*qHABu_UnEmEUSOEn.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p><strong>2.3.2 Mobilnet Fully Connected Layer Optimisation(code)</strong></p><p>In this section we will see how we can implement Mobilne<strong>t</strong> as a architecture in PyTorch.</p><pre>mobilenet_v2_pretrained = models.mobilenet_v2(pretrained=True)<br>from collections import OrderedDict<br>for param in mobilenet_v2_pretrained.parameters():    <br>    param.requires_grad = True<br>mobilenet_v2_pretrained.fc=torch.nn.Sequential(OrderedDict([(&#39;fc1&#39;,torch.nn.Linear(mobilenet_v2_pretrained.fc.in_features, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))<br>for param in mobilenet_v2_pretrained.fc.parameters():<br>    param.requires_grad = True</pre><p>The above snippet is used to initiate the object for the Mobilnet model.Since we are using the Mobilnet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The pre-trained weight weights are specified <em>param.requires_grad = False s</em>o that the loss is not propagated back to these layers where as<em>in fully connected layers param.requires_grad = True </em>which allows loss to propagate back only in this layers<em>.</em>The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>MobileNetV2(   (features): Sequential(     (0): ConvBNActivation(       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )     (1): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (2): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (3): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (4): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (5): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (6): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (7): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (8): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (9): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (10): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (11): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (12): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (13): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (14): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (15): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (16): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (17): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (18): ConvBNActivation(       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )   )   (classifier): Sequential(     (0): Dropout(p=0.2, inplace=False)     (1): Linear(in_features=1280, out_features=10, bias=True)   ) )</pre><p>Now after creating model we have to test the model that it is producing the correct output which can be done with the help of below codes:</p><pre>for images, labels in train_dl:<br>    print(&#39;images.shape:&#39;, images.shape)    <br>    out = mobilenet_v2_pretrained(images)    <br>    print(&#39;out.shape:&#39;, out.shape)    <br>    print(&#39;out[0]:&#39;, out[0])    <br>    break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3<br>best_accuracy = 0.0<br>import torch.optim as optimi<br>mport torch.nn.functional as F<br>optimizer = optim.SGD(resnet_pretrained.parameters(), lr=0.001, momentum=0.9)<br>for epoch in range(NUM_EPOCHS):<br>    print(epoch)    <br>    a=0<br>    for images, labels in iter(train_dl):<br>         print(epoch,a)<br>         a=a+1<br>         optimizer.zero_grad()<br>         outputs = mobilenet_v2_pretrained(images)<br>         loss = F.cross_entropy(outputs, labels)           <br>         loss.backward()<br>         optimizer.step()<br>         a=a+1<br>         test_error_count = 0.0<br>         for images, labels in iter(test_dl):<br>             outputs = mobilenet_v2_pretrained(images)      <br>             test_error_count += float(torch.sum(torch.abs(labels -   <br>                                 outputs.argmax(1))))     <br>             test_accuracy = 1.0 - float(test_error_count) /    <br>             float(len(test_dataset))    <br>             print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have trained our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  mobilenet_v2_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used Mobilnet architecture to train on our custom dataset.</p><h3>2.4. Mobilnet weights as a neural network weight initializer</h3><p>In this section we will see how we can implement Mobilnet as a weight ibnitializer in PyTorch. We will use state of the art Mobilnet network architecture and train it with our dataset from scratch i.e. we will use pre-trained weights in this architecture the weights will be optimised while training from scratch only for the fully connected layers but the code for the pre-trained layers remains as it is. The code is explained below:</p><p>2.4.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>import os<br>import torch<br>import torchvision<br>import torchvision.models as models<br>import tarfile<br>from torchvision.datasets.utils <br>import download_urlfrom torch.utils.data <br>import random_splitfrom skimage <br>import io, transform<br>import torchvision.transforms as transformsfrom torchvision.datasets import ImageFolderfrom torchvision.transforms <br>import ToTensor,Resize<br>import matplotlib<br>import matplotlib.pyplot as pltfrom torchvision.utils <br>import make_grid<br>from torch.utils.data.dataloader <br>import DataLoader%matplotlib inlinematplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;download_url(dataset_url, &#39;.&#39;)with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the dataset from the AWS server in our enviromenet and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)print(dataset.classes)</pre><p>The above snippets is used to tranform the dataset into PyTorch dataset by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the dataset into two set i.e. test set and train set.</p><pre>val_size = 5000<br>train_size = len(dataset) - val_sizetrain_ds, <br>val_ds = random_split(dataset, [train_size, val_size])len(train_ds), len(val_ds)<br>batch_size=32<br>train_dl = DataLoader(train_ds, batch_size, shuffle=True)<br>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the dataset as shown below:</p><pre>def show_batch(dl):for images, labels in dl:fig, ax = plt.subplots(figsize=(12, 6))ax.set_xticks([]); ax.set_yticks([])ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))breakshow_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/0*fa9W7M7bh7bKkWzz.png" /><figcaption>Figure 2. Sample CIFAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p><strong>2.4.2</strong><strong>Mobilnet weights as a initialiser (code)</strong></p><p>In this section we will see how we can implement Mobilnet as a architecture in PyTorch.</p><pre>pretrained = models.mobilenet_v2_pretrained(pretrained=True)<br>for param in pretrained.parameters():<br>   param.requires_grad = True</pre><pre>pretrained.fc=torch.nn.Sequential(OrderedDict([(&#39;fc1&#39;,torch.nn.Linear(pretrained.fc.in_features, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in pretrained.classifier[6].parameters():<br>    param.requires_grad = True</pre><pre>pretrained</pre><p>The above snippet is used to initiate the object for the Mobilnet model.Since we are using the Mobilnet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The pre-trained weight weights are specified <em>param.requires_grad = False s</em>o that the loss is not propagated back to these layers where as<em>in fully connected layers param.requires_grad = True </em>which allows loss to propagate back only in this layers<em>.</em>The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>MobileNetV2(   (features): Sequential(     (0): ConvBNActivation(       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )     (1): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (2): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (3): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (4): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (5): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (6): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (7): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (8): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (9): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (10): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (11): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (12): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (13): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (14): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (15): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (16): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (17): InvertedResidual(       (conv): Sequential(         (0): ConvBNActivation(           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (1): ConvBNActivation(           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)           (2): ReLU6(inplace=True)         )         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (18): ConvBNActivation(       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (2): ReLU6(inplace=True)     )   )   (classifier): Sequential(     (0): Dropout(p=0.2, inplace=False)     (1): Linear(in_features=1280, out_features=10, bias=True)   ) )</pre><p>Now after creating model we have to test the model that it is producing the correct output which acn be donne with the help of below codes:</p><pre>for images, labels in train_dl:<br>    print(&#39;images.shape:&#39;, images.shape)    <br>    out = pretrained(images)    <br>    print(&#39;out.shape:&#39;, out.shape)    <br>    print(&#39;out[0]:&#39;, out[0])    <br>    break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3<br>best_accuracy = 0.0<br>import torch.optim as optimi<br>mport torch.nn.functional as F<br>optimizer = optim.SGD(resnet_pretrained.parameters(), lr=0.001, momentum=0.9)<br>for epoch in range(NUM_EPOCHS):<br>    print(epoch)    <br>    a=0<br>    for images, labels in iter(train_dl):<br>         print(epoch,a)<br>         a=a+1<br>         optimizer.zero_grad()<br>         outputs = pretrained(images)<br>         loss = F.cross_entropy(outputs, labels)           <br>         loss.backward()<br>         optimizer.step()<br>         a=a+1<br>         test_error_count = 0.0<br>         for images, labels in iter(test_dl):<br>             outputs = pretrained(images)      <br>             test_error_count += float(torch.sum(torch.abs(labels -   <br>                                 outputs.argmax(1))))     <br>             test_accuracy = 1.0 - float(test_error_count) /    <br>             float(len(test_dataset))    <br>             print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have traioned our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used Mobilnet architechture to train on our custom dataset.</p><p>In this article we have discussed about the pre-trained Mobilenet models with implementation in PyTorch. In next article we will discuss Xception model. Stay Tuned!!!!</p><p>Special Thanks:</p><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote><em>Pytorch: </em><a href="https://pytorch.org/get-started/locally/#windows-python"><em>Link</em></a></blockquote><blockquote><em>Keras: </em><a href="https://keras.io/"><em>Link</em></a></blockquote><blockquote><em>Tensorflow: </em><a href="https://www.tensorflow.org/guide/keras/sequential_model"><em>Link</em></a></blockquote><blockquote><em>ResNet Paper:</em></blockquote><blockquote><em>Imagenet Dataset: </em><a href="https://www.image-net.org/"><em>Link</em></a></blockquote><blockquote><em>ILSVRC : </em><a href="https://www.image-net.org/challenges/LSVRC/index.php"><em>Link</em></a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote><em>YouTube : </em><a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ"><em>Lin</em></a><em>k</em></blockquote><blockquote><em>Website: </em><a href="http://www.rstiwari.com/"><em>www.rstiwari.com</em></a></blockquote><blockquote><em>Medium: </em><a href="https://tiwari11-rst.medium.com/"><em>https://tiwari11-rst.medium.com</em></a></blockquote><blockquote><em>Github Pages: </em><a href="https://happyman11.github.io/"><em>https://happyman11.github.io/</em></a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote><em>Google Form: </em><a href="https://forms.gle/mhDYQKQJKtAKP78V7"><em>https://forms.gle/mhDYQKQJKtAKP78V7</em></a></blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2d3f3851a15b" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-6-2-implementing-mobilenet-in-pytorch-2d3f3851a15b">Transfer Learning — Part — 6.2!! Implementing Mobilenet in PyTorch</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 6.1!! Implementing Mobilenet in Keras]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-6-1-implementing-mobilenet-in-keras-b8d314a8609a?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/b8d314a8609a</guid>
    <category>
        <![CDATA[keras]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[convolution]]>
    </category>
    <category>
        <![CDATA[mobilenetv2]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Sun, 13 Mar 2022 08:59:45 GMT</pubDate>
    <atom:updated>2022-08-05T16:15:52.340Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 6.1!! Implementing Mobilenet in Keras</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*uMvRZ8dnfRkXsxnY.jpg" /><figcaption>Figure.1 Transfer Learning</figcaption></figure><p>In Part 6.0 of the Transfer Learning series we have discussed about Mobilenet pre-trained model in depth so in this series we will implement the above mentioned pre-trained model in Keras. We will be implementing the pre-trained Mobilenet model in 4 ways which we will discuss further in this article. For setting- up the Colab notebook it will be advisable to go through the below mentioned article of Transfer Learning Series. In Part 2 of the Transfer Learning series we have discussed how we can set-up our environment below is the link for the article.</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>It is also advisable to go through the article of ResNet before reading this article which is mentioned below:</p><p><a href="https://tiwari11-rst.medium.com/transfer-learning-part-6-0-mobile-net-a7e7467a27f">Transfer Learning — Part — 6.0!! Mobile net</a></p><h3>1. Implementing Mobilenet Pre-trained model</h3><p>In this section we will see how we can implement MobileNet model in keras to have a foundation to start our real implementation .</p><p><strong>1.1. Image which we will predict on</strong></p><p>We will use the image of the coffee mug to predict the labels with the Mobilenet architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image = tf.keras.preprocessing.image.load_img(link_of_image, target_size=(224, 224))                                     <strong>#Line 2<br></strong>image = tf.keras.preprocessing.image.img_to_array(image)    <strong>#Line 3<br></strong>image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))                                            <strong>#Line 4<br></strong>image = tf.keras.applications.mobilenet_v2.preprocess_input(image)<strong>#Line 5</strong></pre><p><strong>Line 2: </strong>This snippet loads the images with size of (224,224).</p><p><strong>Line 3: </strong>This snippet converts the image into array for further pre-processing.</p><p><strong>Line 4: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 5: </strong>This snippet use to pre process the image according to the Mobilenet architecture.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/0*Cm5imJMzXY7M40Ks.jpeg" /><figcaption>Figure. 1 Image to be predicted</figcaption></figure><p><strong>1.2. Mobilenet Implementation</strong></p><p>Here we will use Mobilenet network to predict on the coffee mug image code is demonstrated below.</p><pre>MobileNetV2_MODEL=   tf.keras.applications.MobileNetV2(include_top=True, weights=&#39;imagenet&#39;, input_tensor=None,input_shape=(224,224, 3), pooling=&#39;max&#39;, classes=1000,classifier_activation=&#39;softmax&#39;) <strong>#Line 1</strong></pre><pre>print(MobileNetV2_MODEL.summary()).                          <strong>#Line 2</strong></pre><p><strong>Line 1:</strong> This snippets is used to create an object for the MobileNet model by including all its layer, specifying input shape to —<em>input_shape=(224, 224, 3), </em>pooling is set to max pooling<em>pooling=’max’, </em>since no. of classes in 1000 in ImageNet we also have set the classes to 1000 here classes=1000<strong> </strong>and classifier_ layer activation to softmax i.e.<em>classifier_activation=’softmax’.</em></p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>Model: &quot;mobilenetv2_1.00_224&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_1 (InputLayer)            [(None, 224, 224, 3) 0                                             __________________________________________________________________________________________________ Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                     __________________________________________________________________________________________________ bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                       __________________________________________________________________________________________________ Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                    __________________________________________________________________________________________________ expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                  __________________________________________________________________________________________________ expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]     __________________________________________________________________________________________________ expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0]  __________________________________________________________________________________________________ expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0 __________________________________________________________________________________________________ expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]       __________________________________________________________________________________________________ block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]    __________________________________________________________________________________________________ block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]              __________________________________________________________________________________________________ block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]           __________________________________________________________________________________________________ block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]         __________________________________________________________________________________________________ block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                 __________________________________________________________________________________________________ block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]           __________________________________________________________________________________________________ block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]             __________________________________________________________________________________________________ block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]          __________________________________________________________________________________________________ block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]              __________________________________________________________________________________________________ block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]           __________________________________________________________________________________________________ block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]         __________________________________________________________________________________________________ block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]           __________________________________________________________________________________________________ block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]             __________________________________________________________________________________________________ block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]                                                                           block_2_project_BN[0][0]          __________________________________________________________________________________________________ block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                 __________________________________________________________________________________________________ block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]              __________________________________________________________________________________________________ block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]           __________________________________________________________________________________________________ block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]         __________________________________________________________________________________________________ block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                 __________________________________________________________________________________________________ block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]           __________________________________________________________________________________________________ block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]             __________________________________________________________________________________________________ block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]          __________________________________________________________________________________________________ block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]              __________________________________________________________________________________________________ block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]           __________________________________________________________________________________________________ block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]         __________________________________________________________________________________________________ block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]           __________________________________________________________________________________________________ block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]             __________________________________________________________________________________________________ block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]                                                                           block_4_project_BN[0][0]          __________________________________________________________________________________________________ block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                 __________________________________________________________________________________________________ block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]              __________________________________________________________________________________________________ block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]           __________________________________________________________________________________________________ block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]         __________________________________________________________________________________________________ block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]           __________________________________________________________________________________________________ block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]             __________________________________________________________________________________________________ block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                                                                                  block_5_project_BN[0][0]          __________________________________________________________________________________________________ block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                 __________________________________________________________________________________________________ block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]              __________________________________________________________________________________________________ block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]           __________________________________________________________________________________________________ block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]         __________________________________________________________________________________________________ block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                 __________________________________________________________________________________________________ block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]           __________________________________________________________________________________________________ block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]             __________________________________________________________________________________________________ block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]          __________________________________________________________________________________________________ block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]              __________________________________________________________________________________________________ block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]           __________________________________________________________________________________________________ block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]         __________________________________________________________________________________________________ block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]           __________________________________________________________________________________________________ block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]             __________________________________________________________________________________________________ block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]                                                                           block_7_project_BN[0][0]          __________________________________________________________________________________________________ block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                 __________________________________________________________________________________________________ block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]              __________________________________________________________________________________________________ block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]           __________________________________________________________________________________________________ block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]         __________________________________________________________________________________________________ block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]           __________________________________________________________________________________________________ block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]             __________________________________________________________________________________________________ block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                                                                                  block_8_project_BN[0][0]          __________________________________________________________________________________________________ block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                 __________________________________________________________________________________________________ block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]              __________________________________________________________________________________________________ block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]           __________________________________________________________________________________________________ block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]         __________________________________________________________________________________________________ block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]           __________________________________________________________________________________________________ block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]             __________________________________________________________________________________________________ block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                                                                                  block_9_project_BN[0][0]          __________________________________________________________________________________________________ block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                 __________________________________________________________________________________________________ block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]             __________________________________________________________________________________________________ block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]          __________________________________________________________________________________________________ block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]        __________________________________________________________________________________________________ block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]          __________________________________________________________________________________________________ block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]            __________________________________________________________________________________________________ block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]         __________________________________________________________________________________________________ block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]             __________________________________________________________________________________________________ block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]          __________________________________________________________________________________________________ block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]        __________________________________________________________________________________________________ block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]          __________________________________________________________________________________________________ block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]            __________________________________________________________________________________________________ block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]                                                                          block_11_project_BN[0][0]         __________________________________________________________________________________________________ block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]                __________________________________________________________________________________________________ block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]             __________________________________________________________________________________________________ block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]          __________________________________________________________________________________________________ block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]        __________________________________________________________________________________________________ block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]          __________________________________________________________________________________________________ block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]            __________________________________________________________________________________________________ block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]                                                                                 block_12_project_BN[0][0]         __________________________________________________________________________________________________ block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]                __________________________________________________________________________________________________ block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]             __________________________________________________________________________________________________ block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]          __________________________________________________________________________________________________ block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]        __________________________________________________________________________________________________ block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]                __________________________________________________________________________________________________ block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]          __________________________________________________________________________________________________ block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]            __________________________________________________________________________________________________ block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]         __________________________________________________________________________________________________ block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]             __________________________________________________________________________________________________ block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]          __________________________________________________________________________________________________ block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]        __________________________________________________________________________________________________ block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]          __________________________________________________________________________________________________ block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]            __________________________________________________________________________________________________ block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]                                                                          block_14_project_BN[0][0]         __________________________________________________________________________________________________ block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]                __________________________________________________________________________________________________ block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]             __________________________________________________________________________________________________ block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]          __________________________________________________________________________________________________ block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]        __________________________________________________________________________________________________ block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]          __________________________________________________________________________________________________ block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]            __________________________________________________________________________________________________ block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]                                                                                 block_15_project_BN[0][0]         __________________________________________________________________________________________________ block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]                __________________________________________________________________________________________________ block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]             __________________________________________________________________________________________________ block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]          __________________________________________________________________________________________________ block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]        __________________________________________________________________________________________________ block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]          __________________________________________________________________________________________________ block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]            __________________________________________________________________________________________________ Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]         __________________________________________________________________________________________________ Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                      __________________________________________________________________________________________________ out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                   __________________________________________________________________________________________________ global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                    __________________________________________________________________________________________________ predictions (Dense)             (None, 1000)         1281000     global_average_pooling2d[0][0]    ================================================================================================== Total params: 3,538,984 Trainable params: 3,504,872 Non-trainable params: 34,112 __________________________________________________________________________________________________</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>import numpy as np<br>from keras.applications.imagenet_utils import preprocess_input, decode_predictions</pre><pre>Pred = MobileNetV2_MODEL.predict(image).       <strong>#Line 3</strong></pre><pre>print(np.argmax(Pred))<br>print(&#39;Predicted:&#39;, decode_predictions(Pred)). #<strong>Line 4</strong></pre><p><strong>Line 3:</strong> This snippets send the pre-processed image to the Mobilenet network for getting prediction.</p><p><strong>Line 4 and Line 5: </strong>These two line accept the prediction from the model and output the top 5 prediction probabilities which is shown below.</p><pre>Downloading data from <a href="https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json">https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json</a> 40960/35363 [==================================] - 0s 0us/step 49152/35363 [=========================================] - 0s 0us/step Predicted: [[(&#39;n03063599&#39;, &#39;coffee_mug&#39;, 0.870349), (&#39;n04560804&#39;, &#39;water_jug&#39;, 0.06071592), (&#39;n07930864&#39;, &#39;cup&#39;, 0.022826966), (&#39;n03063689&#39;, &#39;coffeepot&#39;, 0.012672128), (&#39;n03950228&#39;, &#39;pitcher&#39;, 0.0049368944)]]</pre><p>As I have mentioned above, we will discuss implementation of the pre-trained Mobilenet model in 4 ways which are as follows:</p><ol><li><strong>As a feature Extraction model.</strong></li><li><strong>Using Pre-trained models Mobilenet architecture.</strong></li><li><strong>Fine tunning Pre-trained models Mobilenet architecture.</strong></li><li><strong>Using Pre-trained model weights as a weight initialiser.</strong></li></ol><p>So without any further delay lets start our implementation in Keras :).</p><h3>2.1. As a feature Extraction model.</h3><p>Since we have discussed the Mobile model in details in out previous article i.e. in part 6.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained Mobilenet to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2<br></strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3<br></strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre><br>for i in range(9):  <strong>#Line 5</strong>#<br>    define subplotpyplot.subplot(330 + 1 + i)  <strong>#Line 6<br>    </strong># plot raw pixel data<br>    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7<br>    </strong># show the figure<br>    pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the dataset as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/0*AXhi2uc9f0l2VQss.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9<br></strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.1.2 Mobilenet Implementation as Feature extraction(code)</h3><p>In this section we will see how we can implement Mobilenet as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)).      <strong>#Line 2</strong></pre><pre>baseModel=tf.keras.applications.MobileNetV2(include_top=False,weights=None,input_tensor=image_input)                <strong>#Line 3</strong></pre><pre>baseModel.summary().                           <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained Mobilenet with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the Mobilenet model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;mobilenetv2_1.00_None&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ Conv1 (Conv2D)                  (None, 16, 16, 32)   864         input_2[0][0]                     __________________________________________________________________________________________________ bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                       __________________________________________________________________________________________________ Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                    __________________________________________________________________________________________________ expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                  __________________________________________________________________________________________________ expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]     __________________________________________________________________________________________________ expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0]  __________________________________________________________________________________________________ expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0 __________________________________________________________________________________________________ expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]       __________________________________________________________________________________________________ block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]    __________________________________________________________________________________________________ block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]              __________________________________________________________________________________________________ block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]           __________________________________________________________________________________________________ block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]         __________________________________________________________________________________________________ block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                 __________________________________________________________________________________________________ block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]           __________________________________________________________________________________________________ block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]             __________________________________________________________________________________________________ block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]          __________________________________________________________________________________________________ block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]              __________________________________________________________________________________________________ block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]           __________________________________________________________________________________________________ block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]         __________________________________________________________________________________________________ block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]           __________________________________________________________________________________________________ block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]             __________________________________________________________________________________________________ block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]                                                                           block_2_project_BN[0][0]          __________________________________________________________________________________________________ block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                 __________________________________________________________________________________________________ block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]              __________________________________________________________________________________________________ block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]           __________________________________________________________________________________________________ block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]         __________________________________________________________________________________________________ block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                 __________________________________________________________________________________________________ block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]           __________________________________________________________________________________________________ block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]             __________________________________________________________________________________________________ block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]          __________________________________________________________________________________________________ block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]              __________________________________________________________________________________________________ block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]           __________________________________________________________________________________________________ block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]         __________________________________________________________________________________________________ block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]           __________________________________________________________________________________________________ block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]             __________________________________________________________________________________________________ block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]                                                                           block_4_project_BN[0][0]          __________________________________________________________________________________________________ block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                 __________________________________________________________________________________________________ block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]              __________________________________________________________________________________________________ block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]           __________________________________________________________________________________________________ block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]         __________________________________________________________________________________________________ block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]           __________________________________________________________________________________________________ block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]             __________________________________________________________________________________________________ block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                                                                                  block_5_project_BN[0][0]          __________________________________________________________________________________________________ block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                 __________________________________________________________________________________________________ block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]              __________________________________________________________________________________________________ block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]           __________________________________________________________________________________________________ block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]         __________________________________________________________________________________________________ block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                 __________________________________________________________________________________________________ block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]           __________________________________________________________________________________________________ block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]             __________________________________________________________________________________________________ block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]          __________________________________________________________________________________________________ block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]              __________________________________________________________________________________________________ block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]           __________________________________________________________________________________________________ block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]         __________________________________________________________________________________________________ block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]           __________________________________________________________________________________________________ block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]             __________________________________________________________________________________________________ block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]                                                                           block_7_project_BN[0][0]          __________________________________________________________________________________________________ block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                 __________________________________________________________________________________________________ block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]              __________________________________________________________________________________________________ block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]           __________________________________________________________________________________________________ block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]         __________________________________________________________________________________________________ block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]           __________________________________________________________________________________________________ block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]             __________________________________________________________________________________________________ block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                                                                                  block_8_project_BN[0][0]          __________________________________________________________________________________________________ block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                 __________________________________________________________________________________________________ block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]              __________________________________________________________________________________________________ block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]           __________________________________________________________________________________________________ block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]         __________________________________________________________________________________________________ block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]           __________________________________________________________________________________________________ block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]             __________________________________________________________________________________________________ block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                                                                                  block_9_project_BN[0][0]          __________________________________________________________________________________________________ block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                 __________________________________________________________________________________________________ block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]             __________________________________________________________________________________________________ block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]          __________________________________________________________________________________________________ block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]        __________________________________________________________________________________________________ block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]          __________________________________________________________________________________________________ block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]            __________________________________________________________________________________________________ block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]         __________________________________________________________________________________________________ block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]             __________________________________________________________________________________________________ block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]          __________________________________________________________________________________________________ block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]        __________________________________________________________________________________________________ block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]          __________________________________________________________________________________________________ block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]            __________________________________________________________________________________________________ block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]                                                                          block_11_project_BN[0][0]         __________________________________________________________________________________________________ block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]                __________________________________________________________________________________________________ block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]             __________________________________________________________________________________________________ block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]          __________________________________________________________________________________________________ block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]        __________________________________________________________________________________________________ block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]          __________________________________________________________________________________________________ block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]            __________________________________________________________________________________________________ block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]                                                                                 block_12_project_BN[0][0]         __________________________________________________________________________________________________ block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]                __________________________________________________________________________________________________ block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]             __________________________________________________________________________________________________ block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]          __________________________________________________________________________________________________ block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]        __________________________________________________________________________________________________ block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]                __________________________________________________________________________________________________ block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]          __________________________________________________________________________________________________ block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]            __________________________________________________________________________________________________ block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]         __________________________________________________________________________________________________ block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]             __________________________________________________________________________________________________ block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]          __________________________________________________________________________________________________ block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]        __________________________________________________________________________________________________ block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]          __________________________________________________________________________________________________ block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]            __________________________________________________________________________________________________ block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]                                                                          block_14_project_BN[0][0]         __________________________________________________________________________________________________ block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]                __________________________________________________________________________________________________ block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]             __________________________________________________________________________________________________ block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]          __________________________________________________________________________________________________ block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]        __________________________________________________________________________________________________ block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]          __________________________________________________________________________________________________ block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]            __________________________________________________________________________________________________ block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]                                                                                 block_15_project_BN[0][0]         __________________________________________________________________________________________________ block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]                __________________________________________________________________________________________________ block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]             __________________________________________________________________________________________________ block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]          __________________________________________________________________________________________________ block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]        __________________________________________________________________________________________________ block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]          __________________________________________________________________________________________________ block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]            __________________________________________________________________________________________________ Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]         __________________________________________________________________________________________________ Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                      __________________________________________________________________________________________________ out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                   ================================================================================================== Total params: 2,257,984 Trainable params: 2,223,872 Non-trainable params: 34,112 ________________________________________________________________________________________________________________________________</pre><p>Since we are using the Mobilenet as a architecture with our custom dataset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel.layers):  <strong>#Line 5</strong><br>    layer.trainable=False                           <strong>#Line 6</strong><br>    print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre>input_1 Layer Shape(Input_Shape,Output Shape) : ( [(None, 224, 224, 3)] [(None, 224, 224, 3)] ) is Trainable: True No of Parameter : 0 Layer Number : 1 Layer Name : Conv1 Layer Shape(Input_Shape,Output Shape) : ( (None, 224, 224, 3) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 864 Layer Number : 2 Layer Name : bn_Conv1 Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 3 Layer Name : Conv1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 4 Layer Name : expanded_conv_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 288 Layer Number : 5 Layer Name : expanded_conv_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 6 Layer Name : expanded_conv_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 7 Layer Name : expanded_conv_project Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 16) ) is Trainable: True No of Parameter : 512 Layer Number : 8 Layer Name : expanded_conv_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 16) (None, 112, 112, 16) ) is Trainable: True No of Parameter : 64 Layer Number : 9 Layer Name : block_1_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 16) (None, 112, 112, 96) ) is Trainable: True No of Parameter : 1536 Layer Number : 10 Layer Name : block_1_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 96) (None, 112, 112, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 11 Layer Name : block_1_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 96) (None, 112, 112, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 12 Layer Name : block_1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 96) (None, 113, 113, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 13 Layer Name : block_1_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 113, 113, 96) (None, 56, 56, 96) ) is Trainable: True No of Parameter : 864 Layer Number : 14 Layer Name : block_1_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 96) (None, 56, 56, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 15 Layer Name : block_1_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 96) (None, 56, 56, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 16 Layer Name : block_1_project Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 96) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 2304 Layer Number : 17 Layer Name : block_1_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 96 Layer Number : 18 Layer Name : block_2_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 3456 Layer Number : 19 Layer Name : block_2_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 20 Layer Name : block_2_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 21 Layer Name : block_2_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 1296 Layer Number : 22 Layer Name : block_2_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 23 Layer Name : block_2_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 24 Layer Name : block_2_project Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 3456 Layer Number : 25 Layer Name : block_2_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 96 Layer Number : 26 Layer Name : block_2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 56, 56, 24), (None, 56, 56, 24)] (None, 56, 56, 24) ) is Trainable: True No of Parameter : 0 Layer Number : 27 Layer Name : block_3_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 3456 Layer Number : 28 Layer Name : block_3_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 29 Layer Name : block_3_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 30 Layer Name : block_3_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 57, 57, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 31 Layer Name : block_3_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 57, 57, 144) (None, 28, 28, 144) ) is Trainable: True No of Parameter : 1296 Layer Number : 32 Layer Name : block_3_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 144) (None, 28, 28, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 33 Layer Name : block_3_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 144) (None, 28, 28, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 34 Layer Name : block_3_project Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 144) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 4608 Layer Number : 35 Layer Name : block_3_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 36 Layer Name : block_4_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 37 Layer Name : block_4_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 38 Layer Name : block_4_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 39 Layer Name : block_4_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 40 Layer Name : block_4_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 41 Layer Name : block_4_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 42 Layer Name : block_4_project Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 6144 Layer Number : 43 Layer Name : block_4_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 44 Layer Name : block_4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 32), (None, 28, 28, 32)] (None, 28, 28, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 45 Layer Name : block_5_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 46 Layer Name : block_5_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 47 Layer Name : block_5_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 48 Layer Name : block_5_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 49 Layer Name : block_5_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 50 Layer Name : block_5_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 51 Layer Name : block_5_project Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 6144 Layer Number : 52 Layer Name : block_5_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 53 Layer Name : block_5_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 32), (None, 28, 28, 32)] (None, 28, 28, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 54 Layer Name : block_6_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 55 Layer Name : block_6_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 56 Layer Name : block_6_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 57 Layer Name : block_6_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 29, 29, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 58 Layer Name : block_6_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 29, 29, 192) (None, 14, 14, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 59 Layer Name : block_6_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 192) (None, 14, 14, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 60 Layer Name : block_6_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 192) (None, 14, 14, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 61 Layer Name : block_6_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 192) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 12288 Layer Number : 62 Layer Name : block_6_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 63 Layer Name : block_7_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 64 Layer Name : block_7_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 65 Layer Name : block_7_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 66 Layer Name : block_7_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 67 Layer Name : block_7_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 68 Layer Name : block_7_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 69 Layer Name : block_7_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 70 Layer Name : block_7_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 71 Layer Name : block_7_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 64), (None, 14, 14, 64)] (None, 14, 14, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 72 Layer Name : block_8_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 73 Layer Name : block_8_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 74 Layer Name : block_8_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 75 Layer Name : block_8_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 76 Layer Name : block_8_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 77 Layer Name : block_8_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 78 Layer Name : block_8_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 79 Layer Name : block_8_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 80 Layer Name : block_8_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 64), (None, 14, 14, 64)] (None, 14, 14, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 81 Layer Name : block_9_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 82 Layer Name : block_9_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 83 Layer Name : block_9_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 84 Layer Name : block_9_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 85 Layer Name : block_9_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 86 Layer Name : block_9_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 87 Layer Name : block_9_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 88 Layer Name : block_9_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 89 Layer Name : block_9_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 64), (None, 14, 14, 64)] (None, 14, 14, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 90 Layer Name : block_10_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 91 Layer Name : block_10_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 92 Layer Name : block_10_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 93 Layer Name : block_10_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 94 Layer Name : block_10_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 95 Layer Name : block_10_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 96 Layer Name : block_10_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 36864 Layer Number : 97 Layer Name : block_10_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 98 Layer Name : block_11_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 99 Layer Name : block_11_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 100 Layer Name : block_11_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 101 Layer Name : block_11_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 102 Layer Name : block_11_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 103 Layer Name : block_11_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 104 Layer Name : block_11_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 55296 Layer Number : 105 Layer Name : block_11_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 106 Layer Name : block_11_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 96), (None, 14, 14, 96)] (None, 14, 14, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 107 Layer Name : block_12_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 108 Layer Name : block_12_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 109 Layer Name : block_12_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 110 Layer Name : block_12_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 111 Layer Name : block_12_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 112 Layer Name : block_12_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 113 Layer Name : block_12_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 55296 Layer Number : 114 Layer Name : block_12_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 115 Layer Name : block_12_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 96), (None, 14, 14, 96)] (None, 14, 14, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 116 Layer Name : block_13_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 117 Layer Name : block_13_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 118 Layer Name : block_13_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 119 Layer Name : block_13_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 15, 15, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 120 Layer Name : block_13_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 15, 15, 576) (None, 7, 7, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 121 Layer Name : block_13_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 576) (None, 7, 7, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 122 Layer Name : block_13_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 576) (None, 7, 7, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 123 Layer Name : block_13_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 576) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 92160 Layer Number : 124 Layer Name : block_13_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 125 Layer Name : block_14_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 126 Layer Name : block_14_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 127 Layer Name : block_14_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 128 Layer Name : block_14_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 129 Layer Name : block_14_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 130 Layer Name : block_14_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 131 Layer Name : block_14_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 153600 Layer Number : 132 Layer Name : block_14_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 133 Layer Name : block_14_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 160), (None, 7, 7, 160)] (None, 7, 7, 160) ) is Trainable: True No of Parameter : 0 Layer Number : 134 Layer Name : block_15_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 135 Layer Name : block_15_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 136 Layer Name : block_15_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 137 Layer Name : block_15_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 138 Layer Name : block_15_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 139 Layer Name : block_15_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 140 Layer Name : block_15_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 153600 Layer Number : 141 Layer Name : block_15_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 142 Layer Name : block_15_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 160), (None, 7, 7, 160)] (None, 7, 7, 160) ) is Trainable: True No of Parameter : 0 Layer Number : 143 Layer Name : block_16_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 144 Layer Name : block_16_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 145 Layer Name : block_16_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 146 Layer Name : block_16_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 147 Layer Name : block_16_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 148 Layer Name : block_16_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 149 Layer Name : block_16_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 320) ) is Trainable: True No of Parameter : 307200 Layer Number : 150 Layer Name : block_16_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 320) (None, 7, 7, 320) ) is Trainable: True No of Parameter : 1280 Layer Number : 151 Layer Name : Conv_1 Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 320) (None, 7, 7, 1280) ) is Trainable: True No of Parameter : 409600 Layer Number : 152 Layer Name : Conv_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 1280) (None, 7, 7, 1280) ) is Trainable: True No of Parameter : 5120 Layer Number : 153 Layer Name : out_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 1280) (None, 7, 7, 1280) ) is Trainable: True No of Parameter : 0 Layer Number : 154 Layer Name : global_average_pooling2d Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 1280) (None, 1280) ) is Trainable: True No of Parameter : 0 Layer Number : 155 Layer Name : predictions Layer Shape(Input_Shape,Output Shape) : ( (None, 1280) (None, 1000) ) is Trainable: True No of Parameter : 1281000</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 8<br></strong>baseModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[‘accuracy’]) <strong>#Line 9</strong></pre><p><strong>Line 8</strong> : We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 9</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we have to predict i.e. get the feature from the model which is shown as below:</p><pre>Features_train= baseModel.predict(trainX) <strong>#Line 10</strong></pre><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1,2048) and for the training set it will be of (50000,1,1,2048), for test set it will be of (10000,1,1,2048) size.</em></p><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><h3>2.3. Fine tunning Pre-trained models Mobilenet architecture.</h3><p>In this section we will see how we can implement Mobilenet as a architecture in Keras. We will use state of the art Mobilenet network architecture with weight i.e. weights of the pre-trained model will be freezed i.e. error will not be propagated backward to these layers whereas custom fully connected layers will we optimised according to our dataset i.e. they will be trainable.The code is explained below:</p><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2<br></strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3<br></strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong>for i in range(9):<strong>#Line 5<br></strong># define subplotpyplot.subplot(330 + 1 + i)  <strong>#Line 6<br></strong># plot raw pixel data<br>    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7<br>    </strong># show the figure<br>    pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: </strong>These code snippets are used to display the samples from the dataset as shown below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/0*QPC8OwvcQz84jn5A.png" /></figure><p>Figure 2. Sample CIFDAR-10 dataset</p><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9<br></strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.3.2. Mobilenet Fine Tunning Dense Layer</h3><p>In this section we will see how we can implement Mobilenet as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong>baseModel = tf.keras.applications.MobileNetV2(include_top=False,weights=&#39;imagenet&#39;,input_tensor=image_input)<strong>#Line 3</strong></pre><pre>baseModel.summary() <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained Mobilenet with no weight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False,</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the Mobilenet model which will be used to extract feature from the image shown below.</p><pre>Downloading data from <a href="https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5">https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5</a> 9412608/9406464 [==============================] - 0s 0us/step 9420800/9406464 [==============================] - 0s 0us/step</pre><pre>Model: &quot;mobilenetv2_1.00_224&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ Conv1 (Conv2D)                  (None, 16, 16, 32)   864         input_3[0][0]                     __________________________________________________________________________________________________ bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                       __________________________________________________________________________________________________ Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                    __________________________________________________________________________________________________ expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                  __________________________________________________________________________________________________ expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]     __________________________________________________________________________________________________ expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0]  __________________________________________________________________________________________________ expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0 __________________________________________________________________________________________________ expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]       __________________________________________________________________________________________________ block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]    __________________________________________________________________________________________________ block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]              __________________________________________________________________________________________________ block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]           __________________________________________________________________________________________________ block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]         __________________________________________________________________________________________________ block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                 __________________________________________________________________________________________________ block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]           __________________________________________________________________________________________________ block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]             __________________________________________________________________________________________________ block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]          __________________________________________________________________________________________________ block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]              __________________________________________________________________________________________________ block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]           __________________________________________________________________________________________________ block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]         __________________________________________________________________________________________________ block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]           __________________________________________________________________________________________________ block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]             __________________________________________________________________________________________________ block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]                                                                           block_2_project_BN[0][0]          __________________________________________________________________________________________________ block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                 __________________________________________________________________________________________________ block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]              __________________________________________________________________________________________________ block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]           __________________________________________________________________________________________________ block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]         __________________________________________________________________________________________________ block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                 __________________________________________________________________________________________________ block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]           __________________________________________________________________________________________________ block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]             __________________________________________________________________________________________________ block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]          __________________________________________________________________________________________________ block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]              __________________________________________________________________________________________________ block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]           __________________________________________________________________________________________________ block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]         __________________________________________________________________________________________________ block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]           __________________________________________________________________________________________________ block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]             __________________________________________________________________________________________________ block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]                                                                           block_4_project_BN[0][0]          __________________________________________________________________________________________________ block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                 __________________________________________________________________________________________________ block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]              __________________________________________________________________________________________________ block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]           __________________________________________________________________________________________________ block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]         __________________________________________________________________________________________________ block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]           __________________________________________________________________________________________________ block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]             __________________________________________________________________________________________________ block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                                                                                  block_5_project_BN[0][0]          __________________________________________________________________________________________________ block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                 __________________________________________________________________________________________________ block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]              __________________________________________________________________________________________________ block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]           __________________________________________________________________________________________________ block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]         __________________________________________________________________________________________________ block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                 __________________________________________________________________________________________________ block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]           __________________________________________________________________________________________________ block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]             __________________________________________________________________________________________________ block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]          __________________________________________________________________________________________________ block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]              __________________________________________________________________________________________________ block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]           __________________________________________________________________________________________________ block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]         __________________________________________________________________________________________________ block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]           __________________________________________________________________________________________________ block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]             __________________________________________________________________________________________________ block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]                                                                           block_7_project_BN[0][0]          __________________________________________________________________________________________________ block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                 __________________________________________________________________________________________________ block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]              __________________________________________________________________________________________________ block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]           __________________________________________________________________________________________________ block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]         __________________________________________________________________________________________________ block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]           __________________________________________________________________________________________________ block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]             __________________________________________________________________________________________________ block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                                                                                  block_8_project_BN[0][0]          __________________________________________________________________________________________________ block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                 __________________________________________________________________________________________________ block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]              __________________________________________________________________________________________________ block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]           __________________________________________________________________________________________________ block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]         __________________________________________________________________________________________________ block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]           __________________________________________________________________________________________________ block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]             __________________________________________________________________________________________________ block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                                                                                  block_9_project_BN[0][0]          __________________________________________________________________________________________________ block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                 __________________________________________________________________________________________________ block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]             __________________________________________________________________________________________________ block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]          __________________________________________________________________________________________________ block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]        __________________________________________________________________________________________________ block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]          __________________________________________________________________________________________________ block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]            __________________________________________________________________________________________________ block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]         __________________________________________________________________________________________________ block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]             __________________________________________________________________________________________________ block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]          __________________________________________________________________________________________________ block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]        __________________________________________________________________________________________________ block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]          __________________________________________________________________________________________________ block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]            __________________________________________________________________________________________________ block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]                                                                          block_11_project_BN[0][0]         __________________________________________________________________________________________________ block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]                __________________________________________________________________________________________________ block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]             __________________________________________________________________________________________________ block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]          __________________________________________________________________________________________________ block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]        __________________________________________________________________________________________________ block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]          __________________________________________________________________________________________________ block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]            __________________________________________________________________________________________________ block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]                                                                                 block_12_project_BN[0][0]         __________________________________________________________________________________________________ block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]                __________________________________________________________________________________________________ block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]             __________________________________________________________________________________________________ block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]          __________________________________________________________________________________________________ block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]        __________________________________________________________________________________________________ block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]                __________________________________________________________________________________________________ block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]          __________________________________________________________________________________________________ block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]            __________________________________________________________________________________________________ block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]         __________________________________________________________________________________________________ block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]             __________________________________________________________________________________________________ block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]          __________________________________________________________________________________________________ block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]        __________________________________________________________________________________________________ block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]          __________________________________________________________________________________________________ block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]            __________________________________________________________________________________________________ block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]                                                                          block_14_project_BN[0][0]         __________________________________________________________________________________________________ block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]                __________________________________________________________________________________________________ block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]             __________________________________________________________________________________________________ block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]          __________________________________________________________________________________________________ block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]        __________________________________________________________________________________________________ block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]          __________________________________________________________________________________________________ block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]            __________________________________________________________________________________________________ block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]                                                                                 block_15_project_BN[0][0]         __________________________________________________________________________________________________ block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]                __________________________________________________________________________________________________ block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]             __________________________________________________________________________________________________ block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]          __________________________________________________________________________________________________ block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]        __________________________________________________________________________________________________ block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]          __________________________________________________________________________________________________ block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]            __________________________________________________________________________________________________ Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]         __________________________________________________________________________________________________ Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                      __________________________________________________________________________________________________ out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                   ================================================================================================== Total params: 2,257,984 Trainable params: 2,223,872 Non-trainable params: 34,112 __________________________________________________________________________________________________</pre><p>Since we are using the Mobilenet as a architecture with our custom dataset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel.layers):  <strong>#Line 5<br>  </strong>layer.trainable=False                           <strong>#Line 6<br>  </strong>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre>Layer Number : 0 Layer Name : input_4 Layer Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: True No of Parameter : 0 Layer Number : 1 Layer Name : Conv1 Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 16, 16, 32) ) is Trainable: True No of Parameter : 864 Layer Number : 2 Layer Name : bn_Conv1 Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 32) (None, 16, 16, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 3 Layer Name : Conv1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 32) (None, 16, 16, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 4 Layer Name : expanded_conv_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 32) (None, 16, 16, 32) ) is Trainable: True No of Parameter : 288 Layer Number : 5 Layer Name : expanded_conv_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 32) (None, 16, 16, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 6 Layer Name : expanded_conv_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 32) (None, 16, 16, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 7 Layer Name : expanded_conv_project Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 32) (None, 16, 16, 16) ) is Trainable: True No of Parameter : 512 Layer Number : 8 Layer Name : expanded_conv_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 16) (None, 16, 16, 16) ) is Trainable: True No of Parameter : 64 Layer Number : 9 Layer Name : block_1_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 16) (None, 16, 16, 96) ) is Trainable: True No of Parameter : 1536 Layer Number : 10 Layer Name : block_1_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 96) (None, 16, 16, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 11 Layer Name : block_1_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 96) (None, 16, 16, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 12 Layer Name : block_1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 96) (None, 17, 17, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 13 Layer Name : block_1_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 17, 17, 96) (None, 8, 8, 96) ) is Trainable: True No of Parameter : 864 Layer Number : 14 Layer Name : block_1_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 96) (None, 8, 8, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 15 Layer Name : block_1_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 96) (None, 8, 8, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 16 Layer Name : block_1_project Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 96) (None, 8, 8, 24) ) is Trainable: True No of Parameter : 2304 Layer Number : 17 Layer Name : block_1_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 24) (None, 8, 8, 24) ) is Trainable: True No of Parameter : 96 Layer Number : 18 Layer Name : block_2_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 24) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 3456 Layer Number : 19 Layer Name : block_2_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 20 Layer Name : block_2_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 21 Layer Name : block_2_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 1296 Layer Number : 22 Layer Name : block_2_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 23 Layer Name : block_2_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 24 Layer Name : block_2_project Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 24) ) is Trainable: True No of Parameter : 3456 Layer Number : 25 Layer Name : block_2_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 24) (None, 8, 8, 24) ) is Trainable: True No of Parameter : 96 Layer Number : 26 Layer Name : block_2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 24), (None, 8, 8, 24)] (None, 8, 8, 24) ) is Trainable: True No of Parameter : 0 Layer Number : 27 Layer Name : block_3_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 24) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 3456 Layer Number : 28 Layer Name : block_3_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 29 Layer Name : block_3_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 8, 8, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 30 Layer Name : block_3_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 144) (None, 9, 9, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 31 Layer Name : block_3_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 9, 9, 144) (None, 4, 4, 144) ) is Trainable: True No of Parameter : 1296 Layer Number : 32 Layer Name : block_3_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 144) (None, 4, 4, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 33 Layer Name : block_3_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 144) (None, 4, 4, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 34 Layer Name : block_3_project Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 144) (None, 4, 4, 32) ) is Trainable: True No of Parameter : 4608 Layer Number : 35 Layer Name : block_3_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 32) (None, 4, 4, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 36 Layer Name : block_4_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 32) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 37 Layer Name : block_4_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 38 Layer Name : block_4_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 39 Layer Name : block_4_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 40 Layer Name : block_4_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 41 Layer Name : block_4_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 42 Layer Name : block_4_project Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 32) ) is Trainable: True No of Parameter : 6144 Layer Number : 43 Layer Name : block_4_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 32) (None, 4, 4, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 44 Layer Name : block_4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 32), (None, 4, 4, 32)] (None, 4, 4, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 45 Layer Name : block_5_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 32) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 46 Layer Name : block_5_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 47 Layer Name : block_5_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 48 Layer Name : block_5_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 49 Layer Name : block_5_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 50 Layer Name : block_5_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 51 Layer Name : block_5_project Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 32) ) is Trainable: True No of Parameter : 6144 Layer Number : 52 Layer Name : block_5_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 32) (None, 4, 4, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 53 Layer Name : block_5_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 32), (None, 4, 4, 32)] (None, 4, 4, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 54 Layer Name : block_6_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 32) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 55 Layer Name : block_6_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 56 Layer Name : block_6_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 4, 4, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 57 Layer Name : block_6_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 192) (None, 5, 5, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 58 Layer Name : block_6_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 5, 5, 192) (None, 2, 2, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 59 Layer Name : block_6_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 192) (None, 2, 2, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 60 Layer Name : block_6_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 192) (None, 2, 2, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 61 Layer Name : block_6_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 192) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 12288 Layer Number : 62 Layer Name : block_6_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 63 Layer Name : block_7_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 64 Layer Name : block_7_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 65 Layer Name : block_7_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 66 Layer Name : block_7_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 67 Layer Name : block_7_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 68 Layer Name : block_7_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 69 Layer Name : block_7_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 70 Layer Name : block_7_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 71 Layer Name : block_7_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 64), (None, 2, 2, 64)] (None, 2, 2, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 72 Layer Name : block_8_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 73 Layer Name : block_8_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 74 Layer Name : block_8_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 75 Layer Name : block_8_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 76 Layer Name : block_8_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 77 Layer Name : block_8_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 78 Layer Name : block_8_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 79 Layer Name : block_8_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 80 Layer Name : block_8_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 64), (None, 2, 2, 64)] (None, 2, 2, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 81 Layer Name : block_9_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 82 Layer Name : block_9_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 83 Layer Name : block_9_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 84 Layer Name : block_9_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 85 Layer Name : block_9_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 86 Layer Name : block_9_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 87 Layer Name : block_9_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 88 Layer Name : block_9_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 89 Layer Name : block_9_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 64), (None, 2, 2, 64)] (None, 2, 2, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 90 Layer Name : block_10_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 64) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 91 Layer Name : block_10_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 92 Layer Name : block_10_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 93 Layer Name : block_10_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 94 Layer Name : block_10_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 95 Layer Name : block_10_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 96 Layer Name : block_10_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 384) (None, 2, 2, 96) ) is Trainable: True No of Parameter : 36864 Layer Number : 97 Layer Name : block_10_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 96) (None, 2, 2, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 98 Layer Name : block_11_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 96) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 99 Layer Name : block_11_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 100 Layer Name : block_11_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 101 Layer Name : block_11_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 102 Layer Name : block_11_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 103 Layer Name : block_11_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 104 Layer Name : block_11_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 96) ) is Trainable: True No of Parameter : 55296 Layer Number : 105 Layer Name : block_11_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 96) (None, 2, 2, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 106 Layer Name : block_11_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 96), (None, 2, 2, 96)] (None, 2, 2, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 107 Layer Name : block_12_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 96) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 108 Layer Name : block_12_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 109 Layer Name : block_12_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 110 Layer Name : block_12_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 111 Layer Name : block_12_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 112 Layer Name : block_12_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 113 Layer Name : block_12_project Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 96) ) is Trainable: True No of Parameter : 55296 Layer Number : 114 Layer Name : block_12_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 96) (None, 2, 2, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 115 Layer Name : block_12_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 96), (None, 2, 2, 96)] (None, 2, 2, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 116 Layer Name : block_13_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 96) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 117 Layer Name : block_13_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 118 Layer Name : block_13_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 2, 2, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 119 Layer Name : block_13_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 576) (None, 3, 3, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 120 Layer Name : block_13_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 3, 3, 576) (None, 1, 1, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 121 Layer Name : block_13_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 576) (None, 1, 1, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 122 Layer Name : block_13_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 576) (None, 1, 1, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 123 Layer Name : block_13_project Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 576) (None, 1, 1, 160) ) is Trainable: True No of Parameter : 92160 Layer Number : 124 Layer Name : block_13_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 160) (None, 1, 1, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 125 Layer Name : block_14_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 160) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 126 Layer Name : block_14_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 127 Layer Name : block_14_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 128 Layer Name : block_14_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 129 Layer Name : block_14_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 130 Layer Name : block_14_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 131 Layer Name : block_14_project Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 160) ) is Trainable: True No of Parameter : 153600 Layer Number : 132 Layer Name : block_14_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 160) (None, 1, 1, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 133 Layer Name : block_14_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 160), (None, 1, 1, 160)] (None, 1, 1, 160) ) is Trainable: True No of Parameter : 0 Layer Number : 134 Layer Name : block_15_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 160) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 135 Layer Name : block_15_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 136 Layer Name : block_15_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 137 Layer Name : block_15_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 138 Layer Name : block_15_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 139 Layer Name : block_15_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 140 Layer Name : block_15_project Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 160) ) is Trainable: True No of Parameter : 153600 Layer Number : 141 Layer Name : block_15_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 160) (None, 1, 1, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 142 Layer Name : block_15_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 160), (None, 1, 1, 160)] (None, 1, 1, 160) ) is Trainable: True No of Parameter : 0 Layer Number : 143 Layer Name : block_16_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 160) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 144 Layer Name : block_16_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 145 Layer Name : block_16_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 146 Layer Name : block_16_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 147 Layer Name : block_16_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 148 Layer Name : block_16_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 149 Layer Name : block_16_project Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 960) (None, 1, 1, 320) ) is Trainable: True No of Parameter : 307200 Layer Number : 150 Layer Name : block_16_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 320) (None, 1, 1, 320) ) is Trainable: True No of Parameter : 1280 Layer Number : 151 Layer Name : Conv_1 Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 320) (None, 1, 1, 1280) ) is Trainable: True No of Parameter : 409600 Layer Number : 152 Layer Name : Conv_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 1280) (None, 1, 1, 1280) ) is Trainable: True No of Parameter : 5120 Layer Number : 153 Layer Name : out_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 1280) (None, 1, 1, 1280) ) is Trainable: True No of Parameter : 0</pre><p>Since we are using the Mobilenet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel.output)        <strong>#Line 5<br></strong>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8<br></strong>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9<br></strong>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the Mobilenet network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has Mobilenet architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model_1&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ Conv1 (Conv2D)                  (None, 16, 16, 32)   864         input_3[0][0]                     __________________________________________________________________________________________________ bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                       __________________________________________________________________________________________________ Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                    __________________________________________________________________________________________________ expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                  __________________________________________________________________________________________________ expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]     __________________________________________________________________________________________________ expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0]  __________________________________________________________________________________________________ expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0 __________________________________________________________________________________________________ expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]       __________________________________________________________________________________________________ block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]    __________________________________________________________________________________________________ block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]              __________________________________________________________________________________________________ block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]           __________________________________________________________________________________________________ block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]         __________________________________________________________________________________________________ block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                 __________________________________________________________________________________________________ block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]           __________________________________________________________________________________________________ block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]             __________________________________________________________________________________________________ block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]          __________________________________________________________________________________________________ block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]              __________________________________________________________________________________________________ block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]           __________________________________________________________________________________________________ block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]         __________________________________________________________________________________________________ block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]           __________________________________________________________________________________________________ block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]             __________________________________________________________________________________________________ block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]                                                                           block_2_project_BN[0][0]          __________________________________________________________________________________________________ block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                 __________________________________________________________________________________________________ block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]              __________________________________________________________________________________________________ block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]           __________________________________________________________________________________________________ block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]         __________________________________________________________________________________________________ block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                 __________________________________________________________________________________________________ block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]           __________________________________________________________________________________________________ block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]             __________________________________________________________________________________________________ block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]          __________________________________________________________________________________________________ block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]              __________________________________________________________________________________________________ block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]           __________________________________________________________________________________________________ block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]         __________________________________________________________________________________________________ block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]           __________________________________________________________________________________________________ block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]             __________________________________________________________________________________________________ block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]                                                                           block_4_project_BN[0][0]          __________________________________________________________________________________________________ block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                 __________________________________________________________________________________________________ block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]              __________________________________________________________________________________________________ block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]           __________________________________________________________________________________________________ block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]         __________________________________________________________________________________________________ block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]           __________________________________________________________________________________________________ block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]             __________________________________________________________________________________________________ block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                                                                                  block_5_project_BN[0][0]          __________________________________________________________________________________________________ block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                 __________________________________________________________________________________________________ block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]              __________________________________________________________________________________________________ block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]           __________________________________________________________________________________________________ block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]         __________________________________________________________________________________________________ block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                 __________________________________________________________________________________________________ block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]           __________________________________________________________________________________________________ block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]             __________________________________________________________________________________________________ block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]          __________________________________________________________________________________________________ block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]              __________________________________________________________________________________________________ block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]           __________________________________________________________________________________________________ block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]         __________________________________________________________________________________________________ block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]           __________________________________________________________________________________________________ block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]             __________________________________________________________________________________________________ block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]                                                                           block_7_project_BN[0][0]          __________________________________________________________________________________________________ block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                 __________________________________________________________________________________________________ block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]              __________________________________________________________________________________________________ block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]           __________________________________________________________________________________________________ block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]         __________________________________________________________________________________________________ block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]           __________________________________________________________________________________________________ block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]             __________________________________________________________________________________________________ block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                                                                                  block_8_project_BN[0][0]          __________________________________________________________________________________________________ block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                 __________________________________________________________________________________________________ block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]              __________________________________________________________________________________________________ block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]           __________________________________________________________________________________________________ block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]         __________________________________________________________________________________________________ block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]           __________________________________________________________________________________________________ block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]             __________________________________________________________________________________________________ block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                                                                                  block_9_project_BN[0][0]          __________________________________________________________________________________________________ block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                 __________________________________________________________________________________________________ block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]             __________________________________________________________________________________________________ block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]          __________________________________________________________________________________________________ block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]        __________________________________________________________________________________________________ block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]          __________________________________________________________________________________________________ block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]            __________________________________________________________________________________________________ block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]         __________________________________________________________________________________________________ block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]             __________________________________________________________________________________________________ block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]          __________________________________________________________________________________________________ block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]        __________________________________________________________________________________________________ block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]          __________________________________________________________________________________________________ block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]            __________________________________________________________________________________________________ block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]                                                                          block_11_project_BN[0][0]         __________________________________________________________________________________________________ block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]                __________________________________________________________________________________________________ block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]             __________________________________________________________________________________________________ block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]          __________________________________________________________________________________________________ block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]        __________________________________________________________________________________________________ block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]          __________________________________________________________________________________________________ block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]            __________________________________________________________________________________________________ block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]                                                                                 block_12_project_BN[0][0]         __________________________________________________________________________________________________ block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]                __________________________________________________________________________________________________ block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]             __________________________________________________________________________________________________ block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]          __________________________________________________________________________________________________ block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]        __________________________________________________________________________________________________ block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]                __________________________________________________________________________________________________ block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]          __________________________________________________________________________________________________ block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]            __________________________________________________________________________________________________ block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]         __________________________________________________________________________________________________ block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]             __________________________________________________________________________________________________ block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]          __________________________________________________________________________________________________ block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]        __________________________________________________________________________________________________ block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]          __________________________________________________________________________________________________ block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]            __________________________________________________________________________________________________ block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]                                                                          block_14_project_BN[0][0]         __________________________________________________________________________________________________ block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]                __________________________________________________________________________________________________ block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]             __________________________________________________________________________________________________ block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]          __________________________________________________________________________________________________ block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]        __________________________________________________________________________________________________ block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]          __________________________________________________________________________________________________ block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]            __________________________________________________________________________________________________ block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]                                                                                 block_15_project_BN[0][0]         __________________________________________________________________________________________________ block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]                __________________________________________________________________________________________________ block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]             __________________________________________________________________________________________________ block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]          __________________________________________________________________________________________________ block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]        __________________________________________________________________________________________________ block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]          __________________________________________________________________________________________________ block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]            __________________________________________________________________________________________________ Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]         __________________________________________________________________________________________________ Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                      __________________________________________________________________________________________________ out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                   __________________________________________________________________________________________________ flatten_1 (Flatten)             (None, 1280)         0           out_relu[0][0]                    __________________________________________________________________________________________________ dense_6 (Dense)                 (None, 1000)         1281000     flatten_1[0][0]                   __________________________________________________________________________________________________ dense_7 (Dense)                 (None, 800)          800800      dense_6[0][0]                     __________________________________________________________________________________________________ dense_8 (Dense)                 (None, 400)          320400      dense_7[0][0]                     __________________________________________________________________________________________________ dense_9 (Dense)                 (None, 200)          80200       dense_8[0][0]                     __________________________________________________________________________________________________ dense_10 (Dense)                (None, 100)          20100       dense_9[0][0]                     __________________________________________________________________________________________________ dense_11 (Dense)                (None, 10)           1010        dense_10[0][0]                    ================================================================================================== Total params: 4,761,494 Trainable params: 4,727,382 Non-trainable params: 34,112 __________________________________________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13<br></strong>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following snippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong>prediction=model_final.predict(testX)<strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><p><strong>Note:</strong> In this section we have set the parameter of the Mobilenet to false i.e. the loss will not backward propagated throught these layers where as the fully connected layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h3>2.4. Using Mobilenet weight initialisers</h3><p>In this section we will use Mobilenet network as a initialiser. In Mobilenet architecture the model is trained on the ImageNet dataset and has acquired so we will instantiate Mobilenet architecture with Mobilenet layer weights and set it to trainable i.e. the loss will be backward propagated along with that we will add our custom fully classifying layer will will also be trainable. So in short we are using weights of the Mobilenet architechture to initialize our model and train the whole neural network from scratch.</p><p><strong>2.4.1. Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()      <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2<br></strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3<br></strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5<br></strong># define subplotpyplot.subplot(330 + 1 + i)  <strong>#Line 6<br></strong># plot raw pixel data<br>    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7<br>    </strong># show the figure<br>    pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: </strong>These code snippets are used to display the samples from the dataset as shown below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/0*6Ezb4lp07CwnrH8V.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9<br></strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.3.2. Mobilenet Architechture Implementation</h3><p>In this section we will see how we can implement Mobilenet as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel=tf.keras.applications.MobileNetV2(include_top=False,<br>weights=&#39;imagent&#39;,input_tensor=image_input)baseModel.summary()      <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained Mobilenet with no weight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the Mobilenet model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;model&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ Conv1 (Conv2D)                  (None, 16, 16, 32)   864         input_2[0][0]                     __________________________________________________________________________________________________ bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                       __________________________________________________________________________________________________ Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                    __________________________________________________________________________________________________ expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                  __________________________________________________________________________________________________ expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]     __________________________________________________________________________________________________ expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0]  __________________________________________________________________________________________________ expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0 __________________________________________________________________________________________________ expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]       __________________________________________________________________________________________________ block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]    __________________________________________________________________________________________________ block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]              __________________________________________________________________________________________________ block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]           __________________________________________________________________________________________________ block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]         __________________________________________________________________________________________________ block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                 __________________________________________________________________________________________________ block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]           __________________________________________________________________________________________________ block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]             __________________________________________________________________________________________________ block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]          __________________________________________________________________________________________________ block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]              __________________________________________________________________________________________________ block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]           __________________________________________________________________________________________________ block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]         __________________________________________________________________________________________________ block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]           __________________________________________________________________________________________________ block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]             __________________________________________________________________________________________________ block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]                                                                           block_2_project_BN[0][0]          __________________________________________________________________________________________________ block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                 __________________________________________________________________________________________________ block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]              __________________________________________________________________________________________________ block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]           __________________________________________________________________________________________________ block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]         __________________________________________________________________________________________________ block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                 __________________________________________________________________________________________________ block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]           __________________________________________________________________________________________________ block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]             __________________________________________________________________________________________________ block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]          __________________________________________________________________________________________________ block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]              __________________________________________________________________________________________________ block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]           __________________________________________________________________________________________________ block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]         __________________________________________________________________________________________________ block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]           __________________________________________________________________________________________________ block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]             __________________________________________________________________________________________________ block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]                                                                           block_4_project_BN[0][0]          __________________________________________________________________________________________________ block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                 __________________________________________________________________________________________________ block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]              __________________________________________________________________________________________________ block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]           __________________________________________________________________________________________________ block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]         __________________________________________________________________________________________________ block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]           __________________________________________________________________________________________________ block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]             __________________________________________________________________________________________________ block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                                                                                  block_5_project_BN[0][0]          __________________________________________________________________________________________________ block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                 __________________________________________________________________________________________________ block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]              __________________________________________________________________________________________________ block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]           __________________________________________________________________________________________________ block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]         __________________________________________________________________________________________________ block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                 __________________________________________________________________________________________________ block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]           __________________________________________________________________________________________________ block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]             __________________________________________________________________________________________________ block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]          __________________________________________________________________________________________________ block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]              __________________________________________________________________________________________________ block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]           __________________________________________________________________________________________________ block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]         __________________________________________________________________________________________________ block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]           __________________________________________________________________________________________________ block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]             __________________________________________________________________________________________________ block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]                                                                           block_7_project_BN[0][0]          __________________________________________________________________________________________________ block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                 __________________________________________________________________________________________________ block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]              __________________________________________________________________________________________________ block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]           __________________________________________________________________________________________________ block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]         __________________________________________________________________________________________________ block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]           __________________________________________________________________________________________________ block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]             __________________________________________________________________________________________________ block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                                                                                  block_8_project_BN[0][0]          __________________________________________________________________________________________________ block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                 __________________________________________________________________________________________________ block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]              __________________________________________________________________________________________________ block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]           __________________________________________________________________________________________________ block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]         __________________________________________________________________________________________________ block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]           __________________________________________________________________________________________________ block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]        __________________________________________________________________________________________________ block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]      __________________________________________________________________________________________________ block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]             __________________________________________________________________________________________________ block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                                                                                  block_9_project_BN[0][0]          __________________________________________________________________________________________________ block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                 __________________________________________________________________________________________________ block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]             __________________________________________________________________________________________________ block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]          __________________________________________________________________________________________________ block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]        __________________________________________________________________________________________________ block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]          __________________________________________________________________________________________________ block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]            __________________________________________________________________________________________________ block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]         __________________________________________________________________________________________________ block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]             __________________________________________________________________________________________________ block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]          __________________________________________________________________________________________________ block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]        __________________________________________________________________________________________________ block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]          __________________________________________________________________________________________________ block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]            __________________________________________________________________________________________________ block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]                                                                          block_11_project_BN[0][0]         __________________________________________________________________________________________________ block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]                __________________________________________________________________________________________________ block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]             __________________________________________________________________________________________________ block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]          __________________________________________________________________________________________________ block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]        __________________________________________________________________________________________________ block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]          __________________________________________________________________________________________________ block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]            __________________________________________________________________________________________________ block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]                                                                                 block_12_project_BN[0][0]         __________________________________________________________________________________________________ block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]                __________________________________________________________________________________________________ block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]             __________________________________________________________________________________________________ block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]          __________________________________________________________________________________________________ block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]        __________________________________________________________________________________________________ block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]                __________________________________________________________________________________________________ block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]          __________________________________________________________________________________________________ block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]            __________________________________________________________________________________________________ block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]         __________________________________________________________________________________________________ block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]             __________________________________________________________________________________________________ block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]          __________________________________________________________________________________________________ block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]        __________________________________________________________________________________________________ block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]          __________________________________________________________________________________________________ block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]            __________________________________________________________________________________________________ block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]                                                                          block_14_project_BN[0][0]         __________________________________________________________________________________________________ block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]                __________________________________________________________________________________________________ block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]             __________________________________________________________________________________________________ block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]          __________________________________________________________________________________________________ block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]        __________________________________________________________________________________________________ block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]          __________________________________________________________________________________________________ block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]            __________________________________________________________________________________________________ block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]                                                                                 block_15_project_BN[0][0]         __________________________________________________________________________________________________ block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]                __________________________________________________________________________________________________ block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]             __________________________________________________________________________________________________ block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]          __________________________________________________________________________________________________ block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]        __________________________________________________________________________________________________ block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]          __________________________________________________________________________________________________ block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]       __________________________________________________________________________________________________ block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]     __________________________________________________________________________________________________ block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]            __________________________________________________________________________________________________ Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]         __________________________________________________________________________________________________ Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                      __________________________________________________________________________________________________ out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                   __________________________________________________________________________________________________ flatten (Flatten)               (None, 1280)         0           out_relu[0][0]                    __________________________________________________________________________________________________ dense (Dense)                   (None, 1000)         1281000     flatten[0][0]                     __________________________________________________________________________________________________ dense_1 (Dense)                 (None, 800)          800800      dense[0][0]                       __________________________________________________________________________________________________ dense_2 (Dense)                 (None, 400)          320400      dense_1[0][0]                     __________________________________________________________________________________________________ dense_3 (Dense)                 (None, 200)          80200       dense_2[0][0]                     __________________________________________________________________________________________________ dense_4 (Dense)                 (None, 100)          20100       dense_3[0][0]                     __________________________________________________________________________________________________ dense_5 (Dense)                 (None, 10)           1010        dense_4[0][0]                     ================================================================================================== Total params: 4,761,494 Trainable params: 4,727,382 Non-trainable params: 34,112 __________________________________________________________________________________________________</pre><p>Since we are using the Mobilenet as a architecture with our custom dataset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will activate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel.layers):        <strong>#Line 5<br>    </strong>layer.trainable=True                           <strong>#Line 6<br>    </strong>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=True</em>.</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre>Layer Number : 0 Layer Name : input_1 Layer Shape(Input_Shape,Output Shape) : ( [(None, 224, 224, 3)] [(None, 224, 224, 3)] ) is Trainable: True No of Parameter : 0 Layer Number : 1 Layer Name : Conv1 Layer Shape(Input_Shape,Output Shape) : ( (None, 224, 224, 3) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 864 Layer Number : 2 Layer Name : bn_Conv1 Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 3 Layer Name : Conv1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 4 Layer Name : expanded_conv_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 288 Layer Number : 5 Layer Name : expanded_conv_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 6 Layer Name : expanded_conv_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 7 Layer Name : expanded_conv_project Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 32) (None, 112, 112, 16) ) is Trainable: True No of Parameter : 512 Layer Number : 8 Layer Name : expanded_conv_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 16) (None, 112, 112, 16) ) is Trainable: True No of Parameter : 64 Layer Number : 9 Layer Name : block_1_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 16) (None, 112, 112, 96) ) is Trainable: True No of Parameter : 1536 Layer Number : 10 Layer Name : block_1_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 96) (None, 112, 112, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 11 Layer Name : block_1_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 96) (None, 112, 112, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 12 Layer Name : block_1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 96) (None, 113, 113, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 13 Layer Name : block_1_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 113, 113, 96) (None, 56, 56, 96) ) is Trainable: True No of Parameter : 864 Layer Number : 14 Layer Name : block_1_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 96) (None, 56, 56, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 15 Layer Name : block_1_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 96) (None, 56, 56, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 16 Layer Name : block_1_project Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 96) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 2304 Layer Number : 17 Layer Name : block_1_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 96 Layer Number : 18 Layer Name : block_2_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 3456 Layer Number : 19 Layer Name : block_2_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 20 Layer Name : block_2_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 21 Layer Name : block_2_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 1296 Layer Number : 22 Layer Name : block_2_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 23 Layer Name : block_2_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 24 Layer Name : block_2_project Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 3456 Layer Number : 25 Layer Name : block_2_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 24) ) is Trainable: True No of Parameter : 96 Layer Number : 26 Layer Name : block_2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 56, 56, 24), (None, 56, 56, 24)] (None, 56, 56, 24) ) is Trainable: True No of Parameter : 0 Layer Number : 27 Layer Name : block_3_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 24) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 3456 Layer Number : 28 Layer Name : block_3_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 29 Layer Name : block_3_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 56, 56, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 30 Layer Name : block_3_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 144) (None, 57, 57, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 31 Layer Name : block_3_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 57, 57, 144) (None, 28, 28, 144) ) is Trainable: True No of Parameter : 1296 Layer Number : 32 Layer Name : block_3_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 144) (None, 28, 28, 144) ) is Trainable: True No of Parameter : 576 Layer Number : 33 Layer Name : block_3_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 144) (None, 28, 28, 144) ) is Trainable: True No of Parameter : 0 Layer Number : 34 Layer Name : block_3_project Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 144) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 4608 Layer Number : 35 Layer Name : block_3_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 36 Layer Name : block_4_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 37 Layer Name : block_4_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 38 Layer Name : block_4_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 39 Layer Name : block_4_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 40 Layer Name : block_4_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 41 Layer Name : block_4_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 42 Layer Name : block_4_project Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 6144 Layer Number : 43 Layer Name : block_4_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 44 Layer Name : block_4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 32), (None, 28, 28, 32)] (None, 28, 28, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 45 Layer Name : block_5_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 46 Layer Name : block_5_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 47 Layer Name : block_5_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 48 Layer Name : block_5_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 49 Layer Name : block_5_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 50 Layer Name : block_5_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 51 Layer Name : block_5_project Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 6144 Layer Number : 52 Layer Name : block_5_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 32) ) is Trainable: True No of Parameter : 128 Layer Number : 53 Layer Name : block_5_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 32), (None, 28, 28, 32)] (None, 28, 28, 32) ) is Trainable: True No of Parameter : 0 Layer Number : 54 Layer Name : block_6_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 32) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 6144 Layer Number : 55 Layer Name : block_6_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 56 Layer Name : block_6_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 28, 28, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 57 Layer Name : block_6_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 192) (None, 29, 29, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 58 Layer Name : block_6_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 29, 29, 192) (None, 14, 14, 192) ) is Trainable: True No of Parameter : 1728 Layer Number : 59 Layer Name : block_6_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 192) (None, 14, 14, 192) ) is Trainable: True No of Parameter : 768 Layer Number : 60 Layer Name : block_6_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 192) (None, 14, 14, 192) ) is Trainable: True No of Parameter : 0 Layer Number : 61 Layer Name : block_6_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 192) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 12288 Layer Number : 62 Layer Name : block_6_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 63 Layer Name : block_7_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 64 Layer Name : block_7_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 65 Layer Name : block_7_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 66 Layer Name : block_7_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 67 Layer Name : block_7_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 68 Layer Name : block_7_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 69 Layer Name : block_7_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 70 Layer Name : block_7_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 71 Layer Name : block_7_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 64), (None, 14, 14, 64)] (None, 14, 14, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 72 Layer Name : block_8_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 73 Layer Name : block_8_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 74 Layer Name : block_8_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 75 Layer Name : block_8_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 76 Layer Name : block_8_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 77 Layer Name : block_8_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 78 Layer Name : block_8_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 79 Layer Name : block_8_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 80 Layer Name : block_8_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 64), (None, 14, 14, 64)] (None, 14, 14, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 81 Layer Name : block_9_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 82 Layer Name : block_9_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 83 Layer Name : block_9_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 84 Layer Name : block_9_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 85 Layer Name : block_9_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 86 Layer Name : block_9_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 87 Layer Name : block_9_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 24576 Layer Number : 88 Layer Name : block_9_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 89 Layer Name : block_9_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 64), (None, 14, 14, 64)] (None, 14, 14, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 90 Layer Name : block_10_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 64) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 24576 Layer Number : 91 Layer Name : block_10_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 92 Layer Name : block_10_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 93 Layer Name : block_10_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 3456 Layer Number : 94 Layer Name : block_10_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 1536 Layer Number : 95 Layer Name : block_10_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 384) ) is Trainable: True No of Parameter : 0 Layer Number : 96 Layer Name : block_10_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 384) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 36864 Layer Number : 97 Layer Name : block_10_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 98 Layer Name : block_11_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 99 Layer Name : block_11_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 100 Layer Name : block_11_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 101 Layer Name : block_11_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 102 Layer Name : block_11_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 103 Layer Name : block_11_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 104 Layer Name : block_11_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 55296 Layer Number : 105 Layer Name : block_11_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 106 Layer Name : block_11_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 96), (None, 14, 14, 96)] (None, 14, 14, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 107 Layer Name : block_12_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 108 Layer Name : block_12_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 109 Layer Name : block_12_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 110 Layer Name : block_12_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 111 Layer Name : block_12_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 112 Layer Name : block_12_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 113 Layer Name : block_12_project Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 55296 Layer Number : 114 Layer Name : block_12_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 96) ) is Trainable: True No of Parameter : 384 Layer Number : 115 Layer Name : block_12_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 96), (None, 14, 14, 96)] (None, 14, 14, 96) ) is Trainable: True No of Parameter : 0 Layer Number : 116 Layer Name : block_13_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 96) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 55296 Layer Number : 117 Layer Name : block_13_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 118 Layer Name : block_13_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 14, 14, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 119 Layer Name : block_13_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 576) (None, 15, 15, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 120 Layer Name : block_13_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 15, 15, 576) (None, 7, 7, 576) ) is Trainable: True No of Parameter : 5184 Layer Number : 121 Layer Name : block_13_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 576) (None, 7, 7, 576) ) is Trainable: True No of Parameter : 2304 Layer Number : 122 Layer Name : block_13_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 576) (None, 7, 7, 576) ) is Trainable: True No of Parameter : 0 Layer Number : 123 Layer Name : block_13_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 576) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 92160 Layer Number : 124 Layer Name : block_13_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 125 Layer Name : block_14_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 126 Layer Name : block_14_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 127 Layer Name : block_14_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 128 Layer Name : block_14_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 129 Layer Name : block_14_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 130 Layer Name : block_14_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 131 Layer Name : block_14_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 153600 Layer Number : 132 Layer Name : block_14_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 133 Layer Name : block_14_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 160), (None, 7, 7, 160)] (None, 7, 7, 160) ) is Trainable: True No of Parameter : 0 Layer Number : 134 Layer Name : block_15_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 135 Layer Name : block_15_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 136 Layer Name : block_15_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 137 Layer Name : block_15_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 138 Layer Name : block_15_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 139 Layer Name : block_15_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 140 Layer Name : block_15_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 153600 Layer Number : 141 Layer Name : block_15_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 160) ) is Trainable: True No of Parameter : 640 Layer Number : 142 Layer Name : block_15_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 160), (None, 7, 7, 160)] (None, 7, 7, 160) ) is Trainable: True No of Parameter : 0 Layer Number : 143 Layer Name : block_16_expand Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 160) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 153600 Layer Number : 144 Layer Name : block_16_expand_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 145 Layer Name : block_16_expand_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 146 Layer Name : block_16_depthwise Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 8640 Layer Number : 147 Layer Name : block_16_depthwise_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 3840 Layer Number : 148 Layer Name : block_16_depthwise_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 960) ) is Trainable: True No of Parameter : 0 Layer Number : 149 Layer Name : block_16_project Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 960) (None, 7, 7, 320) ) is Trainable: True No of Parameter : 307200 Layer Number : 150 Layer Name : block_16_project_BN Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 320) (None, 7, 7, 320) ) is Trainable: True No of Parameter : 1280 Layer Number : 151 Layer Name : Conv_1 Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 320) (None, 7, 7, 1280) ) is Trainable: True No of Parameter : 409600 Layer Number : 152 Layer Name : Conv_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 1280) (None, 7, 7, 1280) ) is Trainable: True No of Parameter : 5120 Layer Number : 153 Layer Name : out_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 1280) (None, 7, 7, 1280) ) is Trainable: True No of Parameter : 0 Layer Number : 154 Layer Name : global_average_pooling2d Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 1280) (None, 1280) ) is Trainable: True No of Parameter : 0 Layer Number : 155 Layer Name : predictions Layer Shape(Input_Shape,Output Shape) : ( (None, 1280) (None, 1000) ) is Trainable: True No of Parameter : 1281000</pre><p>Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel.output)        <strong>#Line 5<br></strong>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7<br></strong>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8<br></strong>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10<br></strong>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the ResNet network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong>model_final.summary()<strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has ResNet architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model_2&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_7[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            __________________________________________________________________________________________________ flatten_2 (Flatten)             (None, 2048)         0           conv5_block3_out[0][0]            __________________________________________________________________________________________________ dense_12 (Dense)                (None, 1000)         2049000     flatten_2[0][0]                   __________________________________________________________________________________________________ dense_13 (Dense)                (None, 800)          800800      dense_12[0][0]                    __________________________________________________________________________________________________ dense_14 (Dense)                (None, 400)          320400      dense_13[0][0]                    __________________________________________________________________________________________________ dense_15 (Dense)                (None, 200)          80200       dense_14[0][0]                    __________________________________________________________________________________________________ dense_16 (Dense)                (None, 100)          20100       dense_15[0][0]                    __________________________________________________________________________________________________ dense_17 (Dense)                (None, 10)           1010        dense_16[0][0]                    ================================================================================================== Total params: 26,859,222 Trainable params: 26,806,102 Non-trainable params: 53,120 ________________________________________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><p><strong>Note:</strong> In this section we have set the parameter of the ResNet to true i.e. the loss will bebackward propagated throught these layers where as the fully connected layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h3>In this article we have discussed about the Resnet architechture with Keras. In next article,we will have hands on experience with PyTorch API’s.</h3><h3>Stay Tuned !!! Happy Learning :)</h3><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote><em>Pytorch: </em><a href="https://pytorch.org/get-started/locally/#windows-python"><em>Link</em></a></blockquote><blockquote><em>Keras: </em><a href="https://keras.io/"><em>Link</em></a></blockquote><blockquote><em>Tensorflow: </em><a href="https://www.tensorflow.org/guide/keras/sequential_model"><em>Link</em></a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote><em>YouTube : </em><a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ"><em>Lin</em></a><em>k</em></blockquote><blockquote><em>Website: </em><a href="http://www.rstiwari.com/"><em>www.rstiwari.com</em></a></blockquote><blockquote><em>Medium: </em><a href="https://tiwari11-rst.medium.com/"><em>https://tiwari11-rst.medium.com</em></a></blockquote><blockquote><em>Github Pages: </em><a href="https://happyman11.github.io/"><em>https://happyman11.github.io/</em></a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote><em>Google Form: </em><a href="https://forms.gle/mhDYQKQJKtAKP78V7"><em>https://forms.gle/mhDYQKQJKtAKP78V7</em></a></blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b8d314a8609a" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-6-1-implementing-mobilenet-in-keras-b8d314a8609a">Transfer Learning — Part — 6.1!! Implementing Mobilenet in Keras</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 6.0!! Mobile net]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-6-0-mobile-net-a7e7467a27f?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/a7e7467a27f</guid>
    <category>
        <![CDATA[convolution]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[spartialconvolution]]>
    </category>
    <category>
        <![CDATA[mobilenet]]>
    </category>
    <category>
        <![CDATA[seperable-convolution]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Thu, 24 Feb 2022 17:01:25 GMT</pubDate>
    <atom:updated>2022-02-24T17:01:25.463Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 6.0!! Mobile net</h3><p>In Part 5 Series of the Transfer Learning series we have discussed the Residual Nets in depth along with hands-on application of these pre-trained neural nets in Keras and PyTorch API’s. The datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch which is discussed in Part 5 of this series. In this, article we will discuss theoretically about the Residual Nets and in article 6.2 and 6.3 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>For the repository and document please follow below two mentioned links:</p><p><strong>Keras:</strong></p><p><a href="https://keras.io/guides/transfer_learning/">Keras documentation: Transfer learning &amp; fine-tuning</a></p><p><strong>PyTorch:</strong></p><ul><li><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial - PyTorch Tutorials 1.12.0+cu102 documentation</a></li><li><a href="https://www.hindawi.com/journals/misy/2020/7602384/">A Novel Image Classification Approach via Dense-MobileNet Models</a></li><li><a href="https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299">Transfer Learning using Mobilenet and Keras</a></li></ul><h4>1. History of Mobilenet</h4><p>Numerous models are coming into existence, big thanks to Imagenet competition ILRVSC competition. Earlier opencv algorithms like SHIFT, HOG, LBPH and many other have performed well but their feature set was constructed manually and they lacks the capability of self learning thought they consumed less resources. As the popularity of the ILRVSC competition plummeted, size, efficiency as well as the real-time use of these model also increases.</p><p>The rise of the huge and cheap computational power enable these model to successfully run on these high power compute. But if we look into other side of the coin everyone does not have these kind of computational technology and when it comes to deployment and real time use we have limited resources especially in user end devices. So the deployment of the model was not possible at user end due to huge number of parameters and the the computation it requires to optimisation, forward propagation and back propagation.</p><p>Mobilenet solved the problem of huge parameters by employing seperable convolutional technique and super imposing the feature maps from the previous layer in forward convolutional layer. In order to further reduce the number of network parameters and improve the classification accuracy, dense blocks that are proposed in DenseNets are introduced into MobileNet. In Dense-MobileNet models, convolution layers with the same size of input feature maps in MobileNet models are taken as dense blocks, and dense connections are carried out within the dense blocks. The new network structure can make full use of the output feature maps generated by the previous convolution layers in dense blocks, so as to generate a large number of feature maps with fewer convolution cores and repeatedly use the features. By setting a small growth rate, the network further reduces the parameters and the computation cost. Two Dense-MobileNet models, Dense1-MobileNet and Dense2-MobileNet, are designed. Experiments show that Dense2-MobileNet can achieve higher recognition accuracy than MobileNet, while only with fewer parameters and computation cost. In order to further reduce the number of network parameters and improve the classification accuracy, dense blocks that are proposed in DenseNets are introduced into MobileNet. In Dense-MobileNet models, convolution layers with the same size of input feature maps in MobileNet models are taken as dense blocks, and dense connections are carried out within the dense blocks. The new network structure can make full use of the output feature maps generated by the previous convolution layers in dense blocks, so as to generate a large number of feature maps with fewer convolution cores and repeatedly use the features. By setting a small growth rate, the network further reduces the parameters and the computation cost. Two Dense-MobileNet models, Dense1-MobileNet and Dense2-MobileNet, are designed. Experiments show that Dense2-MobileNet can achieve higher recognition accuracy than MobileNet, while only with fewer parameters and computation cost.In order to further reduce the number of network parameters and improve the classification accuracy, dense blocks that are proposed in DenseNets are introduced into MobileNet. In Dense-MobileNet models, convolution layers with the same size of input feature maps in MobileNet models are taken as dense blocks, and dense connections are carried out within the dense blocks. The new network structure can make full use of the output feature maps generated by the previous convolution layers in dense blocks, so as to generate a large number of feature maps with fewer convolution cores and repeatedly use the features. By setting a small growth rate, the network further reduces the parameters and the computation cost. Two Dense-MobileNet models, Dense1-MobileNet and Dense2-MobileNet, are designed. Experiments show that Dense2-MobileNet can achieve higher recognition accuracy than MobileNet, while only with fewer parameters and computation cost. Compared with VGG-16 network, MobileNet is a lightweight network, which uses depthwise separable convolution to deepen the network, and reduce parameters and computation. At the same time, the classification accuracy of MobileNet on ImageNet data set only reduces by 1%. However, in order to be better applied to mobile devices with limited memory, the parameters and computational complexity of the MobileNet model need to be further reduced. Therefore, we use dense blocks as the basic unit in the network layer of MobileNet. By setting a small growth rate, the model has fewer parameters and lower computational cost. The new models, namely Dense-MobileNets, can also achieve high classification accuracy. MobileNet is a streamlined architecture that uses depthwise separable convolutions to construct lightweight deep convolutional neural networks and provides an efficient model for mobile and embedded vision applications.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/355/1*Ako_swE8qkZnnrCriIjx7w.png" /><figcaption><strong>Fig 1. </strong>Mobilenet</figcaption></figure><p>Lets start this article by explaining how the convolution works then we will dig deep into seperable convolution layers.</p><ol><li><strong>Convolution Layers</strong></li></ol><p>For images/video the best way to extract the features is by convoluting the filters/kernels which is of 2d dimension and extract the different feature maps from the image. A 2D Convolution is a mathematical process in which a 2D kernel slides over the 2D input matrix performing matrix multiplication with the part that is currently on and then summing up the result matrix into a single pixel.</p><p>Suppose there is an input data of size <strong>Df x Df x M</strong>, where Df x Df can be the image size and M is the number of channels (3 for an RGB image and 1 for GreyScale). Suppose there are N filters/kernels of size<strong>Dk x Dk x N</strong>. If a normal convolution operation is done, then, the output size will be<strong>Dp x Dp x N</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/701/0*5uEoHrUa9mNImWHT.jpg" /><figcaption>Fig. 2 Convolutional Network</figcaption></figure><h4><em>Calculations for convolution:</em></h4><p><em>No of multiplication in 1 convolution operation </em>=<strong>Dk * Dk * M</strong><em>(eq 1)</em></p><p>Since, we have N filters and each filter slides vertically and horizontally Dp times so,</p><p><em>Total number of multiplication</em> =<strong> N * Dp * Dp * <em>(eq.1 )</em></strong>(Multiplications per convolution)<em> (eq. 2)</em></p><p>if we calculate using eq 1 and eq 1 we can infer that</p><p><em>Total multiplication =</em><strong><em>N *Dp* Dp*Dk*Dk *M </em></strong><em>(eq. 3)</em></p><p>These calculation are very huge in number and need substantial resource to compute the model and optimise it. In order to save the computing resources and make the model which can be deployed in the real time devices researchers developed concept known as separable convolution in which we can separate the kernels/filters in to smaller kernal for reducing the size of the kernels which directly reduces the size of the computation and prevents over fitting.</p><p>2.<strong> Separable Convolution</strong></p><p>A Separable Convolution is a process in which a single convolution can be divided into two or more convolutions to produce the same output. A single process is divided into two or more sub-processes to achieve the same effect. Let’s understand Separable Convolutions, their types in-depth with examples.</p><p>Mainly there are two types of Separable Convolutions</p><p>2.1<strong> Spartial Seperable Convolution</strong></p><p>This is the easier one out of the two, and illustrates the idea of separating one convolution into two well, so we start with this. Unfortunately, spatial separable convolutions have some significant limitations, meaning that it is not heavily used in deep learning because spartial refers to height and weight of the image it does not take account of the depth .The spatial separable convolution is so named because it deals primarily with the spatial dimensions of an image and kernel: the width and the height. (The other dimension, the “depth” dimension, is the number of channels of each image).</p><p>The spatial separable convolution works on the spatial features of an image: its width and its height. These features are the<strong> spatial </strong>dimensions of the image hence the name, spatial separable. It decomposes the convolution operation into two parts and applies each separated convolution in succession. For instance, the Sobel filter (or the Sobel kernel), which is a 3x3 filter is split into two filters of size 3x1 and 1x3.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/688/0*jKkHeY2_FXy0Siyg.PNG" /><figcaption><strong>Fig. 3 </strong>Spartial Convolutional Network</figcaption></figure><p>As you can see, the 3x3 filter is spilt into a 3x1 and a 1x3 filter. The output does not change as the image still obeys the matrix multiplication rule. The image when the 3x1 filter is applied will have the column dimension as 1 which is the row dimension of the next filter, the 1x3 filter. What is changed is the number of multiplications that are performed. Spatial separable convolution reduces the number of individual multiplications. In a regular 3x3 convolution, there are a total of 9 operations. But when we split the matrix into a 3x1 and a 1x3 filter, there are a total of 6 operations. Therefore, less matrix multiplications are needed when convolving it in an image.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*_jtyHZXZ9Nd8RlHT.png" /><figcaption>Fig. 4 Saprtial Convolutional Network</figcaption></figure><p>Let’s generalize the formula. For any N x N image, applying convolutions with an m x m kernel having stride of 1 and padding of 0:</p><p><em>Traditional convolution requires ((N — 2) x (N — 2) x m x m) matrix multiplications</em>.<em>(eq. 4)</em></p><p><em>Spatially separable convolution requires (N x (N-2) x m) + ((N-2) x (N-2) x m) = (2N-2) x (N-2) x m multiplications. (eq. 5)</em></p><p>We can find the ratio of computation costs between both the approaches. The ratio between computational cost of spatial separable convolution and computational cost of regular convolution is:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/297/0*C3SJJLcRjgCqNyCj.PNG" /><figcaption><strong>Fig . 5 </strong>Ration of CNN and Spartial CNN</figcaption></figure><p>We can see this ratio becomes 2 / m when the image size is way larger than the filter size (when N &gt;&gt; m). Putting values of kernel size, m = 3, 5, 7, and so on, we see that the computational cost of spatially separable convolution is 2/3 (about 66%) of the standard convolution for a 3 x 3 filter, 2 / 5 (40%) for a 5 x 5 filter, 2 / 7 (about 29%) for a 7 x 7 filter.</p><p>An important thing to note here is that not every kernel can be separated. Because of this drawback, this method is used lesser compared to Depthwise separable convolutions.</p><p>2.2 <strong>Depth wise Separable Convolution</strong></p><p>Unlike spatial separable convolutions, depthwise separable convolutions work with kernels that cannot be “factored” into two smaller kernels. Hence, it is more commonly used. This is the type of separable convolution seen in tf.keras.layers.SeparableConv2D or tf.layers.separable_conv2d.</p><p>The depthwise separable convolution is so named because it deals not just with the spatial dimensions, but with the depth dimension — the number of channels — as well. An input image may have 3 channels: RGB. After a few convolutions, an image may have multiple channels. You can image each channel as a particular interpretation of that image; in for example, the “red” channel interprets the “redness” of each pixel, the “blue” channel interprets the “blueness” of each pixel, and the “green” channel interprets the “greenness” of each pixel. An image with 64 channels has 64 different interpretations of that image.</p><p>Similar to the spatial separable convolution, a depthwise separable convolution splits a kernel into 2 separate kernels that do two convolutions: the depth wise — for spartial operation convolution and the point wise convolution — for depth wise operations.</p><p>Now we will look at depth-wise separable convolutions. This process is broken down into 2 operations –</p><p>2.2.1<strong>. Depth wise Convolution</strong></p><p>In<strong> </strong>depth-wise operation, convolution operation is applied to a single channel only at a time unlike standard CNN’s in which it is done for all the M channels. So if the filters/kernels will be of size<strong>Dk x Dk x 1</strong>. Given there are M channels in the input data, then M such filters are required. Output will be of size<strong>Dp x Dp x M</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/651/0*RBEdC2vyuDoGt2qa.png" /><figcaption><strong>Fig . 6.</strong> Depthwise CNN</figcaption></figure><h4>Calculations for depth wise convolution:</h4><p><em>A single convolution operation= </em><strong><em>Dk x Dk</em></strong><em> multiplications (eq. 6)</em></p><p>Since the filter are slided by<strong> Dp x Dp</strong> times across all the M channels, so the</p><p><em>Total number of multiplication = </em><strong><em>M x Dp x Dp x Dk x Dk </em></strong><em>(eq. 7)</em></p><p><em>Total number of multiplication =</em><strong>M x Dk2 x Dp2 </strong><em>(eq. 8)</em></p><p>2.2.2.<strong> Point wise Convolution</strong></p><p>In point-wise operation, a 1×1 convolution operation is applied on the M channels. So the filter size for this operation will be <strong>1 x 1 x M</strong>. Say we use N such filters, the output size becomes<strong>Dp x Dp x N</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/686/0*A-DJXP3R6pumo1a7.png" /><figcaption><strong>Fig . 7</strong> Pointwise CNN</figcaption></figure><p><strong>Cost of this point wise convolution:</strong></p><p>A single convolution operation =<strong> 1 x M multiplications. </strong><em>(eq. 9)</em></p><p>Since the filter is being slided by<strong> Dp x Dp</strong> times,</p><p>the total number of multiplications = <strong>M x Dp x Dp x (no. of filters) </strong><em>(eq. 9)</em></p><p>So for point wise convolution operation</p><p>Total no of multiplications =<strong> M x Dp2 x N </strong><em>(eq. 10)</em></p><p><em>Hence,for overall operation:</em></p><p>Total multiplications =<strong> Depth wise conv. multiplications + Point wise conv. multiplications </strong><em>(eq. 11)</em></p><p>Total multiplications =<strong> M * Dk2 * Dp2 + M * Dp2 * N = M * Dp2 * (Dk2 + n) </strong><em>(eq. 12)</em></p><p>So for depth wise separable convolution operation</p><p>Total no of multiplications =<strong> M x Dp2 x (Dk2 + N) </strong><em>(eq. 13)</em></p><p><strong>Comparison between the complexities of these types of convolution operations :-</strong></p><p>Complexity of depth wise separable convolutions/Complexity of standard convolution = RATIO ( R ) <em>(eq. 14)</em></p><p>Upon solving <em>eq. 3, eq. 13 in eq. 14 we get,</em></p><p>Ratio(R) =<strong> 1/N + 1/Dk2 (</strong><em>eq. 15)</em></p><p>which is much more computational effective as compared to the normal convolutional.</p><p>In Mobilenet, DenseNet proposed a new connection mode, connecting each current layer of the network with the previous network layers, so that the current layer can take the output feature maps of all the previous layers as input features. To some extent, this kind of connection can alleviate the problem of gradient disappearance. Since each layer is connected with all the previous layers, the previous features can be repeatedly used to generate more feature maps with less convolution kernel.</p><p>DenseNet takes dense blocks as basic unit modules, a dense block structure consists of 4 densely connected layers with a growth rate of 4. Each layer in this structure takes the output feature maps of the previous layers as the input feature maps. Different from the residual unit in ResNet , which combines the sum of the feature maps of the previous layers in one layer, the dense block transfers the feature maps to all the subsequent layers, adding the dimension of the feature maps rather than adding the pixel values in the feature maps.the dense block only superimposes the feature maps of the previous convolution layers and increases the number of feature maps. Therefore, only the magnitude of xt and xt+1 is required to be equal, and the number of feature maps does not need to be the same. DenseNet uses hyperparameter growth rate to control the number of feature map channels in the network. The growth rate indicates that the output feature maps of each network layer is . That is, for each convolution layer, the input feature maps of the next layer will increase channels.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/570/1*QKY8Qj42Iv3l_KiDHHGRmA.png" /><figcaption><strong>Fig. 8 </strong>Two layers of dense connected modules.</figcaption></figure><p>DenseNet contains a transition layer between two consecutive dense blocks. The transition layer reduces the number of input feature maps by using 1 ∗ 1 convolution kernel and halves the number of input feature maps by using 2 ∗ 2 average pooling layer. The above two operations can ease the computational load of the network. Different from DenseNet, there is no transition layer between two consecutive dense blocks in Dense1-MobileNet model, the reason are as follows: (1) in MobileNet, batch normalization is carried out behind each convolution layer, and the last layer of the dense blocks is 1 ∗ 1 point convolution layer, which can reduce the number of feature maps; (2) in addition, MobileNet reduces the size of feature map by using convolution layer instead of pooling layer, that is, it directly convolutes the output feature map of the previous point convolution layer with stride 2 to reduce the size of feature map.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/572/1*uOk38SFkfke0p_wSRRNldA.png" /><figcaption><strong>Fig. 9.</strong> Schematic diagram of the Dense1-MobileNet model.</figcaption></figure><p>Dense2-MobileNet accepts depthwise distinct convolution all in all, called a thick (depthwise detachable convolution) block, which contains two point convolutional layers and a depthwise convolutional layer. The info highlight guides of depthwise detachable convolution layer is the gathering of result include maps created by point convolutions in all past depthwise distinguishable convolution layers, while the information highlight map in point convolution layer is just the result highlight map produced by the depthwise convolution in the thick square, not the superposition of the result highlight guides of the relative multitude of past layers.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/571/1*XM-TScFLbH4ecbjQE3fmOQ.png" /><figcaption>Fig. 10 Diagram of the Dense2 MobileNet Model</figcaption></figure><p>In Dense2-MobileNet model, just one information include map needs to overlay the result highlight guide of point convolution in the upper depthwise distinct convolution layer. In view of the less combined seasons of underlying component maps, the quantity of result include guides of all layers in a thick square is additionally less aggregate; thus, it isn’t important to diminish the channel of element maps by a 1 ∗ 1 convolution. In the wake of superimposing the result include maps created by the past divisible convolutions, the size of the component guide can be diminished by the depthwise convolution with step 2; along these lines, the Dense2-MobileNet model doesn’t add other change layers as well. The MobileNet model is at last pooled universally and associated straightforwardly to the result layer. Tests show that the grouping precision of the worldwide normal prepooling depthwise divisible convolution with thick association before the worldwide normal pooling is higher than that of two-layer depthwise distinguishable convolution without thick association. Along these lines, the depthwise divisible convolution layer before worldwide normal pooling is additionally thickly associated.</p><p><strong><em>Alternatives to separable convolution</em></strong></p><p>While separable convolution is one of many convolution techniques out there, one can choose from a list of different convolution techniques that specialize in specific domains. Alternatives to separable convolution are:</p><ul><li>Transposed Convolution (Deconvolution, checkerboard artifacts)</li><li>Dilated Convolution (Atrous Convolution)</li><li>Flattened Convolution</li><li>Grouped Convolution</li><li>Shuffled Grouped Convolution</li><li>Pointwise Grouped Convolution</li></ul><p>In this article we have discussed about the Mobilenet architecture theoretically in next article i.e. 5.2 and 5.3 we will have hands on experience with Keras and PyTorch API’s.</p><h4>Stay Tuned !!! Happy Learning :)</h4><p><strong><em>Need help ???</em></strong><em> Consult with me on </em><strong><em>DDI :)</em></strong></p><p><a href="https://app.ddichat.com/experts/ravi-shekhar-tiwari/">Ravi Shekhar TIwari - DDIChat</a></p><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote>Pytorch: <a href="https://pytorch.org/get-started/locally/#windows-python">Link</a></blockquote><blockquote>Keras: <a href="https://keras.io/">Link</a></blockquote><blockquote>ResNet:<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiz__vNp93zAhUBxzgGHTtVBvcQFnoECAQQAQ&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1512.03385&amp;usg=AOvVaw0ko2RV0WsEDskyH0kl1EHN"><em> Link</em></a></blockquote><blockquote>Tensorflow: <a href="https://www.tensorflow.org/guide/keras/sequential_model">Link</a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote>YouTube : <a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ">Lin</a>k</blockquote><blockquote>Website: <a href="http://www.rstiwari.com/">www.rstiwari.com</a></blockquote><blockquote>Medium: <a href="https://tiwari11-rst.medium.com/">https://tiwari11-rst.medium.com</a></blockquote><blockquote>Github Pages: <a href="https://happyman11.github.io/">https://happyman11.github.io/</a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Google Form: <a href="https://forms.gle/mhDYQKQJKtAKP78V7">https://forms.gle/mhDYQKQJKtAKP78V7</a></blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a7e7467a27f" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-6-0-mobile-net-a7e7467a27f">Transfer Learning — Part — 6.0!! Mobile net</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 5.2!! Implementing ResNet in PyTorch]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-5-2-implementing-resnet-in-pytorch-fe87f2821f83?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/fe87f2821f83</guid>
    <category>
        <![CDATA[python3]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[resnet]]>
    </category>
    <category>
        <![CDATA[artificial-intelligence]]>
    </category>
    <category>
        <![CDATA[pytorch]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Tue, 11 Jan 2022 14:37:36 GMT</pubDate>
    <atom:updated>2022-04-09T06:18:21.978Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 5.2!! Implementing ResNet in PyTorch</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*1fTB7GLajuWvFn24.jpg" /><figcaption><strong>Figure.1 </strong>Transfer Learning</figcaption></figure><p>In Part 5.0 of the Transfer Learning series we have discussed about ResNet pre-trained model in depth so in this series we will implement the above mentioned pre-trained model in PyTorch. This part is going to be little long because we are going to implement ResNet in PyTorch with Python. We will be implementing the per-trained ResNet model in 4 ways which we will discuss further in this article. For setting- up the Colab notebook it will be advisable to go through the below mentioned article of Transfer Learning Series.</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>It is also advisable to go through the article of ResNet before reading this article which is mentioned below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-5-1-implementing-resnet-in-keras-455afbc28657">Transfer Learning — Part — 5.1!! Implementing ResNet in Keras</a></p><p><strong>1.Implementing ResNet Pre-trained model</strong></p><p>In this section we will see how we can implement ResNet model in PyTorch to have a foundation to start our real implementation .</p><p><strong>1.1. Image to predict</strong></p><p>We will use the image of the coffee mug to predict the labels with the ResNet architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import torch                                          <strong>#Line 1</strong></pre><pre>import torchvision.models as models                   <strong>#Line 2</strong></pre><pre>from PIL import Image                                 <strong>#Line 3</strong></pre><pre>import torchvision.transforms.functional as TF        <strong>#Line 4</strong></pre><pre>from torchsummary import summary                      <strong>#Line 5</strong></pre><pre>!pip install torchviz                                 <strong>#Line 6</strong></pre><pre>from torchviz import make_dot                         <strong>#Line 7</strong></pre><pre>import numpy as np</pre><p><strong>Line 1:</strong> The above snippet is used to import the PyTorch library which we use use to implement ResNet network.</p><p><strong>Line 2:</strong> The above snippet is used to import the PyTorch pre-trained models.</p><p><strong>Line 3:</strong> The above snippet is used to import the PIL library for visualization purpose.</p><p><strong>Line 4:</strong> The above snippet is used to import the PyTorch Transformation library which we use use to transform the dataset for training and testing.</p><p><strong>Line 5:</strong> The above snippet is used to import library which shows the summary of models.</p><p><strong>Line 6:</strong> The above snippet is used to install torchviz to visualise the network.</p><p><strong>Line 7:</strong> The above snippet is used to import torchviz to visualize the network.</p><pre>image = Image.open(link_of_image)   <strong>#Line 8</strong></pre><pre>image=image.resize((224,224))       <strong>#Line 9</strong></pre><pre>x = TF.to_tensor(image)             <strong>#Line 10</strong></pre><pre>x.unsqueeze_(0)                     <strong>#Line 11</strong></pre><pre>x=x.to(device)                      <strong>#Line 12</strong></pre><pre>print(x.shape)                      <strong>#Line 13</strong></pre><p><strong>Line 8: </strong>This snippet loads the images from the path.</p><p><strong>Line 9: </strong>This snippet converts the image in the size (224,224) required by the model.</p><p><strong>Line 10:</strong> This snippet convert the image into array</p><p><strong>Line 11: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 12:</strong> This snippet is used to move the image to the device on which model is registered.</p><p><strong>Line 13: </strong>This snippet use to display the image shape as shown below:</p><pre>torch.Size([1, 3, 224, 224])</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*Q8sQsV5H4B8-or4D3-nQgg.jpeg" /><figcaption><strong>Figure. 1 </strong>Image to be predicted</figcaption></figure><p><strong>1.2. ResNet Implementation</strong></p><p>Here we will use ResNet network to predict on the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0</strong></pre><pre>resnet_pretrained = models.resnet50(pretrained=True).to(device)    <br><strong>#LINE 1</strong></pre><pre>summary(resnet_pretrained, (3, 224, 224))                    <strong>#LINE 2</strong></pre><pre>resnet_pretrained                                            <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the ResNet model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)<br>  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)</pre><pre>----------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1         [-1, 64, 112, 112]           9,408<br>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br>              ReLU-3         [-1, 64, 112, 112]               0<br>         MaxPool2d-4           [-1, 64, 56, 56]               0<br>            Conv2d-5           [-1, 64, 56, 56]           4,096<br>       BatchNorm2d-6           [-1, 64, 56, 56]             128<br>              ReLU-7           [-1, 64, 56, 56]               0<br>            Conv2d-8           [-1, 64, 56, 56]          36,864<br>       BatchNorm2d-9           [-1, 64, 56, 56]             128<br>             ReLU-10           [-1, 64, 56, 56]               0<br>           Conv2d-11          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-12          [-1, 256, 56, 56]             512<br>           Conv2d-13          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-14          [-1, 256, 56, 56]             512<br>             ReLU-15          [-1, 256, 56, 56]               0<br>       Bottleneck-16          [-1, 256, 56, 56]               0<br>           Conv2d-17           [-1, 64, 56, 56]          16,384<br>      BatchNorm2d-18           [-1, 64, 56, 56]             128<br>             ReLU-19           [-1, 64, 56, 56]               0<br>           Conv2d-20           [-1, 64, 56, 56]          36,864<br>      BatchNorm2d-21           [-1, 64, 56, 56]             128<br>             ReLU-22           [-1, 64, 56, 56]               0<br>           Conv2d-23          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-24          [-1, 256, 56, 56]             512<br>             ReLU-25          [-1, 256, 56, 56]               0<br>       Bottleneck-26          [-1, 256, 56, 56]               0<br>           Conv2d-27           [-1, 64, 56, 56]          16,384<br>      BatchNorm2d-28           [-1, 64, 56, 56]             128<br>             ReLU-29           [-1, 64, 56, 56]               0<br>           Conv2d-30           [-1, 64, 56, 56]          36,864<br>      BatchNorm2d-31           [-1, 64, 56, 56]             128<br>             ReLU-32           [-1, 64, 56, 56]               0<br>           Conv2d-33          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-34          [-1, 256, 56, 56]             512<br>             ReLU-35          [-1, 256, 56, 56]               0<br>       Bottleneck-36          [-1, 256, 56, 56]               0<br>           Conv2d-37          [-1, 128, 56, 56]          32,768<br>      BatchNorm2d-38          [-1, 128, 56, 56]             256<br>             ReLU-39          [-1, 128, 56, 56]               0<br>           Conv2d-40          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-41          [-1, 128, 28, 28]             256<br>             ReLU-42          [-1, 128, 28, 28]               0<br>           Conv2d-43          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-44          [-1, 512, 28, 28]           1,024<br>           Conv2d-45          [-1, 512, 28, 28]         131,072<br>      BatchNorm2d-46          [-1, 512, 28, 28]           1,024<br>             ReLU-47          [-1, 512, 28, 28]               0<br>       Bottleneck-48          [-1, 512, 28, 28]               0<br>           Conv2d-49          [-1, 128, 28, 28]          65,536<br>      BatchNorm2d-50          [-1, 128, 28, 28]             256<br>             ReLU-51          [-1, 128, 28, 28]               0<br>           Conv2d-52          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-53          [-1, 128, 28, 28]             256<br>             ReLU-54          [-1, 128, 28, 28]               0<br>           Conv2d-55          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-56          [-1, 512, 28, 28]           1,024<br>             ReLU-57          [-1, 512, 28, 28]               0<br>       Bottleneck-58          [-1, 512, 28, 28]               0<br>           Conv2d-59          [-1, 128, 28, 28]          65,536<br>      BatchNorm2d-60          [-1, 128, 28, 28]             256<br>             ReLU-61          [-1, 128, 28, 28]               0<br>           Conv2d-62          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-63          [-1, 128, 28, 28]             256<br>             ReLU-64          [-1, 128, 28, 28]               0<br>           Conv2d-65          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-66          [-1, 512, 28, 28]           1,024<br>             ReLU-67          [-1, 512, 28, 28]               0<br>       Bottleneck-68          [-1, 512, 28, 28]               0<br>           Conv2d-69          [-1, 128, 28, 28]          65,536<br>      BatchNorm2d-70          [-1, 128, 28, 28]             256<br>             ReLU-71          [-1, 128, 28, 28]               0<br>           Conv2d-72          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-73          [-1, 128, 28, 28]             256<br>             ReLU-74          [-1, 128, 28, 28]               0<br>           Conv2d-75          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-76          [-1, 512, 28, 28]           1,024<br>             ReLU-77          [-1, 512, 28, 28]               0<br>       Bottleneck-78          [-1, 512, 28, 28]               0<br>           Conv2d-79          [-1, 256, 28, 28]         131,072<br>      BatchNorm2d-80          [-1, 256, 28, 28]             512<br>             ReLU-81          [-1, 256, 28, 28]               0<br>           Conv2d-82          [-1, 256, 14, 14]         589,824<br>      BatchNorm2d-83          [-1, 256, 14, 14]             512<br>             ReLU-84          [-1, 256, 14, 14]               0<br>           Conv2d-85         [-1, 1024, 14, 14]         262,144<br>      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048<br>           Conv2d-87         [-1, 1024, 14, 14]         524,288<br>      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048<br>             ReLU-89         [-1, 1024, 14, 14]               0<br>       Bottleneck-90         [-1, 1024, 14, 14]               0<br>           Conv2d-91          [-1, 256, 14, 14]         262,144<br>      BatchNorm2d-92          [-1, 256, 14, 14]             512<br>             ReLU-93          [-1, 256, 14, 14]               0<br>           Conv2d-94          [-1, 256, 14, 14]         589,824<br>      BatchNorm2d-95          [-1, 256, 14, 14]             512<br>             ReLU-96          [-1, 256, 14, 14]               0<br>           Conv2d-97         [-1, 1024, 14, 14]         262,144<br>      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048<br>             ReLU-99         [-1, 1024, 14, 14]               0<br>      Bottleneck-100         [-1, 1024, 14, 14]               0<br>          Conv2d-101          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-102          [-1, 256, 14, 14]             512<br>            ReLU-103          [-1, 256, 14, 14]               0<br>          Conv2d-104          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-105          [-1, 256, 14, 14]             512<br>            ReLU-106          [-1, 256, 14, 14]               0<br>          Conv2d-107         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048<br>            ReLU-109         [-1, 1024, 14, 14]               0<br>      Bottleneck-110         [-1, 1024, 14, 14]               0<br>          Conv2d-111          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-112          [-1, 256, 14, 14]             512<br>            ReLU-113          [-1, 256, 14, 14]               0<br>          Conv2d-114          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-115          [-1, 256, 14, 14]             512<br>            ReLU-116          [-1, 256, 14, 14]               0<br>          Conv2d-117         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048<br>            ReLU-119         [-1, 1024, 14, 14]               0<br>      Bottleneck-120         [-1, 1024, 14, 14]               0<br>          Conv2d-121          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-122          [-1, 256, 14, 14]             512<br>            ReLU-123          [-1, 256, 14, 14]               0<br>          Conv2d-124          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-125          [-1, 256, 14, 14]             512<br>            ReLU-126          [-1, 256, 14, 14]               0<br>          Conv2d-127         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048<br>            ReLU-129         [-1, 1024, 14, 14]               0<br>      Bottleneck-130         [-1, 1024, 14, 14]               0<br>          Conv2d-131          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-132          [-1, 256, 14, 14]             512<br>            ReLU-133          [-1, 256, 14, 14]               0<br>          Conv2d-134          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-135          [-1, 256, 14, 14]             512<br>            ReLU-136          [-1, 256, 14, 14]               0<br>          Conv2d-137         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048<br>            ReLU-139         [-1, 1024, 14, 14]               0<br>      Bottleneck-140         [-1, 1024, 14, 14]               0<br>          Conv2d-141          [-1, 512, 14, 14]         524,288<br>     BatchNorm2d-142          [-1, 512, 14, 14]           1,024<br>            ReLU-143          [-1, 512, 14, 14]               0<br>          Conv2d-144            [-1, 512, 7, 7]       2,359,296<br>     BatchNorm2d-145            [-1, 512, 7, 7]           1,024<br>            ReLU-146            [-1, 512, 7, 7]               0<br>          Conv2d-147           [-1, 2048, 7, 7]       1,048,576<br>     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096<br>          Conv2d-149           [-1, 2048, 7, 7]       2,097,152<br>     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096<br>            ReLU-151           [-1, 2048, 7, 7]               0<br>      Bottleneck-152           [-1, 2048, 7, 7]               0<br>          Conv2d-153            [-1, 512, 7, 7]       1,048,576<br>     BatchNorm2d-154            [-1, 512, 7, 7]           1,024<br>            ReLU-155            [-1, 512, 7, 7]               0<br>          Conv2d-156            [-1, 512, 7, 7]       2,359,296<br>     BatchNorm2d-157            [-1, 512, 7, 7]           1,024<br>            ReLU-158            [-1, 512, 7, 7]               0<br>          Conv2d-159           [-1, 2048, 7, 7]       1,048,576<br>     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096<br>            ReLU-161           [-1, 2048, 7, 7]               0<br>      Bottleneck-162           [-1, 2048, 7, 7]               0<br>          Conv2d-163            [-1, 512, 7, 7]       1,048,576<br>     BatchNorm2d-164            [-1, 512, 7, 7]           1,024<br>            ReLU-165            [-1, 512, 7, 7]               0<br>          Conv2d-166            [-1, 512, 7, 7]       2,359,296<br>     BatchNorm2d-167            [-1, 512, 7, 7]           1,024<br>            ReLU-168            [-1, 512, 7, 7]               0<br>          Conv2d-169           [-1, 2048, 7, 7]       1,048,576<br>     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096<br>            ReLU-171           [-1, 2048, 7, 7]               0<br>      Bottleneck-172           [-1, 2048, 7, 7]               0<br>AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0<br>          Linear-174                 [-1, 1000]       2,049,000<br>================================================================<br>Total params: 25,557,032<br>Trainable params: 25,557,032<br>Non-trainable params: 0<br>----------------------------------------------------------------<br>Input size (MB): 0.57<br>Forward/backward pass size (MB): 286.56<br>Params size (MB): 97.49<br>Estimated Total Size (MB): 384.62<br>----------------------------------------------------------------</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the layers which is shown below with types of layer:</p><pre>ResNet(   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   (relu): ReLU(inplace=True)   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)   </pre><pre>(layer1): Sequential(     <br>(0): Bottleneck(       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(2): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer2): Sequential(     (0): Bottleneck(       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(2): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(3): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer3): Sequential(     (0): Bottleneck(       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(3): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(4): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(5): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer4): Sequential(     (0): Bottleneck(       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(2): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   </pre><pre>(avgpool): AdaptiveAvgPool2d(output_size=(1, 1))   (fc): Linear(in_features=2048, out_features=1000, bias=True) )</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>resnet_prediction=resnet_pretrained(x)                       <strong>#Line 4</strong></pre><pre>resnet_prediction_numpy=resnet_prediction.detach().numpy()   <strong>#Line 5</strong></pre><pre>predicted_class_max = np.argmax(resnet_prediction_numpy)     <strong>#Line 6</strong></pre><pre>predicted_class_max                                          <strong>#Line 7</strong></pre><p><strong>Line 4:</strong> This snippets send the pre-processed image to the ResNet network for getting prediction.</p><p><strong>Line 5: </strong>This line is used to<strong> </strong>move the prediction from the model from GPU to CPU so we can manipulate it and convert the prediction from torch tensor to numpy array.</p><p><strong>Line 6: </strong>This snippet is used to get the array index whose probability is maximum.</p><p><strong>Line 7: </strong>This snippets is used to display the highest probability class.</p><pre>504</pre><p>The below snippets is used to read the label from text file and display the label name as shown below:</p><pre>with open(‘/content/imagenet1000_clsidx_to_labels.txt’, ‘r’) as fp:<br>    line_numbers = [predicted_class_max]<br>    for i, line in enumerate(fp):<br>       if i in line_numbers:<br>           lines.append(line.strip()<br>           break</pre><pre>print(lines)</pre><pre><strong>Output&gt;&gt;&gt;&gt;<br></strong>[&quot;504: &#39;coffee mug&#39;,&quot;]</pre><p><strong>2.1. As a feature Extraction model.</strong></p><p>Since we have discussed the ResNet model in details in out previous article i.e. in part 5.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained ResNet to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p>2.1.1<strong> Image to extract feature</strong></p><p>We will use the image of the coffee mug to predict the labels with the ResNet architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import torch                                          <strong>#Line 1</strong></pre><pre>import torchvision.models as models                   <strong>#Line 2</strong></pre><pre>from PIL import Image                                 <strong>#Line 3</strong></pre><pre>import torchvision.transforms.functional as TF        <strong>#Line 4</strong></pre><pre>from torchsummary import summary                      <strong>#Line 5</strong></pre><pre>!pip install torchviz                                 <strong>#Line 6</strong></pre><pre>from torchviz import make_dot                         <strong>#Line 7</strong></pre><pre>import numpy as np</pre><p><strong>Line 1:</strong> The above snippet is used to import the PyTorch library which we use use to implement ResNet network.</p><p><strong>Line 2:</strong> The above snippet is used to import the PyTorch pre-trained models.</p><p><strong>Line 3:</strong> The above snippet is used to import the PIL library for visualization purpose.</p><figure><a href="https://aijobsboard.com/?fbclid=IwAR0GcsLs8A6CFM-fynrZMM3sTgo_Zpbto2CjglJm0Dmi6otC6YWc7CDFpQk"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dAlwXfVrtYspdCzmC8iADw.png" /></a><figcaption>Big Data Jobs</figcaption></figure><p><strong>Line 4:</strong> The above snippet is used to import the PyTorch Transformation library which we use use to transform the dataset for training and testing.</p><p><strong>Line 5:</strong> The above snippet is used to import library which shows the summary of models.</p><p><strong>Line 6:</strong> The above snippet is used to install torchviz to visualise the network.</p><p><strong>Line 7:</strong> The above snippet is used to import torchviz to visualize the network.</p><pre>image = Image.open(link_of_image)   <strong>#Line 8</strong></pre><pre>image=image.resize((224,224))       <strong>#Line 9</strong></pre><pre>x = TF.to_tensor(image)             <strong>#Line 10</strong></pre><pre>x.unsqueeze_(0)                     <strong>#Line 11</strong></pre><pre>x=x.to(device)                      <strong>#Line 12</strong></pre><pre>print(x.shape)                      <strong>#Line 13</strong></pre><p><strong>Line 8: </strong>This snippet loads the images from the path.</p><p><strong>Line 9: </strong>This snippet converts the image in the size (224,224) required by the model.</p><p><strong>Line 10:</strong> This snippet convert the image into array</p><p><strong>Line 11: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 12:</strong> This snippet is used to move the image to the device on which model is registered.</p><p><strong>Line 13: </strong>This snippet use to display the image shape as shown below:</p><pre>torch.Size([1, 3, 224, 224])</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*Q8sQsV5H4B8-or4D3-nQgg.jpeg" /><figcaption><strong>Figure. 1 </strong>Image to be predicted</figcaption></figure><p>2.1.2 <strong>ResNet Implementation as Feature extraction</strong>(code)</p><p>Here we will use ResNet network to extract features of the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0</strong></pre><pre>resnet_pretrained = models.resnet(pretrained=True).to(device) <strong>#LINE 1</strong></pre><pre>resnet_pretrained.features                             <strong>#LINE 2</strong></pre><pre>summary(resnet_pretrained, (3, 224, 224))               <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the ResNet model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>ResNet(   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   (relu): ReLU(inplace=True)   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</pre><pre>(layer1): Sequential(     <br>(0): Bottleneck(       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(2): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer2): Sequential(     (0): Bottleneck(       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(2): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(3): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer3): Sequential(     (0): Bottleneck(       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(3): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(4): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(5): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer4): Sequential(     (0): Bottleneck(       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )</pre><pre>(2): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )</pre><pre>(avgpool): AdaptiveAvgPool2d(output_size=(1, 1))   (fc): Linear(in_features=2048, out_features=1000, bias=True) )</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the feature extractor layers which is shown below :</p><pre>/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)<br>  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)</pre><pre>----------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1         [-1, 64, 112, 112]           9,408<br>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br>              ReLU-3         [-1, 64, 112, 112]               0<br>         MaxPool2d-4           [-1, 64, 56, 56]               0<br>            Conv2d-5           [-1, 64, 56, 56]           4,096<br>       BatchNorm2d-6           [-1, 64, 56, 56]             128<br>              ReLU-7           [-1, 64, 56, 56]               0<br>            Conv2d-8           [-1, 64, 56, 56]          36,864<br>       BatchNorm2d-9           [-1, 64, 56, 56]             128<br>             ReLU-10           [-1, 64, 56, 56]               0<br>           Conv2d-11          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-12          [-1, 256, 56, 56]             512<br>           Conv2d-13          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-14          [-1, 256, 56, 56]             512<br>             ReLU-15          [-1, 256, 56, 56]               0<br>       Bottleneck-16          [-1, 256, 56, 56]               0<br>           Conv2d-17           [-1, 64, 56, 56]          16,384<br>      BatchNorm2d-18           [-1, 64, 56, 56]             128<br>             ReLU-19           [-1, 64, 56, 56]               0<br>           Conv2d-20           [-1, 64, 56, 56]          36,864<br>      BatchNorm2d-21           [-1, 64, 56, 56]             128<br>             ReLU-22           [-1, 64, 56, 56]               0<br>           Conv2d-23          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-24          [-1, 256, 56, 56]             512<br>             ReLU-25          [-1, 256, 56, 56]               0<br>       Bottleneck-26          [-1, 256, 56, 56]               0<br>           Conv2d-27           [-1, 64, 56, 56]          16,384<br>      BatchNorm2d-28           [-1, 64, 56, 56]             128<br>             ReLU-29           [-1, 64, 56, 56]               0<br>           Conv2d-30           [-1, 64, 56, 56]          36,864<br>      BatchNorm2d-31           [-1, 64, 56, 56]             128<br>             ReLU-32           [-1, 64, 56, 56]               0<br>           Conv2d-33          [-1, 256, 56, 56]          16,384<br>      BatchNorm2d-34          [-1, 256, 56, 56]             512<br>             ReLU-35          [-1, 256, 56, 56]               0<br>       Bottleneck-36          [-1, 256, 56, 56]               0<br>           Conv2d-37          [-1, 128, 56, 56]          32,768<br>      BatchNorm2d-38          [-1, 128, 56, 56]             256<br>             ReLU-39          [-1, 128, 56, 56]               0<br>           Conv2d-40          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-41          [-1, 128, 28, 28]             256<br>             ReLU-42          [-1, 128, 28, 28]               0<br>           Conv2d-43          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-44          [-1, 512, 28, 28]           1,024<br>           Conv2d-45          [-1, 512, 28, 28]         131,072<br>      BatchNorm2d-46          [-1, 512, 28, 28]           1,024<br>             ReLU-47          [-1, 512, 28, 28]               0<br>       Bottleneck-48          [-1, 512, 28, 28]               0<br>           Conv2d-49          [-1, 128, 28, 28]          65,536<br>      BatchNorm2d-50          [-1, 128, 28, 28]             256<br>             ReLU-51          [-1, 128, 28, 28]               0<br>           Conv2d-52          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-53          [-1, 128, 28, 28]             256<br>             ReLU-54          [-1, 128, 28, 28]               0<br>           Conv2d-55          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-56          [-1, 512, 28, 28]           1,024<br>             ReLU-57          [-1, 512, 28, 28]               0<br>       Bottleneck-58          [-1, 512, 28, 28]               0<br>           Conv2d-59          [-1, 128, 28, 28]          65,536<br>      BatchNorm2d-60          [-1, 128, 28, 28]             256<br>             ReLU-61          [-1, 128, 28, 28]               0<br>           Conv2d-62          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-63          [-1, 128, 28, 28]             256<br>             ReLU-64          [-1, 128, 28, 28]               0<br>           Conv2d-65          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-66          [-1, 512, 28, 28]           1,024<br>             ReLU-67          [-1, 512, 28, 28]               0<br>       Bottleneck-68          [-1, 512, 28, 28]               0<br>           Conv2d-69          [-1, 128, 28, 28]          65,536<br>      BatchNorm2d-70          [-1, 128, 28, 28]             256<br>             ReLU-71          [-1, 128, 28, 28]               0<br>           Conv2d-72          [-1, 128, 28, 28]         147,456<br>      BatchNorm2d-73          [-1, 128, 28, 28]             256<br>             ReLU-74          [-1, 128, 28, 28]               0<br>           Conv2d-75          [-1, 512, 28, 28]          65,536<br>      BatchNorm2d-76          [-1, 512, 28, 28]           1,024<br>             ReLU-77          [-1, 512, 28, 28]               0<br>       Bottleneck-78          [-1, 512, 28, 28]               0<br>           Conv2d-79          [-1, 256, 28, 28]         131,072<br>      BatchNorm2d-80          [-1, 256, 28, 28]             512<br>             ReLU-81          [-1, 256, 28, 28]               0<br>           Conv2d-82          [-1, 256, 14, 14]         589,824<br>      BatchNorm2d-83          [-1, 256, 14, 14]             512<br>             ReLU-84          [-1, 256, 14, 14]               0<br>           Conv2d-85         [-1, 1024, 14, 14]         262,144<br>      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048<br>           Conv2d-87         [-1, 1024, 14, 14]         524,288<br>      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048<br>             ReLU-89         [-1, 1024, 14, 14]               0<br>       Bottleneck-90         [-1, 1024, 14, 14]               0<br>           Conv2d-91          [-1, 256, 14, 14]         262,144<br>      BatchNorm2d-92          [-1, 256, 14, 14]             512<br>             ReLU-93          [-1, 256, 14, 14]               0<br>           Conv2d-94          [-1, 256, 14, 14]         589,824<br>      BatchNorm2d-95          [-1, 256, 14, 14]             512<br>             ReLU-96          [-1, 256, 14, 14]               0<br>           Conv2d-97         [-1, 1024, 14, 14]         262,144<br>      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048<br>             ReLU-99         [-1, 1024, 14, 14]               0<br>      Bottleneck-100         [-1, 1024, 14, 14]               0<br>          Conv2d-101          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-102          [-1, 256, 14, 14]             512<br>            ReLU-103          [-1, 256, 14, 14]               0<br>          Conv2d-104          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-105          [-1, 256, 14, 14]             512<br>            ReLU-106          [-1, 256, 14, 14]               0<br>          Conv2d-107         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048<br>            ReLU-109         [-1, 1024, 14, 14]               0<br>      Bottleneck-110         [-1, 1024, 14, 14]               0<br>          Conv2d-111          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-112          [-1, 256, 14, 14]             512<br>            ReLU-113          [-1, 256, 14, 14]               0<br>          Conv2d-114          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-115          [-1, 256, 14, 14]             512<br>            ReLU-116          [-1, 256, 14, 14]               0<br>          Conv2d-117         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048<br>            ReLU-119         [-1, 1024, 14, 14]               0<br>      Bottleneck-120         [-1, 1024, 14, 14]               0<br>          Conv2d-121          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-122          [-1, 256, 14, 14]             512<br>            ReLU-123          [-1, 256, 14, 14]               0<br>          Conv2d-124          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-125          [-1, 256, 14, 14]             512<br>            ReLU-126          [-1, 256, 14, 14]               0<br>          Conv2d-127         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048<br>            ReLU-129         [-1, 1024, 14, 14]               0<br>      Bottleneck-130         [-1, 1024, 14, 14]               0<br>          Conv2d-131          [-1, 256, 14, 14]         262,144<br>     BatchNorm2d-132          [-1, 256, 14, 14]             512<br>            ReLU-133          [-1, 256, 14, 14]               0<br>          Conv2d-134          [-1, 256, 14, 14]         589,824<br>     BatchNorm2d-135          [-1, 256, 14, 14]             512<br>            ReLU-136          [-1, 256, 14, 14]               0<br>          Conv2d-137         [-1, 1024, 14, 14]         262,144<br>     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048<br>            ReLU-139         [-1, 1024, 14, 14]               0<br>      Bottleneck-140         [-1, 1024, 14, 14]               0<br>          Conv2d-141          [-1, 512, 14, 14]         524,288<br>     BatchNorm2d-142          [-1, 512, 14, 14]           1,024<br>            ReLU-143          [-1, 512, 14, 14]               0<br>          Conv2d-144            [-1, 512, 7, 7]       2,359,296<br>     BatchNorm2d-145            [-1, 512, 7, 7]           1,024<br>            ReLU-146            [-1, 512, 7, 7]               0<br>          Conv2d-147           [-1, 2048, 7, 7]       1,048,576<br>     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096<br>          Conv2d-149           [-1, 2048, 7, 7]       2,097,152<br>     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096<br>            ReLU-151           [-1, 2048, 7, 7]               0<br>      Bottleneck-152           [-1, 2048, 7, 7]               0<br>          Conv2d-153            [-1, 512, 7, 7]       1,048,576<br>     BatchNorm2d-154            [-1, 512, 7, 7]           1,024<br>            ReLU-155            [-1, 512, 7, 7]               0<br>          Conv2d-156            [-1, 512, 7, 7]       2,359,296<br>     BatchNorm2d-157            [-1, 512, 7, 7]           1,024<br>            ReLU-158            [-1, 512, 7, 7]               0<br>          Conv2d-159           [-1, 2048, 7, 7]       1,048,576<br>     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096<br>            ReLU-161           [-1, 2048, 7, 7]               0<br>      Bottleneck-162           [-1, 2048, 7, 7]               0<br>          Conv2d-163            [-1, 512, 7, 7]       1,048,576<br>     BatchNorm2d-164            [-1, 512, 7, 7]           1,024<br>            ReLU-165            [-1, 512, 7, 7]               0<br>          Conv2d-166            [-1, 512, 7, 7]       2,359,296<br>     BatchNorm2d-167            [-1, 512, 7, 7]           1,024<br>            ReLU-168            [-1, 512, 7, 7]               0<br>          Conv2d-169           [-1, 2048, 7, 7]       1,048,576<br>     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096<br>            ReLU-171           [-1, 2048, 7, 7]               0<br>      Bottleneck-172           [-1, 2048, 7, 7]               0<br>AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0<br>          Linear-174                 [-1, 1000]       2,049,000<br>================================================================<br>Total params: 25,557,032<br>Trainable params: 25,557,032<br>Non-trainable params: 0<br>----------------------------------------------------------------<br>Input size (MB): 0.57<br>Forward/backward pass size (MB): 286.56<br>Params size (MB): 97.49<br>Estimated Total Size (MB): 384.62<br>----------------------------------------------------------------</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>resnet_prediction=resnet_pretrained.features(x)               <strong>#Line 4</strong></pre><pre>resnet_prediction_numpy=resnet_prediction.detach().numpy()   <strong>#Line 5</strong></pre><p><strong>Line 4: </strong>This snippet is used to feed the image to the feature extractor layer of the VGG network</p><p><strong>Line 5: </strong>This snippet is used to detach the output from the GPU to CPU.</p><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1000) </em>and for the training set it will be of<em>(50000,1,1000), f</em>or test set it will be of<em>(10000,1,1000) size.</em></p><h3>Trending Bot Articles:</h3><blockquote><a href="https://chatbotslife.com/how-conversational-ai-can-automate-customer-service-ce1e6e330902">1. How Conversational AI can Automate Customer Service</a></blockquote><blockquote><a href="https://chatbotslife.com/automated-vs-live-chats-what-will-the-future-of-customer-service-look-like-69c90432c8f4">2. Automated vs Live Chats: What will the Future of Customer Service Look Like?</a></blockquote><blockquote><a href="https://chatbotslife.com/chatbots-as-medical-assistants-in-covid-19-pandemic-3d2731b85128">3. Chatbots As Medical Assistants In COVID-19 Pandemic</a></blockquote><blockquote><a href="https://chatbotslife.com/chatbot-vs-intelligent-virtual-assistant-whats-the-difference-why-care-180aebde9358">4. Chatbot Vs. Intelligent Virtual Assistant — What’s the difference &amp; Why Care?</a></blockquote><p>2.2 <strong>Using ResNet Architecture(</strong>without weights<strong>)</strong></p><p>In this section we will see how we can implement ResNet as a architecture in Keras. We will use state of the art ResNetnetwork architecture and train it with our datasets from scratch i.e. we will not use pre-trained weights in this architecture the weights will be optimized while training from scratch. The code is explained below:</p><p>2.2.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 datasets composed of 60K images, 50K for training and 10K for testing/evaluation.</p><pre>import os</pre><pre>import torch</pre><pre>import torchvision</pre><pre>import torchvision.models as models</pre><pre>import tarfile</pre><pre>from torchvision.datasets.utils import download_url</pre><pre>from torch.utils.data import random_split</pre><pre>from skimage import io, transform</pre><pre>import torchvision.transforms as transforms</pre><pre>from torchvision.datasets import ImageFolder</pre><pre>from torchvision.transforms import ToTensor,Resize</pre><pre>import matplotlib</pre><pre>import matplotlib.pyplot as plt</pre><pre>from torchvision.utils import make_grid</pre><pre>from torch.utils.data.dataloader import DataLoader</pre><pre>%matplotlib inline</pre><pre>matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;</pre><pre>download_url(dataset_url, &#39;.&#39;)</pre><pre>with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:</pre><pre>tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the datasets from the AWS server in our environment and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])</pre><pre>dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)</pre><pre>print(dataset.classes)</pre><p>The above snippets is used to transform the datasets into PyTorch datasets by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the datasets into two set i.e. test set and train set.</p><pre>val_size = 5000</pre><pre>train_size = len(dataset) - val_size</pre><pre>train_ds, val_ds = random_split(dataset, [train_size, val_size])</pre><pre>len(train_ds), len(val_ds)</pre><pre>batch_size=32</pre><pre>train_dl = DataLoader(train_ds, batch_size, shuffle=True)</pre><pre>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the datasets as shown below:</p><pre>def show_batch(dl):</pre><pre>for images, labels in dl:</pre><pre>fig, ax = plt.subplots(figsize=(12, 6))</pre><pre>ax.set_xticks([]); ax.set_yticks([])</pre><pre>ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))</pre><pre>break</pre><pre>show_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/1*t_R_XEdu-zKwBKvB2YcXbQ.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p>2.2.2 <strong>ResNet Architecture</strong>(code)</p><p>In this section we will see how we can implement ResNet as a architecture in Keras.</p><pre>resnet_pretrained = models.resnet50()</pre><pre>resnet_pretrained.fc=torch.nn.Linear(resnet_pretrained.fc.in_features, 10)</pre><pre>for param in resnet_pretrained.fc.parameters():<br>    param.requires_grad = True</pre><p>The above snippet is used to initiate the object for the ResNet model.Since we are using the ResNet as a architecture with our custom datasets so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The line has 10 neurons with Softmax activation function which allow us to predict the probabilities of each classes đrom the neural network. the architecture is shown below:</p><pre>ResNet(   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   (relu): ReLU(inplace=True)   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)   </pre><pre>(layer1): Sequential(     (0): Bottleneck(       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(2): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer2): Sequential(     (0): Bottleneck(       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(2): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(3): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer3): Sequential(     (0): Bottleneck(       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(4): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(5): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer4): Sequential(     (0): Bottleneck(       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     </pre><pre>(2): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   </pre><pre>(avgpool): AdaptiveAvgPool2d(output_size=(1, 1))   (fc): Linear(in_features=2048, out_features=10, bias=True) )</pre><p>Now after creating model we have to test the model that it is producing the correct output which can be done with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>print(&#39;images.shape:&#39;, images.shape)</pre><pre>out = Vgg16_pretrained(images)</pre><pre>print(&#39;out.shape:&#39;, out.shape)</pre><pre>print(&#39;out[0]:&#39;, out[0])</pre><pre>break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(resnet_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>    print(epoch)</pre><pre>    a=0</pre><pre>    for images, labels in iter(train_dl):</pre><pre>        print(epoch,a)</pre><pre>        a=a+1</pre><pre>        optimizer.zero_grad()</pre><pre>        outputs = resnet_pretrained(images)</pre><pre>        loss = F.cross_entropy(outputs, labels)</pre><pre>        loss.backward()</pre><pre>        optimizer.step()</pre><pre>        a=a+1</pre><pre>        test_error_count = 0.0</pre><pre>     for images, labels in iter(test_dl):</pre><pre>          outputs = resnet_pretrained(images)</pre><pre>     test_error_count += float(torch.sum(torch.abs(labels -   <br>      outputs.argmax(1))))</pre><pre>    test_accuracy = 1.0 - float(test_error_count) /    <br>     float(len(test_dataset))</pre><pre>    print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have trained our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  resnet_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used ResNet architecture to train on our custom datasets.</p><h4>2.3. Fine Turning ResNet Architecture with Custom Fully Connected layers</h4><p>In this section we will see how we can implement ResNet as a architecture in PyTorch. We will use state of the art ResNet network architecture and train it with our dataset from scratch i.e. we will use pre-trained weights in this architecture the weights will be optimised while training from scratch only for the fully connected layers but the code for the pre-trained layers remains as it is. The code is explained below:</p><p>2.3.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>mport os</pre><pre>import torch</pre><pre>import torchvision</pre><pre>import torchvision.models as models</pre><pre>import tarfile</pre><pre>from torchvision.datasets.utils import download_url</pre><pre>from torch.utils.data import random_split</pre><pre>from skimage import io, transform</pre><pre>import torchvision.transforms as transforms</pre><pre>from torchvision.datasets import ImageFolder</pre><pre>from torchvision.transforms import ToTensor,Resize</pre><pre>import matplotlib</pre><pre>import matplotlib.pyplot as plt</pre><pre>from torchvision.utils import make_grid</pre><pre>from torch.utils.data.dataloader import DataLoader</pre><pre>%matplotlib inline</pre><pre>matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;</pre><pre>download_url(dataset_url, &#39;.&#39;)</pre><pre>with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:</pre><pre>tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the dataset from the AWS server in our enviromenet and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])</pre><pre>dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)</pre><pre>print(dataset.classes)</pre><p>The above snippets is used to tranform the dataset into PyTorch dataset by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the dataset into two set i.e. test set and train set.</p><pre>val_size = 5000</pre><pre>train_size = len(dataset) - val_size</pre><pre>train_ds, val_ds = random_split(dataset, [train_size, val_size])</pre><pre>len(train_ds), len(val_ds)</pre><pre>batch_size=32</pre><pre>train_dl = DataLoader(train_ds, batch_size, shuffle=True)</pre><pre>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the dataset as shown below:</p><pre>def show_batch(dl):</pre><pre>for images, labels in dl:</pre><pre>fig, ax = plt.subplots(figsize=(12, 6))</pre><pre>ax.set_xticks([]); ax.set_yticks([])</pre><pre>ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))</pre><pre>break</pre><pre>show_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/1*t_R_XEdu-zKwBKvB2YcXbQ.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p><strong>2.3.2</strong><strong>ResNet Fully Connected Layer Optimisation(code)</strong></p><p>In this section we will see how we can implement ResNet as a architecture in PyTorch.</p><pre>resnet_pretrained = models.resnet50(pretrained=True)</pre><pre>from collections import OrderedDict</pre><pre>for param in resnet_pretrained.parameters():</pre><pre>    param.requires_grad = True</pre><pre>resnet_pretrained.fc=torch.nn.Sequential(OrderedDict([</pre><pre>(&#39;fc1&#39;,torch.nn.Linear(resnet_pretrained.fc.in_features, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in resnet_pretrained.fc.parameters():<br>    param.requires_grad = True</pre><p>The above snippet is used to initiate the object for the ResNet model.Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The pre-trained weight weights are specified <em>param.requires_grad = False s</em>o that the loss is not propagated back to these layers where as<em>in fully connected layers param.requires_grad = True </em>which allows loss to propagate back only in this layers<em>.</em>The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>ResNet(   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   (relu): ReLU(inplace=True)   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)   (layer1): Sequential(     (0): Bottleneck(       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer2): Sequential(     (0): Bottleneck(       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer3): Sequential(     (0): Bottleneck(       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (4): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (5): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer4): Sequential(     (0): Bottleneck(       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))   (fc): Sequential(     (fc1): Linear(in_features=2048, out_features=10, bias=True)     (activation1): Softmax(dim=None)   ) )</pre><p>Now after creating model we have to test the model that it is producing the correct output which can be done with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>    print(&#39;images.shape:&#39;, images.shape)</pre><pre>    out = resnet_pretrained(images)</pre><pre>    print(&#39;out.shape:&#39;, out.shape)</pre><pre>    print(&#39;out[0]:&#39;, out[0])</pre><pre>    break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(resnet_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>    print(epoch)</pre><pre>    a=0</pre><pre>    for images, labels in iter(train_dl):</pre><pre>        print(epoch,a)</pre><pre>        a=a+1</pre><pre>        optimizer.zero_grad()</pre><pre>        outputs = resnet_pretrained(images)</pre><pre>        loss = F.cross_entropy(outputs, labels)</pre><pre>        loss.backward()</pre><pre>        optimizer.step()</pre><pre>        a=a+1</pre><pre>        test_error_count = 0.0</pre><pre>        for images, labels in iter(test_dl):</pre><pre>             outputs = Vgg16_pretrained(images)</pre><pre>         test_error_count += float(torch.sum(torch.abs(labels -   <br><br>              outputs.argmax(1))))</pre><pre>    test_accuracy = 1.0 - float(test_error_count) /    <br>   float(len(test_dataset))</pre><pre>print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have traioned our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  resnet_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finsally we have used ResNet architecture to train on our cvustom dataset.</p><h4>2.4. ResNet weights as a neural network weight initializer</h4><p>In this section we will see how we can implement ResNet as a weight initializer in PyTorch. We will use state of the art ResNet network architecture and train it with our dataset from scratch i.e. we will use pre-trained weights in this architecture the weights will be optimised while training from scratch only for the fully connected layers but the code for the pre-trained layers remains as it is. The code is explained below:</p><p>2.4.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>mport os</pre><pre>import torch</pre><pre>import torchvision</pre><pre>import torchvision.models as models</pre><pre>import tarfile</pre><pre>from torchvision.datasets.utils import download_url</pre><pre>from torch.utils.data import random_split</pre><pre>from skimage import io, transform</pre><pre>import torchvision.transforms as transforms</pre><pre>from torchvision.datasets import ImageFolder</pre><pre>from torchvision.transforms import ToTensor,Resize</pre><pre>import matplotlib</pre><pre>import matplotlib.pyplot as plt</pre><pre>from torchvision.utils import make_grid</pre><pre>from torch.utils.data.dataloader import DataLoader</pre><pre>%matplotlib inline</pre><pre>matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;</pre><pre>download_url(dataset_url, &#39;.&#39;)</pre><pre>with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:</pre><pre>tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the dataset from the AWS server in our enviromenet and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])</pre><pre>dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)</pre><pre>print(dataset.classes)</pre><p>The above snippets is used to tranform the dataset into PyTorch dataset by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the dataset into two set i.e. test set and train set.</p><pre>val_size = 5000</pre><pre>train_size = len(dataset) - val_size</pre><pre>train_ds, val_ds = random_split(dataset, [train_size, val_size])</pre><pre>len(train_ds), len(val_ds)</pre><pre>batch_size=32</pre><pre>train_dl = DataLoader(train_ds, batch_size, shuffle=True)</pre><pre>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the dataset as shown below:</p><pre>def show_batch(dl):</pre><pre>for images, labels in dl:</pre><pre>fig, ax = plt.subplots(figsize=(12, 6))</pre><pre>ax.set_xticks([]); ax.set_yticks([])</pre><pre>ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))</pre><pre>break</pre><pre>show_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/1*t_R_XEdu-zKwBKvB2YcXbQ.png" /><figcaption>Figure 2. Sample CIFAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p><strong>2.4.2</strong><strong>ResNet weights as a initialiser (code)</strong></p><p>In this section we will see how we can implement ResNet as a architecture in PyTorch.</p><pre>pretrained = models.resnet50(pretrained=True)</pre><pre>for param in pretrained.parameters():<br>   param.requires_grad = True</pre><pre>pretrained.fc=torch.nn.Sequential(OrderedDict([(&#39;fc1&#39;,torch.nn.Linear(pretrained.fc.in_features, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in pretrained.classifier[6].parameters():<br>    param.requires_grad = True</pre><pre>pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The pre-trained weight weights are specified <em>param.requires_grad = False s</em>o that the loss is not propagated back to these layers where as<em>in fully connected layers param.requires_grad = True </em>which allows loss to propagate back only in this layers<em>.</em>The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>ResNet(   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)   (relu): ReLU(inplace=True)   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)   (layer1): Sequential(     (0): Bottleneck(       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer2): Sequential(     (0): Bottleneck(       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer3): Sequential(     (0): Bottleneck(       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (3): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (4): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (5): Bottleneck(       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (layer4): Sequential(     (0): Bottleneck(       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)       (downsample): Sequential(         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       )     )     (1): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )     (2): Bottleneck(       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)       (relu): ReLU(inplace=True)     )   )   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))   (fc): Sequential(     (fc1): Linear(in_features=2048, out_features=10, bias=True)     (activation1): Softmax(dim=None)   ) )</pre><p>Now after creating model we have to test the model that it is producing the correct output which can be done with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>    print(&#39;images.shape:&#39;, images.shape)</pre><pre>    out = Vgg16_pretrained(images)</pre><pre>    print(&#39;out.shape:&#39;, out.shape)</pre><pre>    print(&#39;out[0]:&#39;, out[0])</pre><pre>    break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>    print(epoch)</pre><pre>    a=0</pre><pre>    for images, labels in iter(train_dl):</pre><pre>        print(epoch,a)</pre><pre>        a=a+1</pre><pre>        optimizer.zero_grad()</pre><pre>        outputs = pretrained(images)</pre><pre>        loss = F.cross_entropy(outputs, labels)</pre><pre>        loss.backward()</pre><pre>        optimizer.step()</pre><pre>        a=a+1</pre><pre>        test_error_count = 0.0</pre><pre>     for images, labels in iter(test_dl):</pre><pre>         outputs = Vgg16_pretrained(images)</pre><pre>         test_error_count += float(torch.sum(torch.abs(labels -   <br><br>        outputs.argmax(1))))</pre><pre>      test_accuracy = 1.0 - float(test_error_count) /    <br>   float(len(test_dataset))</pre><pre>    print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have traioned our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used ResNet architechture to train on our custom dataset.</p><p>In this article we have discussed about the pre-trained ResNet models with implementation in PyTorch. In next article we will discuss ResNet model. Stay Tuned!!!!</p><p><em>Need help ??? Consult with me on DDI :)</em></p><p><a href="https://app.ddichat.com/experts/ravi-shekhar-tiwari/">Ravi Shekhar TIwari - DDIChat</a></p><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote>Pytorch: <a href="https://pytorch.org/get-started/locally/#windows-python">Link</a></blockquote><blockquote>Keras: <a href="https://keras.io/">Link</a></blockquote><blockquote>Tensorflow: <a href="https://www.tensorflow.org/guide/keras/sequential_model">Link</a></blockquote><blockquote>ResNet Paper:</blockquote><blockquote><em>Imagenet Dataset: </em><a href="https://www.image-net.org/"><em>Link</em></a></blockquote><blockquote><em>ILSVRC : </em><a href="https://www.image-net.org/challenges/LSVRC/index.php"><em>Link</em></a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote>YouTube : <a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ">Lin</a>k</blockquote><blockquote>Website: <a href="http://www.rstiwari.com/">www.rstiwari.com</a></blockquote><blockquote>Medium: <a href="https://tiwari11-rst.medium.com/">https://tiwari11-rst.medium.com</a></blockquote><blockquote>Github Pages: <a href="https://happyman11.github.io/">https://happyman11.github.io/</a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Google Form: <a href="https://forms.gle/mhDYQKQJKtAKP78V7">https://forms.gle/mhDYQKQJKtAKP78V7</a></blockquote><h3>Don’t forget to give us your 👏 !</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/0*2lvCls4yjxVMfZSR" /></figure><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fupscri.be%2F8f5f8b%3Fas_embed%3Dtrue&amp;dntp=1&amp;url=https%3A%2F%2Fupscri.be%2F8f5f8b&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=upscri" width="800" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href">https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href</a></iframe><figure><a href="https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*2f7OqE2AJK1KSrhkmD9ZMw.png" /></a></figure><figure><a href="https://upscri.be/8f5f8b"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*v-PpfkSWHbvlWWamSVHHWg.png" /></a></figure><figure><a href="https://becominghuman.ai/write-for-us-48270209de63"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*Wt2auqISiEAOZxJ-I7brDQ.png" /></a></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fe87f2821f83" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-5-2-implementing-resnet-in-pytorch-fe87f2821f83">Transfer Learning — Part — 5.2!! Implementing ResNet in PyTorch</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 5.1!! Implementing ResNet in Keras]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-5-1-implementing-resnet-in-keras-455afbc28657?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/455afbc28657</guid>
    <category>
        <![CDATA[resnet]]>
    </category>
    <category>
        <![CDATA[keras]]>
    </category>
    <category>
        <![CDATA[deep-learning]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[artificial-intelligence]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Sat, 18 Dec 2021 11:59:09 GMT</pubDate>
    <atom:updated>2022-03-06T17:51:45.181Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 5.1!! Implementing ResNet in Keras</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*BuJ-xkul8-yknI0j.jpg" /><figcaption><strong>Figure.1</strong> Transfer Learning</figcaption></figure><p>In Part 5.0 of the Transfer Learning series we have discussed about ResNet pre-trained model in depth so in this series we will implement the above mentioned pre-trained model in Keras. We will be implementing the pre-trained ResNet model in 4 ways which we will discuss further in this article. For setting- up the Colab notebook it will be advisable to go through the below mentioned article of Transfer Learning Series.</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>It is also advisable to go through the article of ResNetbefore reading this article which is mentioned below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-5-0-residualnets-48d42368eb71">Transfer Learning — Part — 5.0!! ResidualNets</a></p><h3>1. Implementing ResNet Pre-trained model</h3><p>In this section we will see how we can implement ResNet model in keras to have a foundation to start our real implementation .</p><p><strong>1.1. Image which we will predict on</strong></p><p>We will use the image of the coffee mug to predict the labels with the ResNet architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image = tf.keras.preprocessing.image.load_img(link_of_image, target_size=(224, 224))                                    <strong>#Line 2<br></strong>image = tf.keras.preprocessing.image.img_to_array(image)   <strong>#Line 3<br></strong>image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))                                            <strong>#Line 4<br></strong>image = tf.keras.applications.resnet50.preprocess_input(image)</pre><pre><strong>#Line 5</strong></pre><p><strong>Line 2: </strong>This snippet loads the images with size of (224,224).</p><p><strong>Line 3: </strong>This snippet converts the image into array for further pre-processing.</p><p><strong>Line 4: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 5: </strong>This snippet use to pre process the image according to the ResNet architecture.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/0*iQutDUOfC6oZ67Oe.jpeg" /><figcaption><strong>Figure. 1</strong> Image to be predicted</figcaption></figure><p><strong>1.2. ResNet Implementation</strong></p><p>Here we will use ResNet network to predict on the coffee mug image code is demonstrated below.</p><pre>rESNET50_pre_trained=   tf.keras.applications.ResNet50(include_top=True, weights=&#39;imagenet&#39;, input_tensor=None,input_shape=(224, 224, 3), pooling=&#39;max&#39;,classes=1000,classifier_activation=&#39;softmax&#39;)<strong>#Line 1</strong></pre><pre>print(rESNET50_pre_trained.summary())  <strong>#Line 2</strong></pre><p><strong>Line 1:</strong> This snippets is used to create an object for the ResNet model by including all its layer, specifying input shape to —<em>input_shape=(224, 224, 3), </em>pooling is set to max pooling<em>pooling=’max’, </em>since no. of classes in 1000 in ImageNet we also have set the classes to 1000 here classes=1000<strong> </strong>and classifier_ layer activation to softmax i.e.<em>classifier_activation=’softmax’.</em></p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>Model: &quot;resnet50&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_3 (InputLayer)            [(None, 224, 224, 3) 0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]            __________________________________________________________________________________________________ avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]            __________________________________________________________________________________________________ predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                    ================================================================================================== Total params: 25,636,712 Trainable params: 25,583,592 Non-trainable params: 53,120 __________________________________________________________________________________________________ None</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>resnet_prediction = rESNET50_pre_trained.predict(image) <strong>#Line 3</strong></pre><pre>Top_predictions=tf.keras.applications.resnet50.decode_predictions(resnet_prediction , top=5) <strong>#Line 4</strong></pre><pre>Top_predictions <strong>#Line 5</strong></pre><p><strong>Line 3:</strong> This snippets send the pre-processed image to the ResNet network for getting prediction.</p><p><strong>Line 4 and Line 5: </strong>These two line accept the prediction from the model and output the top 5 prediction probabilities which is shown below.</p><pre>Downloading data from <a href="https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json">https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json</a><br>40960/35363 [==================================] - 0s 0us/step<br>49152/35363 [=========================================] - 0s 0us/step</pre><pre>[[(&#39;n03063599&#39;, &#39;coffee_mug&#39;, 0.9719216),<br>  (&#39;n04398044&#39;, &#39;teapot&#39;, 0.00816639),<br>  (&#39;n07930864&#39;, &#39;cup&#39;, 0.0068901684),<br>  (&#39;n03950228&#39;, &#39;pitcher&#39;, 0.0063208146),<br>  (&#39;n03063689&#39;, &#39;coffeepot&#39;, 0.005167215)]]</pre><h3>2. Application of ResNet Network</h3><p>As I have mentioned above, we will discuss implementation of the pre-trained ResNet model in 4 ways which are as follows:</p><ol><li><strong>As a feature Extraction model.</strong></li><li><strong>Using Pre-trained models ResNet architecture.</strong></li><li><strong>Fine tunning Pre-trained models ResNet architecture.</strong></li><li><strong>Using Pre-trained model weights as a weight initialiser.</strong></li></ol><p>So without any further delay lets start our implementation in Keras :).</p><h3>2.1. As a feature Extraction model.</h3><p>Since we have discussed the ResNet model in details in out previous article i.e. in part 5.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained ResNet to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2</strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape))<strong>#Line 3</strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))<strong>#Line 4</strong>for i in range(9):<strong>#Line 5</strong># define subplotpyplot.subplot(330 + 1 + i)<strong>#Line 6</strong># plot raw pixel datapyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))<strong>#Line 7</strong># show the figurepyplot.show()<strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the dataset as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/0*CArSldae72YVAZnv.png" /><figcaption>2. Application of Resnet Network</figcaption></figure><p>As I have mentioned above, we will discuss implementation of the pre-trained Resnet model in 4 ways which are as follows:</p><ol><li><strong>As a feature Extraction model.</strong></li><li><strong>Using Pre-trained models Resnet architechture.</strong></li><li><strong>Fine tunning Pre-trained models Resnet architechture.</strong></li><li><strong>Using Pre-trained model weights as a weight initialiser.</strong></li></ol><p>So without any further delay lets start our implementation in Keras :).</p><figure><a href="https://aijobsboard.com/?fbclid=IwAR0GcsLs8A6CFM-fynrZMM3sTgo_Zpbto2CjglJm0Dmi6otC6YWc7CDFpQk"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dAlwXfVrtYspdCzmC8iADw.png" /></a><figcaption>Big Data Jobs</figcaption></figure><h3>2.1. As a feature Extraction model.</h3><p>Since we have discussed the VGG -16 and VGG- 19 model in details in out previous article i.e. in part 4.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained Resnet to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2</strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape))<strong>#Line 3</strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))<strong>#Line 4</strong>for i in range(9):<strong>#Line 5</strong># define subplotpyplot.subplot(330 + 1 + i)<strong>#Line 6</strong># plot raw pixel datapyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))<strong>#Line 7</strong># show the figurepyplot.show()<strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the dataset as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/0*v8x4_dHitdiycVfA.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9</strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)<strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.1.2 ResNet Implementation as Feature extraction(code)</h3><p>In this section we will see how we can implement ResNet as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong>#Line 2</strong></pre><pre>baseModel = tf.keras.applications.ResNet50(include_top=False,weights=&#39;imagenet&#39;,input_tensor=image_input).                            <strong>#Line 3</strong></pre><pre>baseModel.summary()                                  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained ResNet with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the ResNet model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;resnet50&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_8 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_8[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            ================================================================================================== Total params: 23,587,712 Trainable params: 23,534,592 Non-trainable params: 53,120 __________________________________________________________________________________________________</pre><h3>Trending AI Articles:</h3><blockquote><a href="https://becominghuman.ai/why-corporate-ai-projects-fail-part-1-4-3b820041ab00">1. Why Corporate AI projects fail?</a></blockquote><blockquote><a href="https://becominghuman.ai/how-ai-will-power-the-next-wave-of-healthcare-innovation-695a2196aae8">2. How AI Will Power the Next Wave of Healthcare Innovation?</a></blockquote><blockquote><a href="https://becominghuman.ai/machine-learning-by-using-regression-model-f0c7993a66c8">3. Machine Learning by Using Regression Model</a></blockquote><blockquote><a href="https://becominghuman.ai/top-data-science-platforms-in-2021-other-than-kaggle-a1b4609c06b0">4. Top Data Science Platforms in 2021 Other than Kaggle</a></blockquote><p>Since we are using the ResNet as a architecture with our custom dataset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel.layers):  <strong>#Line 5</strong></pre><pre>    layer.trainable=False                           <strong>#Line 6</strong><br>    print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre>Layer Number : 0 Layer Name : input_8 Layer Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0 Layer Number : 1 Layer Name : conv1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 38, 38, 3) ) is Trainable: False No of Parameter : 0 Layer Number : 2 Layer Name : conv1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 38, 38, 3) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 9472 Layer Number : 3 Layer Name : conv1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 4 Layer Name : conv1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 5 Layer Name : pool1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 18, 18, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 6 Layer Name : pool1_pool Layer Shape(Input_Shape,Output Shape) : ( (None, 18, 18, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 7 Layer Name : conv2_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 4160 Layer Number : 8 Layer Name : conv2_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 9 Layer Name : conv2_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 10 Layer Name : conv2_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 36928 Layer Number : 11 Layer Name : conv2_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 12 Layer Name : conv2_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 13 Layer Name : conv2_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 16640 Layer Number : 14 Layer Name : conv2_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 16640 Layer Number : 15 Layer Name : conv2_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 16 Layer Name : conv2_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 17 Layer Name : conv2_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 256), (None, 8, 8, 256)] (None, 8, 8, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 18 Layer Name : conv2_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 19 Layer Name : conv2_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 16448 Layer Number : 20 Layer Name : conv2_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 21 Layer Name : conv2_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 22 Layer Name : conv2_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 36928 Layer Number : 23 Layer Name : conv2_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 24 Layer Name : conv2_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 25 Layer Name : conv2_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 16640 Layer Number : 26 Layer Name : conv2_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 27 Layer Name : conv2_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 256), (None, 8, 8, 256)] (None, 8, 8, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 28 Layer Name : conv2_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 29 Layer Name : conv2_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 16448 Layer Number : 30 Layer Name : conv2_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 31 Layer Name : conv2_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 32 Layer Name : conv2_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 36928 Layer Number : 33 Layer Name : conv2_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 256 Layer Number : 34 Layer Name : conv2_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: False No of Parameter : 0 Layer Number : 35 Layer Name : conv2_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 16640 Layer Number : 36 Layer Name : conv2_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 37 Layer Name : conv2_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 256), (None, 8, 8, 256)] (None, 8, 8, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 38 Layer Name : conv2_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 39 Layer Name : conv3_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 32896 Layer Number : 40 Layer Name : conv3_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 41 Layer Name : conv3_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 42 Layer Name : conv3_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 147584 Layer Number : 43 Layer Name : conv3_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 44 Layer Name : conv3_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 45 Layer Name : conv3_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 131584 Layer Number : 46 Layer Name : conv3_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 66048 Layer Number : 47 Layer Name : conv3_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 48 Layer Name : conv3_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 49 Layer Name : conv3_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 50 Layer Name : conv3_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 51 Layer Name : conv3_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 65664 Layer Number : 52 Layer Name : conv3_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 53 Layer Name : conv3_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 54 Layer Name : conv3_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 147584 Layer Number : 55 Layer Name : conv3_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 56 Layer Name : conv3_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 57 Layer Name : conv3_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 66048 Layer Number : 58 Layer Name : conv3_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 59 Layer Name : conv3_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 60 Layer Name : conv3_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 61 Layer Name : conv3_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 65664 Layer Number : 62 Layer Name : conv3_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 63 Layer Name : conv3_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 64 Layer Name : conv3_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 147584 Layer Number : 65 Layer Name : conv3_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 66 Layer Name : conv3_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 67 Layer Name : conv3_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 66048 Layer Number : 68 Layer Name : conv3_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 69 Layer Name : conv3_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 70 Layer Name : conv3_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 71 Layer Name : conv3_block4_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 65664 Layer Number : 72 Layer Name : conv3_block4_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 73 Layer Name : conv3_block4_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 74 Layer Name : conv3_block4_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 147584 Layer Number : 75 Layer Name : conv3_block4_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 512 Layer Number : 76 Layer Name : conv3_block4_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: False No of Parameter : 0 Layer Number : 77 Layer Name : conv3_block4_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 66048 Layer Number : 78 Layer Name : conv3_block4_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 79 Layer Name : conv3_block4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 80 Layer Name : conv3_block4_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 81 Layer Name : conv4_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 131328 Layer Number : 82 Layer Name : conv4_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 83 Layer Name : conv4_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 84 Layer Name : conv4_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 590080 Layer Number : 85 Layer Name : conv4_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 86 Layer Name : conv4_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 87 Layer Name : conv4_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 525312 Layer Number : 88 Layer Name : conv4_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 263168 Layer Number : 89 Layer Name : conv4_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 90 Layer Name : conv4_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 91 Layer Name : conv4_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 92 Layer Name : conv4_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 93 Layer Name : conv4_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 262400 Layer Number : 94 Layer Name : conv4_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 95 Layer Name : conv4_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 96 Layer Name : conv4_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 590080 Layer Number : 97 Layer Name : conv4_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 98 Layer Name : conv4_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 99 Layer Name : conv4_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 263168 Layer Number : 100 Layer Name : conv4_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 101 Layer Name : conv4_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 102 Layer Name : conv4_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 103 Layer Name : conv4_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 262400 Layer Number : 104 Layer Name : conv4_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 105 Layer Name : conv4_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 106 Layer Name : conv4_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 590080 Layer Number : 107 Layer Name : conv4_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 108 Layer Name : conv4_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 109 Layer Name : conv4_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 263168 Layer Number : 110 Layer Name : conv4_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 111 Layer Name : conv4_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 112 Layer Name : conv4_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 113 Layer Name : conv4_block4_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 262400 Layer Number : 114 Layer Name : conv4_block4_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 115 Layer Name : conv4_block4_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 116 Layer Name : conv4_block4_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 590080 Layer Number : 117 Layer Name : conv4_block4_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 118 Layer Name : conv4_block4_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 119 Layer Name : conv4_block4_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 263168 Layer Number : 120 Layer Name : conv4_block4_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 121 Layer Name : conv4_block4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 122 Layer Name : conv4_block4_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 123 Layer Name : conv4_block5_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 262400 Layer Number : 124 Layer Name : conv4_block5_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 125 Layer Name : conv4_block5_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 126 Layer Name : conv4_block5_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 590080 Layer Number : 127 Layer Name : conv4_block5_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 128 Layer Name : conv4_block5_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 129 Layer Name : conv4_block5_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 263168 Layer Number : 130 Layer Name : conv4_block5_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 131 Layer Name : conv4_block5_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 132 Layer Name : conv4_block5_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 133 Layer Name : conv4_block6_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 262400 Layer Number : 134 Layer Name : conv4_block6_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 135 Layer Name : conv4_block6_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 136 Layer Name : conv4_block6_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 590080 Layer Number : 137 Layer Name : conv4_block6_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 1024 Layer Number : 138 Layer Name : conv4_block6_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: False No of Parameter : 0 Layer Number : 139 Layer Name : conv4_block6_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 263168 Layer Number : 140 Layer Name : conv4_block6_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 4096 Layer Number : 141 Layer Name : conv4_block6_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 142 Layer Name : conv4_block6_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: False No of Parameter : 0 Layer Number : 143 Layer Name : conv5_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 524800 Layer Number : 144 Layer Name : conv5_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 145 Layer Name : conv5_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 146 Layer Name : conv5_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2359808 Layer Number : 147 Layer Name : conv5_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 148 Layer Name : conv5_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 149 Layer Name : conv5_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 2099200 Layer Number : 150 Layer Name : conv5_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 1050624 Layer Number : 151 Layer Name : conv5_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 8192 Layer Number : 152 Layer Name : conv5_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 8192 Layer Number : 153 Layer Name : conv5_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 2048), (None, 1, 1, 2048)] (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 0 Layer Number : 154 Layer Name : conv5_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 0 Layer Number : 155 Layer Name : conv5_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 1049088 Layer Number : 156 Layer Name : conv5_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 157 Layer Name : conv5_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 158 Layer Name : conv5_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2359808 Layer Number : 159 Layer Name : conv5_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 160 Layer Name : conv5_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 161 Layer Name : conv5_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 1050624 Layer Number : 162 Layer Name : conv5_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 8192 Layer Number : 163 Layer Name : conv5_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 2048), (None, 1, 1, 2048)] (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 0 Layer Number : 164 Layer Name : conv5_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 0 Layer Number : 165 Layer Name : conv5_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 1049088 Layer Number : 166 Layer Name : conv5_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 167 Layer Name : conv5_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 168 Layer Name : conv5_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2359808 Layer Number : 169 Layer Name : conv5_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 2048 Layer Number : 170 Layer Name : conv5_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0 Layer Number : 171 Layer Name : conv5_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 1050624 Layer Number : 172 Layer Name : conv5_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 8192 Layer Number : 173 Layer Name : conv5_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 2048), (None, 1, 1, 2048)] (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 0 Layer Number : 174 Layer Name : conv5_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: False No of Parameter : 0</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 8<br></strong>baseModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[‘accuracy’]) <strong>#Line 9</strong></pre><p><strong>Line 8</strong> : We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 9</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we have to predict i.e. get the feature from the model which is shown as below:</p><pre>Features_train= baseModel.predict(trainX) <strong>#Line 10</strong></pre><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1,2048) and for the training set it will be of (50000,1,1,2048), for test set it will be of (10000,1,1,2048) size.</em></p><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><h3>2.2 Using ResNet Architecture(without weights)</h3><p>In this section we will see how we can implement ResNet as a architecture in Keras. We will use state of the art ResNet network architechture and train it with our dataset from scratch i.e. we will not use pre-trained weights in this architechture the weights will be optimised while trainning from scratch. The code is explained below:</p><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2<br></strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3<br></strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5<br></strong># define subplotpyplot.subplot(330 + 1 + i)  <strong>#Line 6<br></strong># plot raw pixel data<br>    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7<br>    </strong># show the figure<br>    pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: </strong>These code snippets are used to display the samples from the dataset as shown below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/0*v8x4_dHitdiycVfA.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9<br></strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.2.2 ResNet Architechture(code)</h3><p>In this section we will see how we can implement ResNet as a architecture in Keras.</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_Restnet50 = tf.keras.applications.ResNet50(include_top=False,weights=None,input_tensor=image_input)    <strong>#Line 3</strong></pre><pre>baseModel_Restnet50.summary() <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained ResNet with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the ResNet model which will be used to extract featur from the image shown below.</p><pre>Model: &quot;resnet50&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_5[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            ================================================================================================== Total params: 23,587,712 Trainable params: 23,534,592 Non-trainable params: 53,120 __________________________________________________________________________________________________</pre><p>Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_Restnet50.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6<br></strong>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7<br></strong>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8<br></strong>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10<br></strong>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the ResNet network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has Resnet architechture as well as our custom fully classification layer. We have specified our input layer as<em> image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_5[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            __________________________________________________________________________________________________ flatten (Flatten)               (None, 2048)         0           conv5_block3_out[0][0]            __________________________________________________________________________________________________ dense (Dense)                   (None, 1000)         2049000     flatten[0][0]                     __________________________________________________________________________________________________ dense_1 (Dense)                 (None, 800)          800800      dense[0][0]                       __________________________________________________________________________________________________ dense_2 (Dense)                 (None, 400)          320400      dense_1[0][0]                     __________________________________________________________________________________________________ dense_3 (Dense)                 (None, 200)          80200       dense_2[0][0]                     __________________________________________________________________________________________________ dense_4 (Dense)                 (None, 100)          20100       dense_3[0][0]                     __________________________________________________________________________________________________ dense_5 (Dense)                 (None, 10)           1010        dense_4[0][0]                     ================================================================================================== Total params: 26,859,222 Trainable params: 26,806,102 Non-trainable params: 53,120 __________________________________________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><h3>2.3. Fine tunning Pre-trained models ResNet architechture.</h3><p>In this section we will see how we can implement ResNet as a architecture in Keras. We will use state of the art Residual network architechture with weight i.e. weights of the pre-trained model will be freezed i.e. error will not be propagated backward to these layers wheras tcustom fully connected layers will we optimised according to our dataset i.e. they will be trainable.The code is explained below:</p><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2<br></strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3<br></strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5<br></strong># define subplotpyplot.subplot(330 + 1 + i)  <strong>#Line 6<br></strong># plot raw pixel data<br>    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7<br>    </strong># show the figure<br>    pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: </strong>These code snippets are used to display the samples from the dataset as shown below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/0*v8x4_dHitdiycVfA.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9<br></strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.3.2. ResNet Fine Tunning Dense Layer</h3><p>In this section we will see how we can implement ResNet as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel = tf.keras.applications.ResNet50(include_top=False,weights=&#39;imagenet&#39;,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel.summary() <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained ResNet with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the ResNet model which will be used to extract feature from the image shown below.</p><pre>Downloading data from <a href="https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5">https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5</a> 94773248/94765736 [==============================] - 1s 0us/step 94781440/94765736 [==============================] - 1s 0us/step Model: &quot;resnet50&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_6[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            ================================================================================================== Total params: 23,587,712 Trainable params: 23,534,592 Non-trainable params: 53,120 __________________________________________________________________________________________________</pre><p>Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel.layers):  <strong>#Line 5<br>  </strong>layer.trainable=False                           <strong>#Line 6<br>  </strong>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre>Layer Number : 0 Layer Name : input_3 Layer Shape(Input_Shape,Output Shape) : ( [(None, 224, 224, 3)] [(None, 224, 224, 3)] ) is Trainable: True No of Parameter : 0 Layer Number : 1 Layer Name : conv1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 224, 224, 3) (None, 230, 230, 3) ) is Trainable: True No of Parameter : 0 Layer Number : 2 Layer Name : conv1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 230, 230, 3) (None, 112, 112, 64) ) is Trainable: True No of Parameter : 9472 Layer Number : 3 Layer Name : conv1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 64) (None, 112, 112, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 4 Layer Name : conv1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 64) (None, 112, 112, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 5 Layer Name : pool1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 112, 112, 64) (None, 114, 114, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 6 Layer Name : pool1_pool Layer Shape(Input_Shape,Output Shape) : ( (None, 114, 114, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 7 Layer Name : conv2_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 4160 Layer Number : 8 Layer Name : conv2_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 9 Layer Name : conv2_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 10 Layer Name : conv2_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 36928 Layer Number : 11 Layer Name : conv2_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 12 Layer Name : conv2_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 13 Layer Name : conv2_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 14 Layer Name : conv2_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 15 Layer Name : conv2_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 16 Layer Name : conv2_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 17 Layer Name : conv2_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 56, 56, 256), (None, 56, 56, 256)] (None, 56, 56, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 18 Layer Name : conv2_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 19 Layer Name : conv2_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 16448 Layer Number : 20 Layer Name : conv2_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 21 Layer Name : conv2_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 22 Layer Name : conv2_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 36928 Layer Number : 23 Layer Name : conv2_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 24 Layer Name : conv2_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 25 Layer Name : conv2_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 26 Layer Name : conv2_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 27 Layer Name : conv2_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 56, 56, 256), (None, 56, 56, 256)] (None, 56, 56, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 28 Layer Name : conv2_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 29 Layer Name : conv2_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 16448 Layer Number : 30 Layer Name : conv2_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 31 Layer Name : conv2_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 32 Layer Name : conv2_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 36928 Layer Number : 33 Layer Name : conv2_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 34 Layer Name : conv2_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 35 Layer Name : conv2_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 64) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 36 Layer Name : conv2_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 37 Layer Name : conv2_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 56, 56, 256), (None, 56, 56, 256)] (None, 56, 56, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 38 Layer Name : conv2_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 56, 56, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 39 Layer Name : conv3_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 32896 Layer Number : 40 Layer Name : conv3_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 41 Layer Name : conv3_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 42 Layer Name : conv3_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 43 Layer Name : conv3_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 44 Layer Name : conv3_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 45 Layer Name : conv3_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 56, 56, 256) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 131584 Layer Number : 46 Layer Name : conv3_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 47 Layer Name : conv3_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 48 Layer Name : conv3_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 49 Layer Name : conv3_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 512), (None, 28, 28, 512)] (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 50 Layer Name : conv3_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 51 Layer Name : conv3_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 65664 Layer Number : 52 Layer Name : conv3_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 53 Layer Name : conv3_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 54 Layer Name : conv3_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 55 Layer Name : conv3_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 56 Layer Name : conv3_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 57 Layer Name : conv3_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 58 Layer Name : conv3_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 59 Layer Name : conv3_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 512), (None, 28, 28, 512)] (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 60 Layer Name : conv3_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 61 Layer Name : conv3_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 65664 Layer Number : 62 Layer Name : conv3_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 63 Layer Name : conv3_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 64 Layer Name : conv3_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 65 Layer Name : conv3_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 66 Layer Name : conv3_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 67 Layer Name : conv3_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 68 Layer Name : conv3_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 69 Layer Name : conv3_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 512), (None, 28, 28, 512)] (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 70 Layer Name : conv3_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 71 Layer Name : conv3_block4_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 65664 Layer Number : 72 Layer Name : conv3_block4_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 73 Layer Name : conv3_block4_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 74 Layer Name : conv3_block4_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 75 Layer Name : conv3_block4_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 76 Layer Name : conv3_block4_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 77 Layer Name : conv3_block4_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 128) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 78 Layer Name : conv3_block4_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 79 Layer Name : conv3_block4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 28, 28, 512), (None, 28, 28, 512)] (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 80 Layer Name : conv3_block4_out Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 28, 28, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 81 Layer Name : conv4_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 131328 Layer Number : 82 Layer Name : conv4_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 83 Layer Name : conv4_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 84 Layer Name : conv4_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 85 Layer Name : conv4_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 86 Layer Name : conv4_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 87 Layer Name : conv4_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 28, 28, 512) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 525312 Layer Number : 88 Layer Name : conv4_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 89 Layer Name : conv4_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 90 Layer Name : conv4_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 91 Layer Name : conv4_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 1024), (None, 14, 14, 1024)] (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 92 Layer Name : conv4_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 93 Layer Name : conv4_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 94 Layer Name : conv4_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 95 Layer Name : conv4_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 96 Layer Name : conv4_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 97 Layer Name : conv4_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 98 Layer Name : conv4_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 99 Layer Name : conv4_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 100 Layer Name : conv4_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 101 Layer Name : conv4_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 1024), (None, 14, 14, 1024)] (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 102 Layer Name : conv4_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 103 Layer Name : conv4_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 104 Layer Name : conv4_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 105 Layer Name : conv4_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 106 Layer Name : conv4_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 107 Layer Name : conv4_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 108 Layer Name : conv4_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 109 Layer Name : conv4_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 110 Layer Name : conv4_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 111 Layer Name : conv4_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 1024), (None, 14, 14, 1024)] (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 112 Layer Name : conv4_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 113 Layer Name : conv4_block4_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 114 Layer Name : conv4_block4_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 115 Layer Name : conv4_block4_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 116 Layer Name : conv4_block4_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 117 Layer Name : conv4_block4_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 118 Layer Name : conv4_block4_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 119 Layer Name : conv4_block4_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 120 Layer Name : conv4_block4_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 121 Layer Name : conv4_block4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 1024), (None, 14, 14, 1024)] (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 122 Layer Name : conv4_block4_out Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 123 Layer Name : conv4_block5_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 124 Layer Name : conv4_block5_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 125 Layer Name : conv4_block5_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 126 Layer Name : conv4_block5_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 127 Layer Name : conv4_block5_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 128 Layer Name : conv4_block5_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 129 Layer Name : conv4_block5_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 130 Layer Name : conv4_block5_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 131 Layer Name : conv4_block5_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 1024), (None, 14, 14, 1024)] (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 132 Layer Name : conv4_block5_out Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 133 Layer Name : conv4_block6_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 134 Layer Name : conv4_block6_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 135 Layer Name : conv4_block6_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 136 Layer Name : conv4_block6_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 137 Layer Name : conv4_block6_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 138 Layer Name : conv4_block6_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 139 Layer Name : conv4_block6_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 256) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 140 Layer Name : conv4_block6_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 141 Layer Name : conv4_block6_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 14, 14, 1024), (None, 14, 14, 1024)] (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 142 Layer Name : conv4_block6_out Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 14, 14, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 143 Layer Name : conv5_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 524800 Layer Number : 144 Layer Name : conv5_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 145 Layer Name : conv5_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 146 Layer Name : conv5_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2359808 Layer Number : 147 Layer Name : conv5_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 148 Layer Name : conv5_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 149 Layer Name : conv5_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 14, 14, 1024) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 2099200 Layer Number : 150 Layer Name : conv5_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 1050624 Layer Number : 151 Layer Name : conv5_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 152 Layer Name : conv5_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 153 Layer Name : conv5_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 2048), (None, 7, 7, 2048)] (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 154 Layer Name : conv5_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 155 Layer Name : conv5_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 1049088 Layer Number : 156 Layer Name : conv5_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 157 Layer Name : conv5_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 158 Layer Name : conv5_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2359808 Layer Number : 159 Layer Name : conv5_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 160 Layer Name : conv5_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 161 Layer Name : conv5_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 1050624 Layer Number : 162 Layer Name : conv5_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 163 Layer Name : conv5_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 2048), (None, 7, 7, 2048)] (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 164 Layer Name : conv5_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 165 Layer Name : conv5_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 1049088 Layer Number : 166 Layer Name : conv5_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 167 Layer Name : conv5_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 168 Layer Name : conv5_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2359808 Layer Number : 169 Layer Name : conv5_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 170 Layer Name : conv5_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 171 Layer Name : conv5_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 512) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 1050624 Layer Number : 172 Layer Name : conv5_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 173 Layer Name : conv5_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 7, 7, 2048), (None, 7, 7, 2048)] (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 174 Layer Name : conv5_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 7, 7, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 175 Layer Name : avg_pool Layer Shape(Input_Shape,Output Shape) : ( (None, 7, 7, 2048) (None, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 176 Layer Name : predictions Layer Shape(Input_Shape,Output Shape) : ( (None, 2048) (None, 1000) ) is Trainable: True No of Parameter : 2049000</pre><p>Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel.output)        <strong>#Line 5</strong>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)<strong>#Line 6</strong>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense)<strong>#Line 9</strong>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense)<strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the Resnet network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong>model_final.summary()<strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which hasResNet architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_5[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            __________________________________________________________________________________________________ flatten (Flatten)               (None, 2048)         0           conv5_block3_out[0][0]            __________________________________________________________________________________________________ dense (Dense)                   (None, 1000)         2049000     flatten[0][0]                     __________________________________________________________________________________________________ dense_1 (Dense)                 (None, 800)          800800      dense[0][0]                       __________________________________________________________________________________________________ dense_2 (Dense)                 (None, 400)          320400      dense_1[0][0]                     __________________________________________________________________________________________________ dense_3 (Dense)                 (None, 200)          80200       dense_2[0][0]                     __________________________________________________________________________________________________ dense_4 (Dense)                 (None, 100)          20100       dense_3[0][0]                     __________________________________________________________________________________________________ dense_5 (Dense)                 (None, 10)           1010        dense_4[0][0]                     ================================================================================================== Total params: 26,859,222 Trainable params: 26,806,102 Non-trainable params: 53,120 __________________________________________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13<br></strong>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><p><strong>Note:</strong> In this section we have set the parameter of the ResNet to false i.e. the loss will not backward propagated throught these layers where as the fully connected layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h3>2.4. Using Resnets weight initialisers</h3><p>In this section we will use Resnet network as a initialiser. In Resnet architechture the model is trained on the ImageNet dataset and has acquired so we will instaniate Resnet archtechture with Resnet layer weights and set it to trainable i.e. the loss will be backward propagated along with that we will add our custom fully classifying layer will will also be trainable. So in short we are using weights of the Resnet architechture to initialize our model and train the whole neural network from scratch.</p><p><strong>2.4.1. Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2<br></strong>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3<br></strong>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5<br></strong># define subplotpyplot.subplot(330 + 1 + i)  <strong>#Line 6<br></strong># plot raw pixel data<br>    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7<br>    </strong># show the figure<br>    pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: </strong>These code snippets are used to display the samples from the dataset as shown below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/0*v8x4_dHitdiycVfA.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9<br></strong>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h3>2.3.2. ResNet</h3><p>In this section we will see how we can implement ResNet as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel = tf.keras.applications.ResNet50(include_top=False,weights=&#39;imagenet&#39;,input_tensor=image_input)</pre><pre>baseModel.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained ResNet with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the Resnet model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;resnet50&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_7[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            ================================================================================================== Total params: 23,587,712 Trainable params: 23,534,592 Non-trainable params: 53,120 __________________________________________________________________________________________________</pre><p>Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will activate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel.layers):  <strong>#Line 5<br>    </strong>layer.trainable=True                           <strong>#Line 6<br>    </strong>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=True</em>.</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre>Layer Number : 0 Layer Name : input_7 Layer Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: True No of Parameter : 0 Layer Number : 1 Layer Name : conv1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 38, 38, 3) ) is Trainable: True No of Parameter : 0 Layer Number : 2 Layer Name : conv1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 38, 38, 3) (None, 16, 16, 64) ) is Trainable: True No of Parameter : 9472 Layer Number : 3 Layer Name : conv1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 4 Layer Name : conv1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 5 Layer Name : pool1_pad Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 18, 18, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 6 Layer Name : pool1_pool Layer Shape(Input_Shape,Output Shape) : ( (None, 18, 18, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 7 Layer Name : conv2_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 4160 Layer Number : 8 Layer Name : conv2_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 9 Layer Name : conv2_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 10 Layer Name : conv2_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 36928 Layer Number : 11 Layer Name : conv2_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 12 Layer Name : conv2_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 13 Layer Name : conv2_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 14 Layer Name : conv2_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 15 Layer Name : conv2_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 16 Layer Name : conv2_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 17 Layer Name : conv2_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 256), (None, 8, 8, 256)] (None, 8, 8, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 18 Layer Name : conv2_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 19 Layer Name : conv2_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 16448 Layer Number : 20 Layer Name : conv2_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 21 Layer Name : conv2_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 22 Layer Name : conv2_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 36928 Layer Number : 23 Layer Name : conv2_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 24 Layer Name : conv2_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 25 Layer Name : conv2_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 26 Layer Name : conv2_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 27 Layer Name : conv2_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 256), (None, 8, 8, 256)] (None, 8, 8, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 28 Layer Name : conv2_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 29 Layer Name : conv2_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 16448 Layer Number : 30 Layer Name : conv2_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 31 Layer Name : conv2_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 32 Layer Name : conv2_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 36928 Layer Number : 33 Layer Name : conv2_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 256 Layer Number : 34 Layer Name : conv2_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 64) ) is Trainable: True No of Parameter : 0 Layer Number : 35 Layer Name : conv2_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 64) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 16640 Layer Number : 36 Layer Name : conv2_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 37 Layer Name : conv2_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 8, 8, 256), (None, 8, 8, 256)] (None, 8, 8, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 38 Layer Name : conv2_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 39 Layer Name : conv3_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 32896 Layer Number : 40 Layer Name : conv3_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 41 Layer Name : conv3_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 42 Layer Name : conv3_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 43 Layer Name : conv3_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 44 Layer Name : conv3_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 45 Layer Name : conv3_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 131584 Layer Number : 46 Layer Name : conv3_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 47 Layer Name : conv3_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 48 Layer Name : conv3_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 49 Layer Name : conv3_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 50 Layer Name : conv3_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 51 Layer Name : conv3_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 65664 Layer Number : 52 Layer Name : conv3_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 53 Layer Name : conv3_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 54 Layer Name : conv3_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 55 Layer Name : conv3_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 56 Layer Name : conv3_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 57 Layer Name : conv3_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 58 Layer Name : conv3_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 59 Layer Name : conv3_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 60 Layer Name : conv3_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 61 Layer Name : conv3_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 65664 Layer Number : 62 Layer Name : conv3_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 63 Layer Name : conv3_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 64 Layer Name : conv3_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 65 Layer Name : conv3_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 66 Layer Name : conv3_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 67 Layer Name : conv3_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 68 Layer Name : conv3_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 69 Layer Name : conv3_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 70 Layer Name : conv3_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 71 Layer Name : conv3_block4_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 65664 Layer Number : 72 Layer Name : conv3_block4_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 73 Layer Name : conv3_block4_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 74 Layer Name : conv3_block4_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 147584 Layer Number : 75 Layer Name : conv3_block4_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 512 Layer Number : 76 Layer Name : conv3_block4_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 128) ) is Trainable: True No of Parameter : 0 Layer Number : 77 Layer Name : conv3_block4_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 128) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 66048 Layer Number : 78 Layer Name : conv3_block4_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 79 Layer Name : conv3_block4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 4, 4, 512), (None, 4, 4, 512)] (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 80 Layer Name : conv3_block4_out Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 81 Layer Name : conv4_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 131328 Layer Number : 82 Layer Name : conv4_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 83 Layer Name : conv4_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 84 Layer Name : conv4_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 85 Layer Name : conv4_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 86 Layer Name : conv4_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 87 Layer Name : conv4_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 525312 Layer Number : 88 Layer Name : conv4_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 89 Layer Name : conv4_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 90 Layer Name : conv4_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 91 Layer Name : conv4_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 92 Layer Name : conv4_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 93 Layer Name : conv4_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 94 Layer Name : conv4_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 95 Layer Name : conv4_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 96 Layer Name : conv4_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 97 Layer Name : conv4_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 98 Layer Name : conv4_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 99 Layer Name : conv4_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 100 Layer Name : conv4_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 101 Layer Name : conv4_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 102 Layer Name : conv4_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 103 Layer Name : conv4_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 104 Layer Name : conv4_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 105 Layer Name : conv4_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 106 Layer Name : conv4_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 107 Layer Name : conv4_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 108 Layer Name : conv4_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 109 Layer Name : conv4_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 110 Layer Name : conv4_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 111 Layer Name : conv4_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 112 Layer Name : conv4_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 113 Layer Name : conv4_block4_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 114 Layer Name : conv4_block4_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 115 Layer Name : conv4_block4_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 116 Layer Name : conv4_block4_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 117 Layer Name : conv4_block4_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 118 Layer Name : conv4_block4_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 119 Layer Name : conv4_block4_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 120 Layer Name : conv4_block4_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 121 Layer Name : conv4_block4_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 122 Layer Name : conv4_block4_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 123 Layer Name : conv4_block5_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 124 Layer Name : conv4_block5_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 125 Layer Name : conv4_block5_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 126 Layer Name : conv4_block5_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 127 Layer Name : conv4_block5_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 128 Layer Name : conv4_block5_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 129 Layer Name : conv4_block5_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 130 Layer Name : conv4_block5_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 131 Layer Name : conv4_block5_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 132 Layer Name : conv4_block5_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 133 Layer Name : conv4_block6_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 262400 Layer Number : 134 Layer Name : conv4_block6_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 135 Layer Name : conv4_block6_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 136 Layer Name : conv4_block6_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 590080 Layer Number : 137 Layer Name : conv4_block6_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 1024 Layer Number : 138 Layer Name : conv4_block6_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 256) ) is Trainable: True No of Parameter : 0 Layer Number : 139 Layer Name : conv4_block6_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 256) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 263168 Layer Number : 140 Layer Name : conv4_block6_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 4096 Layer Number : 141 Layer Name : conv4_block6_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 2, 2, 1024), (None, 2, 2, 1024)] (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 142 Layer Name : conv4_block6_out Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 2, 2, 1024) ) is Trainable: True No of Parameter : 0 Layer Number : 143 Layer Name : conv5_block1_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 524800 Layer Number : 144 Layer Name : conv5_block1_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 145 Layer Name : conv5_block1_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 146 Layer Name : conv5_block1_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2359808 Layer Number : 147 Layer Name : conv5_block1_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 148 Layer Name : conv5_block1_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 149 Layer Name : conv5_block1_0_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 1024) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 2099200 Layer Number : 150 Layer Name : conv5_block1_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 1050624 Layer Number : 151 Layer Name : conv5_block1_0_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 152 Layer Name : conv5_block1_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 153 Layer Name : conv5_block1_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 2048), (None, 1, 1, 2048)] (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 154 Layer Name : conv5_block1_out Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 155 Layer Name : conv5_block2_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 1049088 Layer Number : 156 Layer Name : conv5_block2_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 157 Layer Name : conv5_block2_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 158 Layer Name : conv5_block2_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2359808 Layer Number : 159 Layer Name : conv5_block2_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 160 Layer Name : conv5_block2_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 161 Layer Name : conv5_block2_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 1050624 Layer Number : 162 Layer Name : conv5_block2_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 163 Layer Name : conv5_block2_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 2048), (None, 1, 1, 2048)] (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 164 Layer Name : conv5_block2_out Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 165 Layer Name : conv5_block3_1_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 1049088 Layer Number : 166 Layer Name : conv5_block3_1_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 167 Layer Name : conv5_block3_1_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 168 Layer Name : conv5_block3_2_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2359808 Layer Number : 169 Layer Name : conv5_block3_2_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 2048 Layer Number : 170 Layer Name : conv5_block3_2_relu Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 512) ) is Trainable: True No of Parameter : 0 Layer Number : 171 Layer Name : conv5_block3_3_conv Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 512) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 1050624 Layer Number : 172 Layer Name : conv5_block3_3_bn Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 8192 Layer Number : 173 Layer Name : conv5_block3_add Layer Shape(Input_Shape,Output Shape) : ( [(None, 1, 1, 2048), (None, 1, 1, 2048)] (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 0 Layer Number : 174 Layer Name : conv5_block3_out Layer Shape(Input_Shape,Output Shape) : ( (None, 1, 1, 2048) (None, 1, 1, 2048) ) is Trainable: True No of Parameter : 0</pre><p>Since we are using the ResNet as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel.output)        <strong>#Line 5<br></strong>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7<br></strong>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8<br></strong>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10<br></strong>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the ResNet network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has ResNet architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model_2&quot; __________________________________________________________________________________________________ Layer (type)                    Output Shape         Param #     Connected to                      ================================================================================================== input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                             __________________________________________________________________________________________________ conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_7[0][0]                     __________________________________________________________________________________________________ conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                   __________________________________________________________________________________________________ conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                  __________________________________________________________________________________________________ conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                    __________________________________________________________________________________________________ pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                  __________________________________________________________________________________________________ pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                   __________________________________________________________________________________________________ conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                  __________________________________________________________________________________________________ conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]                                                                            conv2_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]            __________________________________________________________________________________________________ conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]            __________________________________________________________________________________________________ conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]                                                                             conv2_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]            __________________________________________________________________________________________________ conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]            __________________________________________________________________________________________________ conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]                                                                             conv2_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]                                                                            conv3_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]            __________________________________________________________________________________________________ conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]            __________________________________________________________________________________________________ conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]                                                                             conv3_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]            __________________________________________________________________________________________________ conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]            __________________________________________________________________________________________________ conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]                                                                             conv3_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]            __________________________________________________________________________________________________ conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]            __________________________________________________________________________________________________ conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]                                                                             conv3_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]                                                                            conv4_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]            __________________________________________________________________________________________________ conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]            __________________________________________________________________________________________________ conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]                                                                             conv4_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]            __________________________________________________________________________________________________ conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]            __________________________________________________________________________________________________ conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]                                                                             conv4_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]            __________________________________________________________________________________________________ conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]            __________________________________________________________________________________________________ conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]                                                                             conv4_block4_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]            __________________________________________________________________________________________________ conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]            __________________________________________________________________________________________________ conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]                                                                             conv4_block5_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]            __________________________________________________________________________________________________ conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]            __________________________________________________________________________________________________ conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]         __________________________________________________________________________________________________ conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]         __________________________________________________________________________________________________ conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]                                                                             conv4_block6_3_bn[0][0]           __________________________________________________________________________________________________ conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]            __________________________________________________________________________________________________ conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]            __________________________________________________________________________________________________ conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]                                                                            conv5_block1_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]            __________________________________________________________________________________________________ conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]            __________________________________________________________________________________________________ conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]                                                                             conv5_block2_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]            __________________________________________________________________________________________________ conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]            __________________________________________________________________________________________________ conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]         __________________________________________________________________________________________________ conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]         __________________________________________________________________________________________________ conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]                                                                             conv5_block3_3_bn[0][0]           __________________________________________________________________________________________________ conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]            __________________________________________________________________________________________________ flatten_2 (Flatten)             (None, 2048)         0           conv5_block3_out[0][0]            __________________________________________________________________________________________________ dense_12 (Dense)                (None, 1000)         2049000     flatten_2[0][0]                   __________________________________________________________________________________________________ dense_13 (Dense)                (None, 800)          800800      dense_12[0][0]                    __________________________________________________________________________________________________ dense_14 (Dense)                (None, 400)          320400      dense_13[0][0]                    __________________________________________________________________________________________________ dense_15 (Dense)                (None, 200)          80200       dense_14[0][0]                    __________________________________________________________________________________________________ dense_16 (Dense)                (None, 100)          20100       dense_15[0][0]                    __________________________________________________________________________________________________ dense_17 (Dense)                (None, 10)           1010        dense_16[0][0]                    ================================================================================================== Total params: 26,859,222 Trainable params: 26,806,102 Non-trainable params: 53,120 ________________________________________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><p><strong>Note:</strong> In this section we have set the parameter of the ResNet to true i.e. the loss will bebackward propagated throught these layers where as the fully connected layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h4>In this article we have discussed about the Resnet architechture with Keras. In next article,we will have hands on experience with PyTorch API’s.</h4><h4>Stay Tuned !!! Happy Learning :)</h4><p><strong><em>Need help ???</em></strong><em> Consult with me on </em><strong><em>DDI :)</em></strong></p><p><a href="https://app.ddichat.com/experts/ravi-shekhar-tiwari/">Ravi Shekhar TIwari - DDIChat</a></p><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote>Pytorch: <a href="https://pytorch.org/get-started/locally/#windows-python">Link</a></blockquote><blockquote>Keras: <a href="https://keras.io/">Link</a></blockquote><blockquote>Tensorflow: <a href="https://www.tensorflow.org/guide/keras/sequential_model">Link</a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote>YouTube : <a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ">Lin</a>k</blockquote><blockquote>Website: <a href="http://www.rstiwari.com/">www.rstiwari.com</a></blockquote><blockquote>Medium: <a href="https://tiwari11-rst.medium.com/">https://tiwari11-rst.medium.com</a></blockquote><blockquote>Github Pages: <a href="https://happyman11.github.io/">https://happyman11.github.io/</a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Google Form: <a href="https://forms.gle/mhDYQKQJKtAKP78V7">https://forms.gle/mhDYQKQJKtAKP78V7</a></blockquote><h3>Don’t forget to give us your 👏 !</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/0*2lvCls4yjxVMfZSR" /></figure><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fupscri.be%2F8f5f8b%3Fas_embed%3Dtrue&amp;dntp=1&amp;url=https%3A%2F%2Fupscri.be%2F8f5f8b&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=upscri" width="800" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href">https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href</a></iframe><figure><a href="https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*2f7OqE2AJK1KSrhkmD9ZMw.png" /></a></figure><figure><a href="https://upscri.be/8f5f8b"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*v-PpfkSWHbvlWWamSVHHWg.png" /></a></figure><figure><a href="https://becominghuman.ai/write-for-us-48270209de63"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*Wt2auqISiEAOZxJ-I7brDQ.png" /></a></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=455afbc28657" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-5-1-implementing-resnet-in-keras-455afbc28657">Transfer Learning — Part — 5.1!! Implementing ResNet in Keras</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 5.0!! ResidualNets]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-5-0-residualnets-48d42368eb71?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/48d42368eb71</guid>
    <category>
        <![CDATA[pytorch]]>
    </category>
    <category>
        <![CDATA[python]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[keras]]>
    </category>
    <category>
        <![CDATA[resnet]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Fri, 22 Oct 2021 05:43:55 GMT</pubDate>
    <atom:updated>2021-10-22T16:14:15.213Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 5.0!! ResidualNets</h3><p>In Part 4 Series of the Transfer Learning series we have discussed the VGG nets in depth along with hands-on application of these pre-trained neural nets in Keras and PyTorch API’s. The datasets on which these pre-trained model is trained for the ILVRC competition which is held annually and their repository as well as the documentation in order to implement this concept with two API’s namely Keras and PyTorch which is discussed in Part 3 of this series. In this, article we will discuss theoretically about the ResidualNets and in article 5.2 and 5.3 we will have practical implementation with Keras and PyTorch API respectively. The link of notebook for setting up the along with the article is given below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>For the repository and document please follow below two mentioned links:</p><p><strong>Keras:</strong></p><p><a href="https://keras.io/guides/transfer_learning/">Keras documentation: Transfer learning &amp; fine-tuning</a></p><p><strong>PyTorch:</strong></p><p><a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial - PyTorch Tutorials 1.12.0+cu102 documentation</a></p><figure><a href="https://aijobsboard.com/?fbclid=IwAR0GcsLs8A6CFM-fynrZMM3sTgo_Zpbto2CjglJm0Dmi6otC6YWc7CDFpQk"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dAlwXfVrtYspdCzmC8iADw.png" /></a><figcaption>Big Data Jobs</figcaption></figure><h4>1. History of the Residual Network</h4><p>In recent years, Computer Vision has shown promising results because of the new trends in technologies. As a direct result the storage and computing power has increased proportionally which gives us an option to add more layer in our network and to solve complex tasks but it has some issues. Researchers observed that by adding more layers to the neural network there is problem in training these models because there is problem of vanishing gradient which makes the gradient descent slow and it goes to zero quickly. Vanishing Gradient is a problem in deep neural network where the loss which is propagated backward in the layers present in the model has very small values which is not significant in optimising the parameters of layers..In the event that we see all the more explicitly, during gradient descent, as you backpropagate from the last layer back to the input layer, you are increasing by the weight grid on each progression, and consequently the slope can diminish dramatically rapidly to nothing and preventing the preparation cycle This issue was encountered by the RestNet architecture by employing skip connection, it becomes possible to solve the difficulties of training very deep neural network models.</p><p>RestNet is abbreviation of Residual Network which was introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun in their paper “Deep Residual Learning for Image Recognition”in 2015 .RestNet was created by keeping an eye to solve the vanishing gradient problem. Residuals nets uses skip connection- core of this network to improve the accuracy of the models. Skip connects work by alleviating the problem of vanishing gradient and in addition it enables the model to learn the identity function. Residual networks makes the model to learn identity function which improves the accuracy of the layers in the model by minimizing the percentage of error. The skip connections add the output from previous layer to the output of stacked layer thus making it possible to train deep neural networks.</p><h4><strong>2. Skip Connection</strong></h4><p>In ResNet architecture, a “shortcut” or a “skip connection” allows the gradient to be directly back propagated to earlier layers and allow model to learn identity functions. The right most below image shows the “main path” through the network and the leftmost below image on the bottom adds a shortcut to the main path. By stacking these ResNet blocks on top of each other, we can form a very deep network.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/700/0*OnPXDY6TyKoUcHKc" /><figcaption><strong>Fig 1. </strong>Skip Connection</figcaption></figure><p>The problem of training very deep networks with vanishing gradient has been relieved with the introduction of these Residual blocks which is part of RestNet.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/350/0*FKV44O4SoxP8nN7E" /><figcaption><strong>Fig. 2 </strong>Skip Connection(Source: ‘<em>Deep Residual Learning for Image Recognition</em>‘ paper_.</figcaption></figure><p>In the above figure, the we can notice that there is a direct connection that skips some layers of the model. This connection is called ’skip connection’ and is the heart of residual blocks. The output is not the same due to this skip connection. Without the skip connection, input ‘X gets multiplied by the weights of the layer followed by adding a bias term.</p><p>Then comes the activation function, f() and we get the output as H(x).</p><p><em>H(x)=f( wx + b ) or H(x)=f(x)</em></p><p>Now with the introduction of a new skip connection technique, the output is H(x) is changed to</p><p><em>H(x)=f(x)+x</em></p><p>But the dimension of the input may be varying from that of the output which might happen with a convolutional layer or pooling layers. Hence, this problem can be handled with these two approaches:</p><p>· Zero is padded with the skip connection to increase its dimensions.</p><p>· 1×1 convolutional layers are added to the input to match the dimensions. In such a case, the output is:</p><p><em>H(x)=f(x)+w1.x</em></p><p>Here an additional parameter w1 is added whereas no additional parameter is added when using the first approach.</p><p>These skip connections technique in ResNet solves the problem of vanishing gradient in deep CNNs by allowing alternate shortcut path for the gradient to flow through. Also, the skip connection helps if any layer hurts the performance of architecture, then it will be skipped by regularization.</p><h3>Trending AI Articles:</h3><blockquote><a href="https://becominghuman.ai/why-corporate-ai-projects-fail-part-1-4-3b820041ab00">1. Why Corporate AI projects fail?</a></blockquote><blockquote><a href="https://becominghuman.ai/how-ai-will-power-the-next-wave-of-healthcare-innovation-695a2196aae8">2. How AI Will Power the Next Wave of Healthcare Innovation?</a></blockquote><blockquote><a href="https://becominghuman.ai/machine-learning-by-using-regression-model-f0c7993a66c8">3. Machine Learning by Using Regression Model</a></blockquote><blockquote><a href="https://becominghuman.ai/top-data-science-platforms-in-2021-other-than-kaggle-a1b4609c06b0">4. Top Data Science Platforms in 2021 Other than Kaggle</a></blockquote><p>There are two main types of blocks that are used in a RestNet, depending the input/output dimensions are the same or different which are mentioned below:</p><h4>2.1. Identity Block</h4><p>The identity block is the standard block used in RestNets and corresponds to the case where the input activation has the same dimension as the output activation. It also represents the skip connection in the RestNet which compensates for the vanishing gradient problem and allows the model to learn identity function.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/0*4O42Ln16v6wZjI3r" /><figcaption><strong>Fig. 3.</strong> Identity Function</figcaption></figure><h4>2.2. Convolutional Block</h4><p>We can employ this type of block when the input and output dimensions don’t match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path with is designed in such a way that it matches the output of the shortest path to the main path.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/837/0*fkL-s7sBtn7QKm1B" /><figcaption><strong>Fig. 4 </strong>Convolution Block</figcaption></figure><h3>3. Architecture of ResNet</h3><p>The below figure represents the various ResNet architecture succitinly:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*aw87NYleB6k7QUwU" /><figcaption><strong>Fig 5</strong>. Types of ResNet</figcaption></figure><h4>In this article we have discussed about the ResNet architecture theoretically in next article i.e. 5.2 and 5.3 we will have hands on experience with Keras and PyTorch API’s.</h4><h4>Stay Tuned !!! Happy Learning :)</h4><p><strong><em>Need help ???</em></strong><em> Consult with me on </em><strong><em>DDI :)</em></strong></p><p><a href="https://app.ddichat.com/experts/ravi-shekhar-tiwari/">Ravi Shekhar TIwari - DDIChat</a></p><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote>Pytorch: <a href="https://pytorch.org/get-started/locally/#windows-python">Link</a></blockquote><blockquote>Keras: <a href="https://keras.io/">Link</a></blockquote><blockquote>ResNet:<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiz__vNp93zAhUBxzgGHTtVBvcQFnoECAQQAQ&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1512.03385&amp;usg=AOvVaw0ko2RV0WsEDskyH0kl1EHN"><em> Link</em></a></blockquote><blockquote>Tensorflow: <a href="https://www.tensorflow.org/guide/keras/sequential_model">Link</a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote>YouTube : <a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ">Lin</a>k</blockquote><blockquote>Website: <a href="http://www.rstiwari.com/">www.rstiwari.com</a></blockquote><blockquote>Medium: <a href="https://tiwari11-rst.medium.com/">https://tiwari11-rst.medium.com</a></blockquote><blockquote>Github Pages: <a href="https://happyman11.github.io/">https://happyman11.github.io/</a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Google Form: <a href="https://forms.gle/mhDYQKQJKtAKP78V7">https://forms.gle/mhDYQKQJKtAKP78V7</a></blockquote><h3>Don’t forget to give us your 👏 !</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/0*2lvCls4yjxVMfZSR" /></figure><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fupscri.be%2F8f5f8b%3Fas_embed%3Dtrue&amp;dntp=1&amp;url=https%3A%2F%2Fupscri.be%2F8f5f8b&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=upscri" width="800" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href">https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href</a></iframe><figure><a href="https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*2f7OqE2AJK1KSrhkmD9ZMw.png" /></a></figure><figure><a href="https://upscri.be/8f5f8b"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*v-PpfkSWHbvlWWamSVHHWg.png" /></a></figure><figure><a href="https://becominghuman.ai/write-for-us-48270209de63"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*Wt2auqISiEAOZxJ-I7brDQ.png" /></a></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=48d42368eb71" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-5-0-residualnets-48d42368eb71">Transfer Learning — Part — 5.0!! ResidualNets</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 4.2!! Implementing VGG-16 and VGG-19 in PyTorch]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-4-2-implementing-vgg-16-and-vgg-19-in-pytorch-c6056d974b19?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/c6056d974b19</guid>
    <category>
        <![CDATA[vgg16]]>
    </category>
    <category>
        <![CDATA[pytorch]]>
    </category>
    <category>
        <![CDATA[vggnet]]>
    </category>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[vgg19]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Fri, 15 Oct 2021 04:49:02 GMT</pubDate>
    <atom:updated>2021-10-19T16:26:13.722Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 4.2!! Implementing VGG-16 and VGG-19 in PyTorch</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*1fTB7GLajuWvFn24.jpg" /><figcaption><strong>Figure.1 </strong>Transfer Learning</figcaption></figure><p>In Part 4.0 of the Transfer Learning series we have discussed about VGG-16 and VGG-19 pre-trained model in depth so in this series we will implement the above mentioned pre-trained model in PyTorch. This part is going to be little long because we are going to implement VGG-16 and VGG-19 in PyTorch with Python. We will be implementing the per-trained VGG model in 4 ways which we will discuss further in this article. For setting- up the Colab notebook it will be advisable to go through the below mentioned article of Transfer Learning Series.</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>It is also advisable to go through the article of VGG-19 and VGG-19 before reading this article which is mentioned below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-4-0-vgg-16-and-vgg-19-d7f0045032de">Transfer Learning — Part — 4.0!! VGG-16 and VGG-19</a></p><p><strong>1.Implementing VGG Pre-trained model</strong></p><p>In this section we will see how we can implement VGG model in PyTorch to have a foundation to start our real implementation .</p><p><strong>1.1. Image to predict</strong></p><p>We will use the image of the coffee mug to predict the labels with the VGG architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import torch                                          <strong>#Line 1</strong></pre><pre>import torchvision.models as models                   <strong>#Line 2</strong></pre><pre>from PIL import Image                                 <strong>#Line 3</strong></pre><pre>import torchvision.transforms.functional as TF        <strong>#Line 4</strong></pre><pre>from torchsummary import summary                      <strong>#Line 5 </strong></pre><pre>!pip install torchviz                                 <strong>#Line 6</strong></pre><pre>from torchviz import make_dot                         <strong>#Line 7</strong></pre><pre>import numpy as np</pre><p><strong>Line 1:</strong> The above snippet is used to import the PyTorch library which we use use to implement VGG network.</p><p><strong>Line 2:</strong> The above snippet is used to import the PyTorch pre-trained models.</p><p><strong>Line 3:</strong> The above snippet is used to import the PIL library for visualization purpose.</p><p><strong>Line 4:</strong> The above snippet is used to import the PyTorch Transformation library which we use use to transform the dataset for training and testing.</p><p><strong>Line 5:</strong> The above snippet is used to import library which shows the summary of models.</p><p><strong>Line 6:</strong> The above snippet is used to install torchviz to visualise the network.</p><p><strong>Line 7:</strong> The above snippet is used to import torchviz to visualize the network.</p><pre>image = Image.open(link_of_image)   <strong>#Line 8</strong></pre><pre>image=image.resize((224,224))       <strong>#Line 9</strong></pre><pre>x = TF.to_tensor(image)             <strong>#Line 10</strong></pre><pre>x.unsqueeze_(0)                     <strong>#Line 11</strong></pre><pre>x=x.to(device)                      <strong>#Line 12</strong></pre><pre>print(x.shape)                      <strong>#Line 13</strong></pre><figure><a href="https://aijobsboard.com/?fbclid=IwAR0GcsLs8A6CFM-fynrZMM3sTgo_Zpbto2CjglJm0Dmi6otC6YWc7CDFpQk"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dAlwXfVrtYspdCzmC8iADw.png" /></a><figcaption>Big Data Jobs</figcaption></figure><p><strong>Line 8: </strong>This snippet loads the images from the path.</p><p><strong>Line 9: </strong>This snippet converts the image in the size (224,224) required by the model.</p><p><strong>Line 10:</strong> This snippet convert the image into array</p><p><strong>Line 11: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 12:</strong> This snippet is used to move the image to the device on which model is registered.</p><p><strong>Line 13: </strong>This snippet use to display the image shape as shown below:</p><pre>torch.Size([1, 3, 224, 224])</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*Q8sQsV5H4B8-or4D3-nQgg.jpeg" /><figcaption><strong>Figure. 1 </strong>Image to be predicted</figcaption></figure><p><strong>1.2. VGG-16 implementation</strong></p><p>Here we will use VGG-16 network to predict on the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0</strong></pre><pre>vgg16_pretrained = models.vgg16(pretrained=True).to(device) <strong>#LINE 1</strong></pre><pre>summary(vgg16_pretrained, (3, 224, 224))                    <strong>#LINE 2</strong></pre><pre>vgg16_pretrained                                            <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the VGG-16 model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>---------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1         [-1, 64, 224, 224]           1,792<br>              ReLU-2         [-1, 64, 224, 224]               0<br>            Conv2d-3         [-1, 64, 224, 224]          36,928<br>              ReLU-4         [-1, 64, 224, 224]               0<br>         MaxPool2d-5         [-1, 64, 112, 112]               0<br>            Conv2d-6        [-1, 128, 112, 112]          73,856<br>              ReLU-7        [-1, 128, 112, 112]               0<br>            Conv2d-8        [-1, 128, 112, 112]         147,584<br>              ReLU-9        [-1, 128, 112, 112]               0<br>        MaxPool2d-10          [-1, 128, 56, 56]               0<br>           Conv2d-11          [-1, 256, 56, 56]         295,168<br>             ReLU-12          [-1, 256, 56, 56]               0<br>           Conv2d-13          [-1, 256, 56, 56]         590,080<br>             ReLU-14          [-1, 256, 56, 56]               0<br>           Conv2d-15          [-1, 256, 56, 56]         590,080<br>             ReLU-16          [-1, 256, 56, 56]               0<br>        MaxPool2d-17          [-1, 256, 28, 28]               0<br>           Conv2d-18          [-1, 512, 28, 28]       1,180,160<br>             ReLU-19          [-1, 512, 28, 28]               0<br>           Conv2d-20          [-1, 512, 28, 28]       2,359,808<br>             ReLU-21          [-1, 512, 28, 28]               0<br>           Conv2d-22          [-1, 512, 28, 28]       2,359,808<br>             ReLU-23          [-1, 512, 28, 28]               0<br>        MaxPool2d-24          [-1, 512, 14, 14]               0<br>           Conv2d-25          [-1, 512, 14, 14]       2,359,808<br>             ReLU-26          [-1, 512, 14, 14]               0<br>           Conv2d-27          [-1, 512, 14, 14]       2,359,808<br>             ReLU-28          [-1, 512, 14, 14]               0<br>           Conv2d-29          [-1, 512, 14, 14]       2,359,808<br>             ReLU-30          [-1, 512, 14, 14]               0<br>        MaxPool2d-31            [-1, 512, 7, 7]               0<br>AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0<br>           Linear-33                 [-1, 4096]     102,764,544<br>             ReLU-34                 [-1, 4096]               0<br>          Dropout-35                 [-1, 4096]               0<br>           Linear-36                 [-1, 4096]      16,781,312<br>             ReLU-37                 [-1, 4096]               0<br>          Dropout-38                 [-1, 4096]               0<br>           Linear-39                 [-1, 1000]       4,097,000<br>================================================================<br>Total params: 138,357,544<br>Trainable params: 138,357,544<br>Non-trainable params: 0<br>----------------------------------------------------------------<br>Input size (MB): 0.57<br>Forward/backward pass size (MB): 218.78<br>Params size (MB): 527.79<br>Estimated Total Size (MB): 747.15<br>----------------------------------------------------------------</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the layers which is shown below with types of layer:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (18): ReLU(inplace=True)<br>    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (25): ReLU(inplace=True)<br>    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (27): ReLU(inplace=True)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=1000, bias=True)<br>  )<br>)</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>VGG_16_prediction=vgg16_pretrained(x)                        <strong>#Line 4</strong></pre><pre>VGG_16_prediction_numpy=VGG_16_prediction.detach().numpy()   <strong>#Line 5</strong></pre><pre>predicted_class_max = np.argmax(VGG_16_prediction_numpy)     <strong>#Line 6</strong></pre><pre>predicted_class_max                                          <strong>#Line 7</strong></pre><p><strong>Line 4:</strong> This snippets send the pre-processed image to the VGG-16 network for getting prediction.</p><p><strong>Line 5: </strong>This line is used to<strong> </strong>move the prediction from the model from GPU to CPU so we can manipulate it and convert the prediction from torch tensor to numpy array.</p><p><strong>Line 6: </strong>This snippet is used to get the array index whose probability is maximum.</p><p><strong>Line 7: </strong>This snippets is used to display the highest probability class.</p><pre>504</pre><p>The below snippets is used to read the label from text file and display the label name as shown below:</p><pre>with open(‘/content/imagenet1000_clsidx_to_labels.txt’, ‘r’) as fp:<br>    line_numbers = [predicted_class_max]<br>    for i, line in enumerate(fp):<br>       if i in line_numbers:<br>           lines.append(line.strip()<br>           break</pre><pre>print(lines)</pre><pre><strong>Output&gt;&gt;&gt;&gt;<br></strong>[&quot;504: &#39;coffee mug&#39;,&quot;]</pre><p><strong>1.3. VGG-19 implementation</strong></p><p>Here we will use VGG-19 network to predict on the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0</strong></pre><pre>vgg19_pretrained = models.vgg19(pretrained=True).to(device) <strong>#LINE 1</strong></pre><pre>summary(vgg19_pretrained, (3, 224, 224))                    <strong>#LINE 2</strong></pre><pre>vgg19_pretrained                                            <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the VGG-19 model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>----------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1         [-1, 64, 224, 224]           1,792<br>              ReLU-2         [-1, 64, 224, 224]               0<br>            Conv2d-3         [-1, 64, 224, 224]          36,928<br>              ReLU-4         [-1, 64, 224, 224]               0<br>         MaxPool2d-5         [-1, 64, 112, 112]               0<br>            Conv2d-6        [-1, 128, 112, 112]          73,856<br>              ReLU-7        [-1, 128, 112, 112]               0<br>            Conv2d-8        [-1, 128, 112, 112]         147,584<br>              ReLU-9        [-1, 128, 112, 112]               0<br>        MaxPool2d-10          [-1, 128, 56, 56]               0<br>           Conv2d-11          [-1, 256, 56, 56]         295,168<br>             ReLU-12          [-1, 256, 56, 56]               0<br>           Conv2d-13          [-1, 256, 56, 56]         590,080<br>             ReLU-14          [-1, 256, 56, 56]               0<br>           Conv2d-15          [-1, 256, 56, 56]         590,080<br>             ReLU-16          [-1, 256, 56, 56]               0<br>           Conv2d-17          [-1, 256, 56, 56]         590,080<br>             ReLU-18          [-1, 256, 56, 56]               0<br>        MaxPool2d-19          [-1, 256, 28, 28]               0<br>           Conv2d-20          [-1, 512, 28, 28]       1,180,160<br>             ReLU-21          [-1, 512, 28, 28]               0<br>           Conv2d-22          [-1, 512, 28, 28]       2,359,808<br>             ReLU-23          [-1, 512, 28, 28]               0<br>           Conv2d-24          [-1, 512, 28, 28]       2,359,808<br>             ReLU-25          [-1, 512, 28, 28]               0<br>           Conv2d-26          [-1, 512, 28, 28]       2,359,808<br>             ReLU-27          [-1, 512, 28, 28]               0<br>        MaxPool2d-28          [-1, 512, 14, 14]               0<br>           Conv2d-29          [-1, 512, 14, 14]       2,359,808<br>             ReLU-30          [-1, 512, 14, 14]               0<br>           Conv2d-31          [-1, 512, 14, 14]       2,359,808<br>             ReLU-32          [-1, 512, 14, 14]               0<br>           Conv2d-33          [-1, 512, 14, 14]       2,359,808<br>             ReLU-34          [-1, 512, 14, 14]               0<br>           Conv2d-35          [-1, 512, 14, 14]       2,359,808<br>             ReLU-36          [-1, 512, 14, 14]               0<br>        MaxPool2d-37            [-1, 512, 7, 7]               0<br>AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0<br>           Linear-39                 [-1, 4096]     102,764,544<br>             ReLU-40                 [-1, 4096]               0<br>          Dropout-41                 [-1, 4096]               0<br>           Linear-42                 [-1, 4096]      16,781,312<br>             ReLU-43                 [-1, 4096]               0<br>          Dropout-44                 [-1, 4096]               0<br>           Linear-45                 [-1, 1000]       4,097,000<br>================================================================<br>Total params: 143,667,240<br>Trainable params: 143,667,240<br>Non-trainable params: 0<br>----------------------------------------------------------------<br>Input size (MB): 0.57<br>Forward/backward pass size (MB): 238.69<br>Params size (MB): 548.05<br>Estimated Total Size (MB): 787.31<br>----------------------------------------------------------------</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the layers which is shown below with types of layer:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (17): ReLU(inplace=True)<br>    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (24): ReLU(inplace=True)<br>    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (26): ReLU(inplace=True)<br>    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (31): ReLU(inplace=True)<br>    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (33): ReLU(inplace=True)<br>    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (35): ReLU(inplace=True)<br>    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=1000, bias=True)<br>  )<br>)</pre><h3>Trending AI Articles:</h3><blockquote><a href="https://becominghuman.ai/why-corporate-ai-projects-fail-part-1-4-3b820041ab00">1. Why Corporate AI projects fail?</a></blockquote><blockquote><a href="https://becominghuman.ai/how-ai-will-power-the-next-wave-of-healthcare-innovation-695a2196aae8">2. How AI Will Power the Next Wave of Healthcare Innovation?</a></blockquote><blockquote><a href="https://becominghuman.ai/machine-learning-by-using-regression-model-f0c7993a66c8">3. Machine Learning by Using Regression Model</a></blockquote><blockquote><a href="https://becominghuman.ai/top-data-science-platforms-in-2021-other-than-kaggle-a1b4609c06b0">4. Top Data Science Platforms in 2021 Other than Kaggle</a></blockquote><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>VGG_19_prediction=vgg19_pretrained(x)                        <strong>#Line 4</strong></pre><pre>VGG_19_prediction_numpy=VGG_19_prediction.detach().numpy()   <strong>#Line 5</strong></pre><pre>predicted_class_max = np.argmax(VGG_19_prediction_numpy)     <strong>#Line 6</strong></pre><pre>predicted_class_max                                          <strong>#Line 7</strong></pre><p><strong>Line 4:</strong> This snippets send the pre-processed image to the VGG-19 network for getting prediction.</p><p><strong>Line 5: </strong>This line is used to<strong> </strong>move the prediction from the model from GPU to CPU so we can manipulate it and convert the prediction from torch tensor to numpy array.</p><p><strong>Line 6: </strong>This snippet is used to get the array index whose probability is maximum.</p><p><strong>Line 7: </strong>This snippets is used to display the highest probability class.</p><pre>504</pre><p>The below snippets is used to read the label from text file and display the label name as shown below:</p><pre>with open(‘/content/imagenet1000_clsidx_to_labels.txt’, ‘r’) as fp:<br>    line_numbers = [predicted_class_max]<br>    for i, line in enumerate(fp):<br>       if i in line_numbers:<br>           lines.append(line.strip()<br>           break</pre><pre>print(lines)</pre><pre><strong>Output&gt;&gt;&gt;&gt;<br></strong>[&quot;504: &#39;coffee mug&#39;,&quot;]</pre><p><strong>2.1. As a feature Extraction model.</strong></p><p>Since we have discussed the VGG -16 and VGG- 19 model in details in out previous article i.e. in part 4.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained VGG-16/VGG-19 to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p>2.1.1<strong> Image to extract feature</strong></p><p>We will use the image of the coffee mug to predict the labels with the VGG architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import torch                                          <strong>#Line 1</strong></pre><pre>import torchvision.models as models                   <strong>#Line 2</strong></pre><pre>from PIL import Image                                 <strong>#Line 3</strong></pre><pre>import torchvision.transforms.functional as TF        <strong>#Line 4</strong></pre><pre>from torchsummary import summary                      <strong>#Line 5</strong></pre><pre>!pip install torchviz                                 <strong>#Line 6</strong></pre><pre>from torchviz import make_dot                         <strong>#Line 7</strong></pre><pre>import numpy as np</pre><p><strong>Line 1:</strong> The above snippet is used to import the PyTorch library which we use use to implement VGG network.</p><p><strong>Line 2:</strong> The above snippet is used to import the PyTorch pre-trained models.</p><p><strong>Line 3:</strong> The above snippet is used to import the PIL library for visualization purpose.</p><p><strong>Line 4:</strong> The above snippet is used to import the PyTorch Transformation library which we use use to transform the dataset for training and testing.</p><p><strong>Line 5:</strong> The above snippet is used to import library which shows the summary of models.</p><p><strong>Line 6:</strong> The above snippet is used to install torchviz to visualise the network.</p><p><strong>Line 7:</strong> The above snippet is used to import torchviz to visualize the network.</p><pre>image = Image.open(link_of_image)   <strong>#Line 8</strong></pre><pre>image=image.resize((224,224))       <strong>#Line 9</strong></pre><pre>x = TF.to_tensor(image)             <strong>#Line 10</strong></pre><pre>x.unsqueeze_(0)                     <strong>#Line 11</strong></pre><pre>x=x.to(device)                      <strong>#Line 12</strong></pre><pre>print(x.shape)                      <strong>#Line 13</strong></pre><p><strong>Line 8: </strong>This snippet loads the images from the path.</p><p><strong>Line 9: </strong>This snippet converts the image in the size (224,224) required by the model.</p><p><strong>Line 10:</strong> This snippet convert the image into array</p><p><strong>Line 11: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 12:</strong> This snippet is used to move the image to the device on which model is registered.</p><p><strong>Line 13: </strong>This snippet use to display the image shape as shown below:</p><pre>torch.Size([1, 3, 224, 224])</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*Q8sQsV5H4B8-or4D3-nQgg.jpeg" /><figcaption><strong>Figure. 1 </strong>Image to be predicted</figcaption></figure><p>2.1.2 <strong>VGG-16 Implementation as Feature extraction</strong>(code)</p><p>Here we will use VGG-16 network to extract features of the coffee mug image code is demonstrated below.</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0</strong></pre><pre>vgg16_pretrained = models.vgg16(pretrained=True).to(device) <strong>#LINE 1</strong></pre><pre>summary(vgg16_pretrained, (3, 224, 224))                    <strong>#LINE 2</strong></pre><pre>vgg16_pretrained.features                                   <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the VGG-16 model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>---------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1         [-1, 64, 224, 224]           1,792<br>              ReLU-2         [-1, 64, 224, 224]               0<br>            Conv2d-3         [-1, 64, 224, 224]          36,928<br>              ReLU-4         [-1, 64, 224, 224]               0<br>         MaxPool2d-5         [-1, 64, 112, 112]               0<br>            Conv2d-6        [-1, 128, 112, 112]          73,856<br>              ReLU-7        [-1, 128, 112, 112]               0<br>            Conv2d-8        [-1, 128, 112, 112]         147,584<br>              ReLU-9        [-1, 128, 112, 112]               0<br>        MaxPool2d-10          [-1, 128, 56, 56]               0<br>           Conv2d-11          [-1, 256, 56, 56]         295,168<br>             ReLU-12          [-1, 256, 56, 56]               0<br>           Conv2d-13          [-1, 256, 56, 56]         590,080<br>             ReLU-14          [-1, 256, 56, 56]               0<br>           Conv2d-15          [-1, 256, 56, 56]         590,080<br>             ReLU-16          [-1, 256, 56, 56]               0<br>        MaxPool2d-17          [-1, 256, 28, 28]               0<br>           Conv2d-18          [-1, 512, 28, 28]       1,180,160<br>             ReLU-19          [-1, 512, 28, 28]               0<br>           Conv2d-20          [-1, 512, 28, 28]       2,359,808<br>             ReLU-21          [-1, 512, 28, 28]               0<br>           Conv2d-22          [-1, 512, 28, 28]       2,359,808<br>             ReLU-23          [-1, 512, 28, 28]               0<br>        MaxPool2d-24          [-1, 512, 14, 14]               0<br>           Conv2d-25          [-1, 512, 14, 14]       2,359,808<br>             ReLU-26          [-1, 512, 14, 14]               0<br>           Conv2d-27          [-1, 512, 14, 14]       2,359,808<br>             ReLU-28          [-1, 512, 14, 14]               0<br>           Conv2d-29          [-1, 512, 14, 14]       2,359,808<br>             ReLU-30          [-1, 512, 14, 14]               0<br>        MaxPool2d-31            [-1, 512, 7, 7]               0<br>AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0<br>           Linear-33                 [-1, 4096]     102,764,544<br>             ReLU-34                 [-1, 4096]               0<br>          Dropout-35                 [-1, 4096]               0<br>           Linear-36                 [-1, 4096]      16,781,312<br>             ReLU-37                 [-1, 4096]               0<br>          Dropout-38                 [-1, 4096]               0<br>           Linear-39                 [-1, 1000]       4,097,000<br>================================================================<br>Total params: 138,357,544<br>Trainable params: 138,357,544<br>Non-trainable params: 0<br>----------------------------------------------------------------<br>Input size (MB): 0.57<br>Forward/backward pass size (MB): 218.78<br>Params size (MB): 527.79<br>Estimated Total Size (MB): 747.15<br>----------------------------------------------------------------</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the feature extractor layers which is shown below :</p><pre>Sequential(<br>  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (1): ReLU(inplace=True)<br>  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (3): ReLU(inplace=True)<br>  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (6): ReLU(inplace=True)<br>  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (8): ReLU(inplace=True)<br>  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (11): ReLU(inplace=True)<br>  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (13): ReLU(inplace=True)<br>  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (15): ReLU(inplace=True)<br>  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (18): ReLU(inplace=True)<br>  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (20): ReLU(inplace=True)<br>  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (22): ReLU(inplace=True)<br>  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (25): ReLU(inplace=True)<br>  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (27): ReLU(inplace=True)<br>  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (29): ReLU(inplace=True)<br>  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>)</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>VGG_16_prediction=vgg16_pretrained.features(x)               <strong>#Line 4</strong></pre><pre>VGG_16_prediction_numpy=VGG_16_prediction.detach().numpy()   <strong>#Line 5</strong></pre><p><strong>Line 4: </strong>This snippet is used to feed the image to the feature extractor layer of the VGG network</p><p><strong>Line 5: </strong>This snippet is used to detacht the output from the GPU to CPU.</p><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1,512) and for the training set it will be of (50000,1,1,512), for test set it will be of (10000,1,1,512) size.</em></p><p>2.1.3 <strong>VGG-19 Implementation as Feature extraction</strong>(code)</p><p>In this section we will see how we can implement VGG-19 as a Feature extractor in PyTorch:</p><pre>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)                                                      <strong>#LINE 0</strong></pre><pre>vgg19_pretrained = models.vgg19(pretrained=True).to(device) <strong>#LINE 1</strong></pre><pre>summary(vgg19_pretrained, (3, 224, 224))                    <strong>#LINE 2</strong></pre><pre>vgg19_pretrained.features                                   <strong>#LINE 3</strong></pre><p><strong>Line 0: </strong>This is used to check the availability of the device in our environment and save it so we we utilize the resources better.</p><p><strong>Line 1:</strong> This snippets is used to create an object for the VGG-19 model by including all its layer, pre-trained is set to true which will include all the default weight of the model trained on ImageNet dataset and attached the model to the avaliable device i.e. GPU or CPU. The model accepts data in channel first format i.e. (channel,height,width) in this case (3,224,224)</p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>----------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1         [-1, 64, 224, 224]           1,792<br>              ReLU-2         [-1, 64, 224, 224]               0<br>            Conv2d-3         [-1, 64, 224, 224]          36,928<br>              ReLU-4         [-1, 64, 224, 224]               0<br>         MaxPool2d-5         [-1, 64, 112, 112]               0<br>            Conv2d-6        [-1, 128, 112, 112]          73,856<br>              ReLU-7        [-1, 128, 112, 112]               0<br>            Conv2d-8        [-1, 128, 112, 112]         147,584<br>              ReLU-9        [-1, 128, 112, 112]               0<br>        MaxPool2d-10          [-1, 128, 56, 56]               0<br>           Conv2d-11          [-1, 256, 56, 56]         295,168<br>             ReLU-12          [-1, 256, 56, 56]               0<br>           Conv2d-13          [-1, 256, 56, 56]         590,080<br>             ReLU-14          [-1, 256, 56, 56]               0<br>           Conv2d-15          [-1, 256, 56, 56]         590,080<br>             ReLU-16          [-1, 256, 56, 56]               0<br>           Conv2d-17          [-1, 256, 56, 56]         590,080<br>             ReLU-18          [-1, 256, 56, 56]               0<br>        MaxPool2d-19          [-1, 256, 28, 28]               0<br>           Conv2d-20          [-1, 512, 28, 28]       1,180,160<br>             ReLU-21          [-1, 512, 28, 28]               0<br>           Conv2d-22          [-1, 512, 28, 28]       2,359,808<br>             ReLU-23          [-1, 512, 28, 28]               0<br>           Conv2d-24          [-1, 512, 28, 28]       2,359,808<br>             ReLU-25          [-1, 512, 28, 28]               0<br>           Conv2d-26          [-1, 512, 28, 28]       2,359,808<br>             ReLU-27          [-1, 512, 28, 28]               0<br>        MaxPool2d-28          [-1, 512, 14, 14]               0<br>           Conv2d-29          [-1, 512, 14, 14]       2,359,808<br>             ReLU-30          [-1, 512, 14, 14]               0<br>           Conv2d-31          [-1, 512, 14, 14]       2,359,808<br>             ReLU-32          [-1, 512, 14, 14]               0<br>           Conv2d-33          [-1, 512, 14, 14]       2,359,808<br>             ReLU-34          [-1, 512, 14, 14]               0<br>           Conv2d-35          [-1, 512, 14, 14]       2,359,808<br>             ReLU-36          [-1, 512, 14, 14]               0<br>        MaxPool2d-37            [-1, 512, 7, 7]               0<br>AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0<br>           Linear-39                 [-1, 4096]     102,764,544<br>             ReLU-40                 [-1, 4096]               0<br>          Dropout-41                 [-1, 4096]               0<br>           Linear-42                 [-1, 4096]      16,781,312<br>             ReLU-43                 [-1, 4096]               0<br>          Dropout-44                 [-1, 4096]               0<br>           Linear-45                 [-1, 1000]       4,097,000<br>================================================================<br>Total params: 143,667,240<br>Trainable params: 143,667,240<br>Non-trainable params: 0<br>----------------------------------------------------------------<br>Input size (MB): 0.57<br>Forward/backward pass size (MB): 238.69<br>Params size (MB): 548.05<br>Estimated Total Size (MB): 787.31<br>----------------------------------------------------------------</pre><p><strong>Line 3</strong>: This line is used to see the full parameter of the feature extractor layers which is shown below :</p><pre>Sequential(<br>  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (1): ReLU(inplace=True)<br>  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (3): ReLU(inplace=True)<br>  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (6): ReLU(inplace=True)<br>  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (8): ReLU(inplace=True)<br>  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (11): ReLU(inplace=True)<br>  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (13): ReLU(inplace=True)<br>  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (15): ReLU(inplace=True)<br>  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (17): ReLU(inplace=True)<br>  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (20): ReLU(inplace=True)<br>  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (22): ReLU(inplace=True)<br>  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (24): ReLU(inplace=True)<br>  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (26): ReLU(inplace=True)<br>  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (29): ReLU(inplace=True)<br>  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (31): ReLU(inplace=True)<br>  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (33): ReLU(inplace=True)<br>  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>  (35): ReLU(inplace=True)<br>  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>)</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>VGG_19_prediction=vgg19_pretrained.features(x)               <strong>#Line 4</strong></pre><pre>VGG_19_prediction_numpy=VGG_19_prediction.detach().numpy()   <strong>#Line 5</strong></pre><p><strong>Line 4: </strong>This snippet is used to feed the image to the feature extractor layer of the VGG network</p><p><strong>Line 5: </strong>This snippet is used to detacht the output from the GPU to CPU.</p><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1,512) and for the training set it will be of (50000,1,1,512), for test set it will be of (10000,1,1,512) size.</em></p><p>2.2 <strong>Using VGG Architecture(</strong>without weights<strong>)</strong></p><p>In this section we will see how we can implement VGG-16 as a architecture in Keras. We will use state of the art VGG network architecture and train it with our datasets from scratch i.e. we will not use pre-trained weights in this architecture the weights will be optimized while training from scratch. The code is explained below:</p><p>2.2.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 datasets composed of 60K images, 50K for training and 10K for testing/evaluation.</p><pre>import os</pre><pre>import torch</pre><pre>import torchvision</pre><pre>import torchvision.models as models</pre><pre>import tarfile</pre><pre>from torchvision.datasets.utils import download_url</pre><pre>from torch.utils.data import random_split</pre><pre>from skimage import io, transform</pre><pre>import torchvision.transforms as transforms</pre><pre>from torchvision.datasets import ImageFolder</pre><pre>from torchvision.transforms import ToTensor,Resize</pre><pre>import matplotlib</pre><pre>import matplotlib.pyplot as plt</pre><pre>from torchvision.utils import make_grid</pre><pre>from torch.utils.data.dataloader import DataLoader</pre><pre>%matplotlib inline</pre><pre>matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;</pre><pre>download_url(dataset_url, &#39;.&#39;)</pre><pre>with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:</pre><pre>tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the datasets from the AWS server in our environment and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])</pre><pre>dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)</pre><pre>print(dataset.classes)</pre><p>The above snippets is used to transform the datasets into PyTorch datasets by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the datasets into two set i.e. test set and train set.</p><pre>val_size = 5000</pre><pre>train_size = len(dataset) - val_size</pre><pre>train_ds, val_ds = random_split(dataset, [train_size, val_size])</pre><pre>len(train_ds), len(val_ds)</pre><pre>batch_size=32</pre><pre>train_dl = DataLoader(train_ds, batch_size, shuffle=True)</pre><pre>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the datasets as shown below:</p><pre>def show_batch(dl):</pre><pre>   for images, labels in dl:</pre><pre>      fig, ax = plt.subplots(figsize=(12, 6))</pre><pre>      ax.set_xticks([]); ax.set_yticks([])</pre><pre>      ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))</pre><pre>      break</pre><pre>show_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/1*t_R_XEdu-zKwBKvB2YcXbQ.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p>2.2.2 <strong>VGG-16 Architecture</strong>(code)</p><p>In this section we will see how we can implement VGG-16 as a architecture in Keras.</p><pre>Vgg16_pretrained = models.vgg16()</pre><pre>for param in Vgg16_pretrained.classifier[6].parameters():<br>   param.requires_grad = True</pre><pre>Vgg16_pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-16 as a architecture with our custom datasets so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The line has 10 neurons with Softmax activation function which allow us to predict the probabilities of each classes đrom the neural network. the architecture is shown below:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (18): ReLU(inplace=True)<br>    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (25): ReLU(inplace=True)<br>    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (27): ReLU(inplace=True)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=10, bias=True)<br>  )<br>)</pre><p>Now after creating model we have to test the model that it is producing the correct output which can be done with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>   print(&#39;images.shape:&#39;, images.shape)</pre><pre>   out = Vgg16_pretrained(images)</pre><pre>   print(&#39;out.shape:&#39;, out.shape)</pre><pre>   print(&#39;out[0]:&#39;, out[0])</pre><pre>   break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(Vgg16_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>    print(epoch)</pre><pre>    a=0</pre><pre>    for images, labels in iter(train_dl):</pre><pre>       print(epoch,a)</pre><pre>       a=a+1</pre><pre>       optimizer.zero_grad()</pre><pre>       outputs = Vgg16_pretrained(images)</pre><pre>       loss = F.cross_entropy(outputs, labels)</pre><pre>       loss.backward()</pre><pre>       optimizer.step()</pre><pre>   a=a+1</pre><pre>   test_error_count = 0.0</pre><pre>   for images, labels in iter(test_dl):</pre><pre>      outputs = Vgg16_pretrained(images)</pre><pre>      test_error_count += float(torch.sum(torch.abs(labels -   <br>      outputs.argmax(1))))</pre><pre>   test_accuracy = 1.0 - float(test_error_count) /    <br>   float(len(test_dataset))</pre><pre>   print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have trained our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  Vgg16_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used VGG-16 architecture to train on our custom datasets.</p><p>2.2.3 <strong>VGG-19 Architecture </strong>(code)</p><p>In this section we will see how we can implement VGG-19 as a architecture in Keras.</p><pre>Vgg19_pretrained = models.vgg16()</pre><pre>Vgg19_pretrained.classifier[6]=torch.nn.Sequential(OrderedDict([<br>                      (&#39;fc1&#39;,nn.Linear(Vgg19_pretrained.classifier[6].in_features</pre><pre>, 10)),(&#39;activation1&#39;, torch.nn.Softmax()),</pre><pre>for param in Vgg19_pretrained.classifier[6].parameters():<br>   param.requires_grad = True</pre><pre>Vgg19_pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-19 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (17): ReLU(inplace=True)<br>    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (24): ReLU(inplace=True)<br>    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (26): ReLU(inplace=True)<br>    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (31): ReLU(inplace=True)<br>    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (33): ReLU(inplace=True)<br>    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (35): ReLU(inplace=True)<br>    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=10, bias=True)<br>  )<br>)</pre><p>Now after creating model we have to test the model that it is producing the correct output which acn be donne with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>   print(&#39;images.shape:&#39;, images.shape)</pre><pre>   out = Vgg19_pretrained(images)</pre><pre>   print(&#39;out.shape:&#39;, out.shape)</pre><pre>   print(&#39;out[0]:&#39;, out[0])</pre><pre>   break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(Vgg16_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>   print(epoch)</pre><pre>   a=0</pre><pre>  for images, labels in iter(train_dl):</pre><pre>    print(epoch,a)</pre><pre>    a=a+1</pre><pre>    optimizer.zero_grad()</pre><pre>    outputs = Vgg19_pretrained(images)</pre><pre>    loss = F.cross_entropy(outputs, labels)</pre><pre>    loss.backward()</pre><pre>    optimizer.step()</pre><pre>   a=a+1</pre><pre>   test_error_count = 0.0</pre><pre>    for images, labels in iter(test_dl):</pre><pre>      outputs = Vgg19_pretrained(images)</pre><pre>      test_error_count += float(torch.sum(torch.abs(labels -   <br>      outputs.argmax(1))))</pre><pre>      test_accuracy = 1.0 - float(test_error_count) /    <br>      float(len(test_dataset))</pre><pre> print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have traioned our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  Vgg19_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used VGG-19 architechture to train on our custom dataset.</p><h4>2.3. Fine Tunning VGG Architecture with Custom Fully Connected layers</h4><p>In this section we will see how we can implement VGG-16 as a architecture in PyTorch. We will use state of the art VGG network architechture and train it with our dataset from scratch i.e. we will use pre-trained weights in this architechture the weights will be optimised while trainning from scratch only for the fully connected layers but the code for the pre-trained layers remains as it is. The code is explained below:</p><p>2.3.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>mport os</pre><pre>import torch</pre><pre>import torchvision</pre><pre>import torchvision.models as models</pre><pre>import tarfile</pre><pre>from torchvision.datasets.utils import download_url</pre><pre>from torch.utils.data import random_split</pre><pre>from skimage import io, transform</pre><pre>import torchvision.transforms as transforms</pre><pre>from torchvision.datasets import ImageFolder</pre><pre>from torchvision.transforms import ToTensor,Resize</pre><pre>import matplotlib</pre><pre>import matplotlib.pyplot as plt</pre><pre>from torchvision.utils import make_grid</pre><pre>from torch.utils.data.dataloader import DataLoader</pre><pre>%matplotlib inline</pre><pre>matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;</pre><pre>download_url(dataset_url, &#39;.&#39;)</pre><pre>with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:</pre><pre>tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the dataset from the AWS server in our enviromenet and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])</pre><pre>dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)</pre><pre>print(dataset.classes)</pre><p>The above snippets is uded to tranform the dataset into PyTorch dataset by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the dataset into two set i.e. test set and train set.</p><pre>val_size = 5000</pre><pre>train_size = len(dataset) - val_size</pre><pre>train_ds, val_ds = random_split(dataset, [train_size, val_size])</pre><pre>len(train_ds), len(val_ds)</pre><pre>batch_size=32</pre><pre>train_dl = DataLoader(train_ds, batch_size, shuffle=True)</pre><pre>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the dataset as shown below:</p><pre>def show_batch(dl):</pre><pre>for images, labels in dl:</pre><pre>fig, ax = plt.subplots(figsize=(12, 6))</pre><pre>ax.set_xticks([]); ax.set_yticks([])</pre><pre>ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))</pre><pre>break</pre><pre>show_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/1*t_R_XEdu-zKwBKvB2YcXbQ.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p><strong>2.3.2</strong><strong>VGG-16 Fully Connected Layer Optimisation(code)</strong></p><p>In this section we will see how we can implement VGG-16 as a architecture in PyTorch.</p><pre>Vgg16_pretrained = models.vgg16(pretrained=True)</pre><pre>for param in Vgg16_pretrained.parameters():<br>   param.requires_grad = False</pre><pre>Vgg16_pretrained.classifier[6]=torch.nn.Sequential(OrderedDict([<br>                      (&#39;fc1&#39;,nn.Linear(Vgg16_pretrained.classifier[6].in_features</pre><pre>, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in Vgg16_pretrained.classifier[6].parameters():<br>    param.requires_grad = True</pre><pre>Vgg16_pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The pre-trained weight weights are specified <em>param.requires_grad = False s</em>o that the loss is not propagated back to these layers where as<em>in fully connected layers param.requires_grad = True </em>which allows loss to propagate back only in this layers<em>.</em>The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (18): ReLU(inplace=True)<br>    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (25): ReLU(inplace=True)<br>    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (27): ReLU(inplace=True)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=10, bias=True)<br>  )<br>)</pre><p>Now after creating model we have to test the model that it is producing the correct output which acn be donne with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>print(&#39;images.shape:&#39;, images.shape)</pre><pre>out = Vgg16_pretrained(images)</pre><pre>print(&#39;out.shape:&#39;, out.shape)</pre><pre>print(&#39;out[0]:&#39;, out[0])</pre><pre>break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(Vgg16_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>print(epoch)</pre><pre>a=0</pre><pre>for images, labels in iter(train_dl):</pre><pre>print(epoch,a)</pre><pre>a=a+1</pre><pre>optimizer.zero_grad()</pre><pre>outputs = Vgg16_pretrained(images)</pre><pre>loss = F.cross_entropy(outputs, labels)</pre><pre>loss.backward()</pre><pre>optimizer.step()</pre><pre>a=a+1</pre><pre>test_error_count = 0.0</pre><pre>for images, labels in iter(test_dl):</pre><pre>outputs = Vgg16_pretrained(images)</pre><pre>test_error_count += float(torch.sum(torch.abs(labels -   <br><br>        outputs.argmax(1))))</pre><pre>test_accuracy = 1.0 - float(test_error_count) /    <br>   float(len(test_dataset))</pre><pre>print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have traioned our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  Vgg16_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finsally we have used VGG-16 architechture to train on our cvustom dataset.</p><p><strong>2.2.2</strong><strong>VGG-19 Fully Connected Layer Optimisation(code)</strong></p><p>In this section we will see how we can implement VGG-19 as a architecture in PyTorch.</p><pre>Vgg19_pretrained = models.vgg19()</pre><pre>Vgg19_pretrained.classifier[6]=torch.nn.Sequential(OrderedDict([<br>                      (&#39;fc1&#39;,nn.Linear(Vgg19_pretrained.classifier[6].in_features</pre><pre>, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in Vgg19_pretrained.classifier[6].parameters():<br>   param.requires_grad = True</pre><pre>Vgg19_pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-19 as a architecture with our custom datasets so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The line has 10 neurons with Softmax activation function which allow us to predict the probabilities of each classes đrom the neural network. the architecture is shown below:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (17): ReLU(inplace=True)<br>    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (24): ReLU(inplace=True)<br>    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (26): ReLU(inplace=True)<br>    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (31): ReLU(inplace=True)<br>    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (33): ReLU(inplace=True)<br>    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (35): ReLU(inplace=True)<br>    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=10, bias=True)<br>  )<br>)</pre><p>Now after creating model we have to test the model that it is producing the correct output which acn be donne with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>print(&#39;images.shape:&#39;, images.shape)</pre><pre>out = Vgg19_pretrained(images)</pre><pre>print(&#39;out.shape:&#39;, out.shape)</pre><pre>print(&#39;out[0]:&#39;, out[0])</pre><pre>break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(Vgg16_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>print(epoch)</pre><pre>a=0</pre><pre>for images, labels in iter(train_dl):</pre><pre>print(epoch,a)</pre><pre>a=a+1</pre><pre>optimizer.zero_grad()</pre><pre>outputs = Vgg19_pretrained(images)</pre><pre>loss = F.cross_entropy(outputs, labels)</pre><pre>loss.backward()</pre><pre>optimizer.step()</pre><pre>a=a+1</pre><pre>test_error_count = 0.0</pre><pre>for images, labels in iter(test_dl):</pre><pre>outputs = Vgg19_pretrained(images)</pre><pre>test_error_count += float(torch.sum(torch.abs(labels -   <br>      outputs.argmax(1))))</pre><pre>test_accuracy = 1.0 - float(test_error_count) /    <br>      float(len(test_dataset))</pre><pre>print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have trained our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  Vgg19_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used VGG-19 architechture to train on our custom dataset.</p><h4>2.4. VGG weights as a neural network weight initializer</h4><p>In this section we will see how we can implement VGG-16 as a weight ibnitializer in PyTorch. We will use state of the art VGG network architechture and train it with our dataset from scratch i.e. we will use pre-trained weights in this architechture the weights will be optimised while trainning from scratch only for the fully connected layers but the code for the pre-trained layers remains as it is. The code is explained below:</p><p>2.4.1<strong> Datasets</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>mport os</pre><pre>import torch</pre><pre>import torchvision</pre><pre>import torchvision.models as models</pre><pre>import tarfile</pre><pre>from torchvision.datasets.utils import download_url</pre><pre>from torch.utils.data import random_split</pre><pre>from skimage import io, transform</pre><pre>import torchvision.transforms as transforms</pre><pre>from torchvision.datasets import ImageFolder</pre><pre>from torchvision.transforms import ToTensor,Resize</pre><pre>import matplotlib</pre><pre>import matplotlib.pyplot as plt</pre><pre>from torchvision.utils import make_grid</pre><pre>from torch.utils.data.dataloader import DataLoader</pre><pre>%matplotlib inline</pre><pre>matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39;</pre><p>The above snippet used to import the library which we will be needing to implement the PyTorch function.</p><pre>dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot;</pre><pre>download_url(dataset_url, &#39;.&#39;)</pre><pre>with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar:</pre><pre>tar.extractall(path=&#39;./data&#39;)</pre><p>The above snippet used to download the dataset from the AWS server in our enviromenet and we extract the downloaded zip fine into the folder named as data.</p><pre>transform=transforms.Compose([Resize((224,224)), ToTensor()])</pre><pre>dataset = ImageFolder(data_dir+&#39;/train&#39;, transform=transform)</pre><pre>print(dataset.classes)</pre><p>The above snippets is uded to tranform the dataset into PyTorch dataset by Resizing each image into (224,224) size and displaying the class names as below:</p><pre>[&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]</pre><p>The below lines are used to split the dataset into two set i.e. test set and train set.</p><pre>val_size = 5000</pre><pre>train_size = len(dataset) - val_size</pre><pre>train_ds, val_ds = random_split(dataset, [train_size, val_size])</pre><pre>len(train_ds), len(val_ds)</pre><pre>batch_size=32</pre><pre>train_dl = DataLoader(train_ds, batch_size, shuffle=True)</pre><pre>val_dl = DataLoader(val_ds, batch_size*2)</pre><p>The below lines is used to plot the sample from the dataset as shown below:</p><pre>def show_batch(dl):</pre><pre>for images, labels in dl:</pre><pre>fig, ax = plt.subplots(figsize=(12, 6))</pre><pre>ax.set_xticks([]); ax.set_yticks([])</pre><pre>ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))</pre><pre>break</pre><pre>show_batch(train_dl)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/687/1*t_R_XEdu-zKwBKvB2YcXbQ.png" /><figcaption>Figure 2. Sample CIFAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><p><strong>2.4.2</strong><strong>VGG-16 weights as a initialiser (code)</strong></p><p>In this section we will see how we can implement VGG-16 as a architecture in PyTorch.</p><pre>Vgg16_pretrained = models.vgg16(pretrained=True)</pre><pre>for param in Vgg16_pretrained.parameters():<br>   param.requires_grad = True</pre><pre>Vgg16_pretrained.classifier[6]=torch.nn.Sequential(OrderedDict([<br>                      (&#39;fc1&#39;,nn.Linear(Vgg16_pretrained.classifier[6].in_features</pre><pre>, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in Vgg16_pretrained.classifier[6].parameters():<br>    param.requires_grad = True</pre><pre>Vgg16_pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The pre-trained weight weights are specified <em>param.requires_grad = False s</em>o that the loss is not propagated back to these layers where as<em>in fully connected layers param.requires_grad = True </em>which allows loss to propagate back only in this layers<em>.</em>The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network. the architechture is shown below:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (18): ReLU(inplace=True)<br>    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (25): ReLU(inplace=True)<br>    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (27): ReLU(inplace=True)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=10, bias=True)<br>  )<br>)</pre><p>Now after creating model we have to test the model that it is producing the correct output which acn be donne with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>print(&#39;images.shape:&#39;, images.shape)</pre><pre>out = Vgg16_pretrained(images)</pre><pre>print(&#39;out.shape:&#39;, out.shape)</pre><pre>print(&#39;out[0]:&#39;, out[0])</pre><pre>break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(Vgg16_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>print(epoch)</pre><pre>a=0</pre><pre>for images, labels in iter(train_dl):</pre><pre>print(epoch,a)</pre><pre>a=a+1</pre><pre>optimizer.zero_grad()</pre><pre>outputs = Vgg16_pretrained(images)</pre><pre>loss = F.cross_entropy(outputs, labels)</pre><pre>loss.backward()</pre><pre>optimizer.step()</pre><pre>a=a+1</pre><pre>test_error_count = 0.0</pre><pre>for images, labels in iter(test_dl):</pre><pre>outputs = Vgg16_pretrained(images)</pre><pre>test_error_count += float(torch.sum(torch.abs(labels -   <br><br>        outputs.argmax(1))))</pre><pre>test_accuracy = 1.0 - float(test_error_count) /    <br>   float(len(test_dataset))</pre><pre>print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have traioned our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  Vgg16_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finsally we have used VGG-16 architechture to train on our custom dataset.</p><p><strong>2.4.3</strong><strong>VGG-19 as a weight initializer(code)</strong></p><p>In this section we will see how we can implement VGG-19 as a architecture in PyTorch.</p><pre>Vgg19_pretrained = models.vgg19(pretrained=True)</pre><pre>for param in Vgg19_pretrained.parameters():<br>   param.requires_grad = True</pre><pre>Vgg19_pretrained.classifier[6]=torch.nn.Sequential(OrderedDict([<br>                      (&#39;fc1&#39;,nn.Linear(Vgg19_pretrained.classifier[6].in_features</pre><pre>, 10)),(&#39;activation1&#39;, torch.nn.Softmax())]))</pre><pre>for param in Vgg19_pretrained.classifier[6].parameters():<br>   param.requires_grad = True</pre><pre>Vgg19_pretrained</pre><p>The above snippet is used to initiate the object for the VGG16 model.Since we are using the VGG-19 as a architecture with our custom datasets so we have to add our custom dense layer so that we can classify the objects from the datasets objects . The line has 10 neurons with Softmax activation function which allow us to predict the probabilities of each classes đrom the neural network. the architecture is shown below:</p><pre>VGG(<br>  (features): Sequential(<br>    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (1): ReLU(inplace=True)<br>    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (3): ReLU(inplace=True)<br>    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (6): ReLU(inplace=True)<br>    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (8): ReLU(inplace=True)<br>    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (11): ReLU(inplace=True)<br>    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (13): ReLU(inplace=True)<br>    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (15): ReLU(inplace=True)<br>    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (17): ReLU(inplace=True)<br>    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (20): ReLU(inplace=True)<br>    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (22): ReLU(inplace=True)<br>    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (24): ReLU(inplace=True)<br>    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (26): ReLU(inplace=True)<br>    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (29): ReLU(inplace=True)<br>    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (31): ReLU(inplace=True)<br>    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (33): ReLU(inplace=True)<br>    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))<br>    (35): ReLU(inplace=True)<br>    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))<br>  (classifier): Sequential(<br>    (0): Linear(in_features=25088, out_features=4096, bias=True)<br>    (1): ReLU(inplace=True)<br>    (2): Dropout(p=0.5, inplace=False)<br>    (3): Linear(in_features=4096, out_features=4096, bias=True)<br>    (4): ReLU(inplace=True)<br>    (5): Dropout(p=0.5, inplace=False)<br>    (6): Linear(in_features=4096, out_features=10, bias=True)<br>  )<br>)</pre><p>Now after creating model we have to test the model that it is producing the correct output which acn be donne with the help of below codes:</p><pre>for images, labels in train_dl:</pre><pre>print(&#39;images.shape:&#39;, images.shape)</pre><pre>out = Vgg19_pretrained(images)</pre><pre>print(&#39;out.shape:&#39;, out.shape)</pre><pre>print(&#39;out[0]:&#39;, out[0])</pre><pre>break</pre><p>The output of above code is :</p><pre>images.shape: torch.Size([32, 3, 224, 224])<br>out.shape: torch.Size([32, 10])<br>out[0]: tensor([ 0.0603, -0.5612,  0.3957, -0.0069, -0.1256, -0.6125,  0.3528, -0.5256,<br>        -0.0646, -0.1953], grad_fn=&lt;SelectBackward&gt;)</pre><p>Now finally we have to train the model by the following code snippets with batch size of 32 as shown below:</p><pre>NUM_EPOCHS = 3</pre><pre>best_accuracy = 0.0</pre><pre>import torch.optim as optim</pre><pre>import torch.nn.functional as F</pre><pre>optimizer = optim.SGD(Vgg16_pretrained.parameters(), lr=0.001, momentum=0.9)</pre><pre>for epoch in range(NUM_EPOCHS):</pre><pre>print(epoch)</pre><pre>a=0</pre><pre>for images, labels in iter(train_dl):</pre><pre>print(epoch,a)</pre><pre>a=a+1</pre><pre>optimizer.zero_grad()</pre><pre>outputs = Vgg19_pretrained(images)</pre><pre>loss = F.cross_entropy(outputs, labels)</pre><pre>loss.backward()</pre><pre>optimizer.step()</pre><pre>a=a+1</pre><pre>test_error_count = 0.0</pre><pre>for images, labels in iter(test_dl):</pre><pre>outputs = Vgg19_pretrained(images)</pre><pre>test_error_count += float(torch.sum(torch.abs(labels -   <br>      outputs.argmax(1))))</pre><pre>test_accuracy = 1.0 - float(test_error_count) /    <br>      float(len(test_dataset))</pre><pre>print(&#39;%d: %f&#39; % (epoch, test_accuracy))</pre><p>Now we have trained our model now it is time for prediction for this we will set the backward propagation to false which is shown below:</p><pre>with torch.no_grad():<br>   prediction =  Vgg19_pretrained(test_dl)<br>   predicted_class = np.argmax(prediction)</pre><p>Finally we have used VGG-19 architechture to train on our custom dataset.</p><p>In this article we have discussed about the pre-trained VGG-16and VGG-19 models with implementation in PyTorch. In next article we will discuss ResNet model. Stay Tuned!!!!</p><p><em>Need help ??? Consult with me on DDI :)</em></p><p><a href="https://app.ddichat.com/experts/ravi-shekhar-tiwari/">Ravi Shekhar TIwari - DDIChat</a></p><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote>Pytorch: <a href="https://pytorch.org/get-started/locally/#windows-python">Link</a></blockquote><blockquote>Keras: <a href="https://keras.io/">Link</a></blockquote><blockquote>Tensorflow: <a href="https://www.tensorflow.org/guide/keras/sequential_model">Link</a></blockquote><blockquote>VGG Paper: <a href="https://arxiv.org/abs/1409.1556">Link</a></blockquote><blockquote><em>Imagenet Dataset: </em><a href="https://www.image-net.org/"><em>Link</em></a></blockquote><blockquote><em>ILSVRC : </em><a href="https://www.image-net.org/challenges/LSVRC/index.php"><em>Link</em></a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote>YouTube : <a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ">Lin</a>k</blockquote><blockquote>Website: <a href="http://www.rstiwari.com/">www.rstiwari.com</a></blockquote><blockquote>Medium: <a href="https://tiwari11-rst.medium.com/">https://tiwari11-rst.medium.com</a></blockquote><blockquote>Github Pages: <a href="https://happyman11.github.io/">https://happyman11.github.io/</a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Google Form: <a href="https://forms.gle/mhDYQKQJKtAKP78V7">https://forms.gle/mhDYQKQJKtAKP78V7</a></blockquote><h3>Don’t forget to give us your 👏 !</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/0*2lvCls4yjxVMfZSR" /></figure><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fupscri.be%2F8f5f8b%3Fas_embed%3Dtrue&amp;dntp=1&amp;url=https%3A%2F%2Fupscri.be%2F8f5f8b&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=upscri" width="800" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href">https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href</a></iframe><figure><a href="https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*2f7OqE2AJK1KSrhkmD9ZMw.png" /></a></figure><figure><a href="https://upscri.be/8f5f8b"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*v-PpfkSWHbvlWWamSVHHWg.png" /></a></figure><figure><a href="https://becominghuman.ai/write-for-us-48270209de63"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*Wt2auqISiEAOZxJ-I7brDQ.png" /></a></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c6056d974b19" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-4-2-implementing-vgg-16-and-vgg-19-in-pytorch-c6056d974b19">Transfer Learning — Part — 4.2!! Implementing VGG-16 and VGG-19 in PyTorch</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
<item>
    <title>
        <![CDATA[Transfer Learning — Part — 4.1!! Implementing VGG-16 and VGG-19 in Keras]]>
    </title>
    <link>https://becominghuman.ai/transfer-learning-part-4-1-implementing-vgg-16-and-vgg-19-in-keras-227278e65869?source=rss-439a66e298ba------2</link>
    <guid isPermaLink="false">https://medium.com/p/227278e65869</guid>
    <category>
        <![CDATA[transfer-learning]]>
    </category>
    <category>
        <![CDATA[keras]]>
    </category>
    <category>
        <![CDATA[vgg19]]>
    </category>
    <category>
        <![CDATA[vgg16]]>
    </category>
    <category>
        <![CDATA[tensorflow]]>
    </category>
    <dc:creator>
        <![CDATA[RAVI SHEKHAR TIWARI]]>
    </dc:creator>
    <pubDate>Sat, 09 Oct 2021 11:07:44 GMT</pubDate>
    <atom:updated>2021-10-11T15:10:29.669Z</atom:updated>
    <content:encoded>
        <![CDATA[<h3>Transfer Learning — Part — 4.1!! Implementing VGG-16 and VGG-19 in Keras</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*1fTB7GLajuWvFn24.jpg" /><figcaption><strong>Figure.1 </strong>Transfer Learning</figcaption></figure><p>In Part 4.0 of the Transfer Learning series we have discussed about VGG-16 and VGG-19 pre-trained model in depth so in this series we will implement the above mentioned pre-trained model in Keras. This part is going to be little long because we are going to implement VGG-16 and VGG-19 in Keras with Python. We will be implementing the pre-trained VGG model in 4 ways which we will discuss further in this article. For setting- up the Colab notebook it will be advisable to go through the below mentioned article of Transfer Learning Series.</p><p><a href="https://becominghuman.ai/transfer-learning-part-3-datasets-and-repositories-cebc644007f4">Transfer Learning —Part -3!! Datasets and repositories</a></p><p>It is also advisable to go through the article of VGG-19 and VGG-19 before reading this article which is mentioned below:</p><p><a href="https://becominghuman.ai/transfer-learning-part-4-0-vgg-16-and-vgg-19-d7f0045032de">Transfer Learning — Part — 4.0!! VGG-16 and VGG-19</a></p><h4><strong>1. Implementing VGG Pre-trained model</strong></h4><p>In this section we will see how we can implement VGG model in keras to have a foundation to start our real implementation .</p><p><strong>1.1. Image which we will predict on</strong></p><p>We will use the image of the coffee mug to predict the labels with the VGG architectures. Below i have demonstrated the code how to load and preprocess the image.</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image = tf.keras.preprocessing.image.load_img(link_of_image, target_size=(224, 224))  <strong>#Line 2</strong></pre><pre>image = tf.keras.preprocessing.image.img_to_array(image) <strong>#Line 3</strong></pre><pre>image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2])) <strong>#Line 4</strong></pre><pre>image = tf.keras.applications.vgg16.preprocess_input(image) <strong>#Line 5</strong></pre><p><strong>Line 2: </strong>This snippet loads the images with size of (224,224).</p><p><strong>Line 3: </strong>This snippet converts the image into array for further pre-processing.</p><p><strong>Line 4: </strong>This snippet converts the image size into (batch_Size,height,width, channel) from (height,width, channel) i.e. (1,224,224,3) from (224,224,3).</p><p><strong>Line 5: </strong>This snippet use to pre process the image according to the VGG architechture.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*Q8sQsV5H4B8-or4D3-nQgg.jpeg" /><figcaption><strong>Figure. 1 </strong>Image to be predicted</figcaption></figure><p><strong>1.3. VGG-16 implementation</strong></p><p>Here we will use VGG-16 network to predict on the coffee mug image code is demonstrated below.</p><pre>VGG_16_pre_trained= tf.keras.applications.VGG16( include_top=True, weights=’imagenet’, input_tensor=None,input_shape=(224, 224, 3), pooling=’max’, classes=1000,classifier_activation=’softmax’) <strong>#Line 1</strong></pre><pre>print(VGG_16_pre_trained.summary())  <strong>#Line 2</strong></pre><p><strong>Line 1:</strong> This snippets is used to create an object for the VGG-16 model by including all its layer, specifying input shape to —<em>input_shape=(224, 224, 3), </em>pooling is set to max pooling<em>pooling=’max’, </em>since no. of classes in 1000 in ImageNet we also have set the classes to 1000 here classes=1000<strong> </strong>and classifier_ layer activation to softmax i.e.<em>classifier_activation=’softmax’.</em></p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>Model: &quot;vgg16&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_3 (InputLayer)         [(None, 224, 224, 3)]     0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         <br>_________________________________________________________________<br>flatten (Flatten)            (None, 25088)             0         <br>_________________________________________________________________<br>fc1 (Dense)                  (None, 4096)              102764544 <br>_________________________________________________________________<br>fc2 (Dense)                  (None, 4096)              16781312  <br>_________________________________________________________________<br>predictions (Dense)          (None, 1000)              4097000   <br>=================================================================<br>Total params: 138,357,544<br>Trainable params: 138,357,544<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>VGG_16_prediction = VGG_16_pre_trained.predict(image) <strong>#Line 3</strong></pre><pre>Top_predictions = tf.keras.applications.vgg16.decode_predictions(VGG_16_prediction , top=5)                                               <strong>#Line 4</strong></pre><pre>Top_predictions                                     <strong>#Line 5</strong></pre><p><strong>Line 3:</strong> This snippets send the pre-processed image to the VGG-16 network for getting prediction.</p><p><strong>Line 4 and Line 5: </strong>These two line accept the prediction from the model and output the top 5 prediction probabilities which is shown below.</p><pre>[[(&#39;n03063599&#39;, &#39;coffee_mug&#39;, 0.70106846),<br>  (&#39;n03063689&#39;, &#39;coffeepot&#39;, 0.1050699),<br>  (&#39;n07930864&#39;, &#39;cup&#39;, 0.07677949),<br>  (&#39;n04398044&#39;, &#39;teapot&#39;, 0.039143685),<br>  (&#39;n03950228&#39;, &#39;pitcher&#39;, 0.030508224)]]</pre><p><strong>1.3. VGG-19 Implementation</strong></p><p>Here we will use VGG-19 network to predict on the coffee mug image code is demonstrated below.</p><pre>VGG_19_pre_trained= tf.keras.applications.VGG19( include_top=True, weights=’imagenet’, input_tensor=None,input_shape=(224, 224, 3), pooling=’max’, classes=1000,classifier_activation=’softmax’) <strong>#Line 1</strong></pre><pre>print(VGG_19_pre_trained.summary())  <strong>#Line 2</strong></pre><p><strong>Line 1:</strong> This snippets is used to create an object for the VGG-19 model by including all its layer, specifying input shape to —<em>input_shape=(224, 224, 3), </em>pooling is set to max pooling<em>pooling=’max’, </em>since no. of classes in 1000 in ImageNet we also have set the classes to 1000 here classes=1000<strong> </strong>and classifier_ layer activation to softmax i.e.<em>classifier_activation=’softmax’.</em></p><p><strong>Line 2</strong>: This snippets shows the summary of the network as shown below:</p><pre>Model: &quot;vgg19&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_5 (InputLayer)         [(None, 224, 224, 3)]     0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         <br>_________________________________________________________________<br>flatten (Flatten)            (None, 25088)             0         <br>_________________________________________________________________<br>fc1 (Dense)                  (None, 4096)              102764544 <br>_________________________________________________________________<br>fc2 (Dense)                  (None, 4096)              16781312  <br>_________________________________________________________________<br>predictions (Dense)          (None, 1000)              4097000   <br>=================================================================<br>Total params: 143,667,240<br>Trainable params: 143,667,240<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now after loading the model and setting up the parameters it is the time for predicting the image as demonstrated below.</p><pre>VGG_19_prediction = VGG_19_pre_trained.predict(image) <strong>#Line 3</strong></pre><pre>Top_predictions = tf.keras.applications.vgg16.decode_predictions(VGG_16_prediction , top=5)                                               <strong>#Line 4</strong></pre><pre>Top_predictions                                     <strong>#Line 5</strong></pre><p><strong>Line 3:</strong> This snippets send the pre-processed image to the VGG-19 network for getting prediction.</p><p><strong>Line 4 and Line 5: </strong>These two line accept the prediction from the model and output the top 5 prediction probabilities which is shown below.</p><pre>[[(&#39;n03063599&#39;, &#39;coffee_mug&#39;, 0.8545638),<br>  (&#39;n07930864&#39;, &#39;cup&#39;, 0.0620479),<br>  (&#39;n03063689&#39;, &#39;coffeepot&#39;, 0.03351114),<br>  (&#39;n03950228&#39;, &#39;pitcher&#39;, 0.017441014),<br>  (&#39;n04398044&#39;, &#39;teapot&#39;, 0.011897426)]]</pre><figure><a href="https://aijobsboard.com/?fbclid=IwAR0GcsLs8A6CFM-fynrZMM3sTgo_Zpbto2CjglJm0Dmi6otC6YWc7CDFpQk"><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dAlwXfVrtYspdCzmC8iADw.png" /></a><figcaption>Big Data Jobs</figcaption></figure><h4><strong>2. Application of VGG Network</strong></h4><p>As I have mentioned above, we will discuss implementation of the pre-trained VGG model in 4 ways which are as follows:</p><ol><li><strong>As a feature Extraction model.</strong></li><li><strong>Using Pre-trained models VGG architechture.</strong></li><li><strong>Fine tunning Pre-trained models VGG architechture.</strong></li><li><strong>Using Pre-trained model weights as a weight initialiser.</strong></li></ol><p>So without any further delay lets start our implementation in Keras :).</p><h4><strong>2.1. As a feature Extraction model.</strong></h4><p>Since we have discussed the VGG -16 and VGG- 19 model in details in out previous article i.e. in part 4.0 of Transfer Learning Series and we know the model have been trained in huge dataset named as ImageNet which has 1000 object. So we can use the pre-trained VGG-16/VGG-19 to extract the features from the image and we can feed the features in another Machine model model for classification, self-supervise learning or many other application. It will give us the following benefits:</p><ol><li><em>No need to train very deep Deep Learning Model.</em></li><li><em>Easy to implement the any algorithm if datasets is small also.</em></li><li><em>No need of high computing resources.</em></li><li><em>Less development time as well as the less deployment time.</em></li></ol><p><strong>2.1.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels fir testing and training purpose.</p><pre>from matplotlib import pyplot   <strong>#Line 2</strong></pre><pre>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3</strong></pre><pre>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5</strong></pre><pre># define subplot</pre><pre>pyplot.subplot(330 + 1 + i)  <strong>#Line 6</strong></pre><pre># plot raw pixel data</pre><pre>pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7</strong></pre><pre># show the figure</pre><pre>pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the dataset as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/1*mcTDWRmqLbWRHbou7oSvaw.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9</strong></pre><pre>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h4>2.1.2 <strong>VGG-16 Implementation as Feature extraction</strong>(code)</h4><p>In this section we will see how we can implement VGG-16 as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_16 = tf.keras.applications.VGG16(include_top=False,weights=None,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_16.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-16 with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-16 model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;vgg16&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_2 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 14,714,688<br>Trainable params: 14,714,688<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we are using the VGG-16 as a architecture with our custom dataset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel_VGG_16.layers):  <strong>#Line 5</strong></pre><pre>    layer.trainable=False                           <strong>#Line 6</strong></pre><pre>    print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre><strong>Layer Number : 0</strong><strong>Layer Name : input_1 Layer </strong><br><em>Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 1 Layer Name : block1_conv</strong>1<br>L<em>ayer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 1792</em><br><strong>Layer Number : 2</strong><strong>Layer Name : block1_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 36928</em><br><strong>Layer Number : 3</strong><strong>Layer Name : block1_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 4 Layer Name : block2_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 73856</em><br><strong>Layer Number : 5</strong><strong>Layer Name : block2_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 147584</em><br><strong>Layer Number : 6</strong><strong>Layer Name : block2_pool <br></strong><em>Layer</em><strong><em> </em></strong><em>Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 8, 8, 128) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 7 Layer Name : block3_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 128) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 295168</em><br><strong>Layer Number : 8 Layer Name : block3_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 9</strong><strong>Layer Name : block3_conv3</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 10 Layer Name : block3_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 256) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 11</strong><strong>Layer Name : block4_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 1180160</em><br><strong>Layer Number : 12 Layer Name : block4_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 13 Layer Name : block4_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 14 Layer Name : block4_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 15 Layer Name : block5_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 16 Layer Name : block5_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 17 Layer Name : block5_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 18 Layer Name : block5_pool <br></strong><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0</em></pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 8</strong></pre><pre>baseModel_VGG_16.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[‘accuracy’]) <strong>#Line 9</strong></pre><p><strong>Line 8</strong> : We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 9</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we have to predict i.e. get the feature from the model which is shown as below:</p><pre>Features_train= baseModel_VGG_16.predict(trainX) <strong>#Line 10</strong></pre><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1,512) and for the training set it will be of (50000,1,1,512), for test set it will be of (10000,1,1,512) size.</em></p><h4>2.1.3 <strong>VGG-19 Implementation as Feature extraction</strong>(code)</h4><p>In this section we will see how we can implement VGG-19 as a Feature extractor in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_19 = tf.keras.applications.VGG19(include_top=False,weights=’imagenet’,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_19.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-19 with ImageNet weight by specifying<em>weights=’imagenet’,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-19 model which will be used to extract featur from the image shown below.</p><pre>Model: &quot;vgg19&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_3 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 20,024,384<br>Trainable params: 20,024,384<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel_VGG_19.layers):  <strong>#Line 5</strong></pre><pre>layer.trainable=False                           <strong>#Line 6</strong></pre><pre>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre><strong>Layer Number : 0 Layer Name : input_3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 1 Layer Name : block1_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 1792</em><br><strong>Layer Number : 2 Layer Name : block1_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 36928</em><br><strong>Layer Number : 3 Layer Name : block1_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 4 Layer Name : block2_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 73856</em><br><strong>Layer Number : 5 Layer Name : block2_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 147584</em><br><strong>Layer Number : 6 Layer Name : block2_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 8, 8, 128) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 7 Layer Name : block3_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 128) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 295168</em><br><strong>Layer Number : 8 Layer Name : block3_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 9 Layer Name : block3_conv3</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 10 Layer Name : block3_conv4 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 11 Layer Name : block3_pool Layer </strong><em>Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 256) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 12 Layer Name : block4_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 1180160</em><br><strong>Layer Number : 13 Layer Name : block4_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 14 Layer Name : block4_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 15 Layer Name : block4_conv4</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 16 Layer Name : block4_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 17 Layer Name : block5_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 18 Layer Name : block5_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 19 Layer Name : block5_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 20 Layer Name : block5_conv4 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 21 Layer Name : block5_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0</em></pre><h3>Trending AI Articles:</h3><blockquote><a href="https://becominghuman.ai/why-corporate-ai-projects-fail-part-1-4-3b820041ab00">1. Why Corporate AI projects fail?</a></blockquote><blockquote><a href="https://becominghuman.ai/how-ai-will-power-the-next-wave-of-healthcare-innovation-695a2196aae8">2. How AI Will Power the Next Wave of Healthcare Innovation?</a></blockquote><blockquote><a href="https://becominghuman.ai/machine-learning-by-using-regression-model-f0c7993a66c8">3. Machine Learning by Using Regression Model</a></blockquote><blockquote><a href="https://becominghuman.ai/top-data-science-platforms-in-2021-other-than-kaggle-a1b4609c06b0">4. Top Data Science Platforms in 2021 Other than Kaggle</a></blockquote><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 8</strong></pre><pre>baseModel_VGG_19.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[‘accuracy’]) <strong>#Line 9</strong></pre><p><strong>Line 8</strong> : We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 9</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>FInally we have to predict i.e. get the feature from the model which is shown as below:</p><pre>Features_train= baseModel_VGG_19.predict(trainX) <strong>#Line 10</strong></pre><p>This will give us the output of features from the image , the Feature variable will be of shape <em>(No_of samples,1,1,512)</em> and for the trainning set it will be of<em>(50000,1,1,512), </em>for test set it will be of<em>(10000,1,1,512) </em>size<em>.</em></p><h4><strong>2.2 Using VGG Architecture(without weights)</strong></h4><p>In this section we will see how we can implement VGG-16 as a architecture in Keras. We will use state of the art VGG network architechture and train it with our dataset from scratch i.e. we will not use pre-trained weights in this architechture the weights will be optimised while trainning from scratch. The code is explained below:</p><p><strong>2.2.1 Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels.</p><pre>from matplotlib import pyplot   <strong>#Line 2</strong></pre><pre>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3</strong></pre><pre>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5</strong></pre><pre># define subplot</pre><pre>pyplot.subplot(330 + 1 + i)  <strong>#Line 6</strong></pre><pre># plot raw pixel data</pre><pre>pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7</strong></pre><pre># show the figure</pre><pre>pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the dataset as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/1*mcTDWRmqLbWRHbou7oSvaw.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9</strong></pre><pre>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels this has been done by the help of this snippets.</p><h4>2.2.2 <strong>VGG-16 Architechture</strong>(code)</h4><p>In this section we will see how we can implement VGG-16 as a architecture in Keras.</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_16 = tf.keras.applications.VGG16(include_top=False,weights=None,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_16.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-16 with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-16 model which will be used to extract featur from the image shown below.</p><pre>Model: &quot;vgg16&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_2 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 14,714,688<br>Trainable params: 14,714,688<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_VGG_19.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong></pre><pre>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the VGG-16 network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has VGG-16 architechture as well as our custom fully classification layer. We have specified our input layer as<em> image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model_9&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_13 (InputLayer)        [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>_________________________________________________________________<br>flatten_6 (Flatten)          (None, 512)               0         <br>_________________________________________________________________<br>dense_36 (Dense)             (None, 1000)              513000    <br>_________________________________________________________________<br>dense_37 (Dense)             (None, 800)               800800    <br>_________________________________________________________________<br>dense_38 (Dense)             (None, 400)               320400    <br>_________________________________________________________________<br>dense_39 (Dense)             (None, 200)               80200     <br>_________________________________________________________________<br>dense_40 (Dense)             (None, 100)               20100     <br>_________________________________________________________________<br>dense_41 (Dense)             (None, 10)                1010      <br>=================================================================<br>Total params: 16,450,198<br>Trainable params: 16,450,198<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><h4>2.2.3 <strong>VGG-19 Architechture </strong>(code)</h4><p>In this section we will see how we can implement VGG-19 as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_19 = tf.keras.applications.VGG19(include_top=False,weights=None,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_19.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-19 with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-16 model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;vgg19&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_16 (InputLayer)        [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 20,024,384<br>Trainable params: 20,024,384<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we are using the VGG-19 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_VGG_19.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong></pre><pre>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the VGG-16 network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has VGG-16 architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_1 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>_________________________________________________________________<br>flatten (Flatten)            (None, 512)               0         <br>_________________________________________________________________<br>dense (Dense)                (None, 1000)              513000    <br>_________________________________________________________________<br>dense_1 (Dense)              (None, 800)               800800    <br>_________________________________________________________________<br>dense_2 (Dense)              (None, 400)               320400    <br>_________________________________________________________________<br>dense_3 (Dense)              (None, 200)               80200     <br>_________________________________________________________________<br>dense_4 (Dense)              (None, 100)               20100     <br>_________________________________________________________________<br>dense_5 (Dense)              (None, 10)                1010      <br>=================================================================<br>Total params: 21,759,894<br>Trainable params: 21,759,894<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets.</p><h4><strong>2.3. Fine tunning Pre-trained models VGG architechture.</strong></h4><p>In this section we will see how we can implement VGG-16 as a architecture in Keras. We will use state of the art VGG network architechture with weight i.e. weights of the pre-trained model will be freezed i.e. error will not be propagated backward to these layers wheras tcustom fully connected layers will we optimised according to our dataset i.e. they will be trainable.The code is explained below:</p><p><strong>2.3.1. Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels.</p><pre>from matplotlib import pyplot   <strong>#Line 2</strong></pre><pre>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3</strong></pre><pre>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5</strong></pre><pre># define subplot</pre><pre>pyplot.subplot(330 + 1 + i)  <strong>#Line 6</strong></pre><pre># plot raw pixel data</pre><pre>pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7</strong></pre><pre># show the figure</pre><pre>pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the dataset as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/1*mcTDWRmqLbWRHbou7oSvaw.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualisation library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9</strong></pre><pre>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h4><strong>2.3.2. VGG-16 Fine Tunning</strong></h4><p>In this section we will see how we can implement VGG-16 as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_16 = tf.keras.applications.VGG16(include_top=False,weights=None,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_16.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-16 with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-16 model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;vgg16&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_2 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 14,714,688<br>Trainable params: 14,714,688<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel_VGG_16.layers):  <strong>#Line 5</strong></pre><pre>layer.trainable=False                           <strong>#Line 6</strong></pre><pre>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre><strong>Layer Number : 0</strong><strong>Layer Name : input_1 Layer </strong><br><em>Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 1 Layer Name : block1_conv</strong>1<br>L<em>ayer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 1792</em><br><strong>Layer Number : 2</strong><strong>Layer Name : block1_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 36928</em><br><strong>Layer Number : 3</strong><strong>Layer Name : block1_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 4 Layer Name : block2_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 73856</em><br><strong>Layer Number : 5</strong><strong>Layer Name : block2_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 147584</em><br><strong>Layer Number : 6</strong><strong>Layer Name : block2_pool <br></strong><em>Layer</em><strong><em> </em></strong><em>Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 8, 8, 128) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 7 Layer Name : block3_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 128) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 295168</em><br><strong>Layer Number : 8 Layer Name : block3_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 9</strong><strong>Layer Name : block3_conv3</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 10 Layer Name : block3_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 256) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 11</strong><strong>Layer Name : block4_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 1180160</em><br><strong>Layer Number : 12 Layer Name : block4_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 13 Layer Name : block4_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 14 Layer Name : block4_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 15 Layer Name : block5_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 16 Layer Name : block5_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 17 Layer Name : block5_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 18 Layer Name : block5_pool <br></strong><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0</em></pre><p>Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_VGG_19.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong></pre><pre>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the VGG-16 network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has VGG-16 architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model_9&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_13 (InputLayer)        [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>_________________________________________________________________<br>flatten_6 (Flatten)          (None, 512)               0         <br>_________________________________________________________________<br>dense_36 (Dense)             (None, 1000)              513000    <br>_________________________________________________________________<br>dense_37 (Dense)             (None, 800)               800800    <br>_________________________________________________________________<br>dense_38 (Dense)             (None, 400)               320400    <br>_________________________________________________________________<br>dense_39 (Dense)             (None, 200)               80200     <br>_________________________________________________________________<br>dense_40 (Dense)             (None, 100)               20100     <br>_________________________________________________________________<br>dense_41 (Dense)             (None, 10)                1010      <br>=================================================================<br>Total params: 16,450,198<br>Trainable params: 16,450,198<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><p><strong>Note:</strong> In this section we have set the parameter of the VGG-16 to false i.e. the loss will not backward propagated throught these layers where as the fully connevted layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h4><strong>2.3.3 VGG-19 Fine Tunning Fully connected layers</strong></h4><p>In this section we will see how we can implement VGG-19as a Feature extractor in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_19 = tf.keras.applications.VGG19(include_top=False,weights=’imagenet’,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_19.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-19 with ImageNet weight by specifying<em>weights=’imagenet’,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-19 model which will be used to extract featur from the image shown below.</p><pre>Model: &quot;vgg19&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_3 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 20,024,384<br>Trainable params: 20,024,384<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will deactivate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel_VGG_19.layers):  <strong>#Line 5</strong></pre><pre>layer.trainable=False                           <strong>#Line 6</strong></pre><pre>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=False</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre><strong>Layer Number : 0 Layer Name : input_3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 1 Layer Name : block1_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 1792</em><br><strong>Layer Number : 2 Layer Name : block1_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 36928</em><br><strong>Layer Number : 3 Layer Name : block1_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 4 Layer Name : block2_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 73856</em><br><strong>Layer Number : 5 Layer Name : block2_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 147584</em><br><strong>Layer Number : 6 Layer Name : block2_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 8, 8, 128) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 7 Layer Name : block3_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 128) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 295168</em><br><strong>Layer Number : 8 Layer Name : block3_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 9 Layer Name : block3_conv3</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 10 Layer Name : block3_conv4 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 11 Layer Name : block3_pool Layer </strong><em>Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 256) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 12 Layer Name : block4_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 1180160</em><br><strong>Layer Number : 13 Layer Name : block4_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 14 Layer Name : block4_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 15 Layer Name : block4_conv4</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 16 Layer Name : block4_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 17 Layer Name : block5_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 18 Layer Name : block5_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 19 Layer Name : block5_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 20 Layer Name : block5_conv4 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 21 Layer Name : block5_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0</em></pre><p>Since we are using the VGG-19 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_VGG_19.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong></pre><pre>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the VGG-16 network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has VGG-16 architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_1 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>_________________________________________________________________<br>flatten (Flatten)            (None, 512)               0         <br>_________________________________________________________________<br>dense (Dense)                (None, 1000)              513000    <br>_________________________________________________________________<br>dense_1 (Dense)              (None, 800)               800800    <br>_________________________________________________________________<br>dense_2 (Dense)              (None, 400)               320400    <br>_________________________________________________________________<br>dense_3 (Dense)              (None, 200)               80200     <br>_________________________________________________________________<br>dense_4 (Dense)              (None, 100)               20100     <br>_________________________________________________________________<br>dense_5 (Dense)              (None, 10)                1010      <br>=================================================================<br>Total params: 21,759,894<br>Trainable params: 21,759,894<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets.</p><p><strong>Note:</strong> In this section we have set the parameter of the VGG-19 to false i.e. the loss will not backward propagated throught these layers where as the fully connevted layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h4><strong>2.4. Using VGG as weight initialisers</strong></h4><p>In this section we will use vgg network as a initialiser. In VGG architechture the model is trained on the ImageNet dataset and has acquired so we will instaniate VGG archtechture with VGG layer weights and set it to trainable i.e. the loss will be backward propagated along with that we will add our custom fully classifying layer will will also be trainable. So in short we are using weights of the VGG architechture to initialize our model and train the whole neural network from scratch.</p><p><strong>2.4.1. Dataset</strong></p><p>For feature extraction we will use CIFAR-10 dataset composed of 60K images, 50K for trainning and 10K for testing/evaluation.</p><pre>(trainX, trainy), (testX, testy) = tf.keras.datasets.cifar10.load_data()     <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet used to import the datasets into separate variable and labels.</p><pre>from matplotlib import pyplot   <strong>#Line 2</strong></pre><pre>print(&#39;Train: X=%s, y=%s&#39; % (trainX.shape, trainy.shape)) <strong>#Line 3</strong></pre><pre>print(&#39;Test: X=%s, y=%s&#39; % (testX.shape, testy.shape))  <strong>#Line 4</strong></pre><pre>for i in range(9):  <strong>#Line 5</strong></pre><pre># define subplot</pre><pre>pyplot.subplot(330 + 1 + i)  <strong>#Line 6</strong></pre><pre># plot raw pixel data</pre><pre>pyplot.imshow(trainX[i], cmap=pyplot.get_cmap(&#39;gray&#39;))  <strong>#Line 7</strong></pre><pre># show the figure</pre><pre>pyplot.show()  <strong>#Line 8</strong></pre><p><strong>Line 2: </strong>This code snippet is used to import the Matplot library for plotting.</p><p><strong>Line 3 and Line 4: </strong>This code snippet is used to display the training and testing dataset size as shown below:</p><pre>Train: X=(50000, 32, 32, 3), y=(50000, 1)<br>Test: X=(10000, 32, 32, 3), y=(10000, 1)</pre><p><strong>Line 5 to Line 8: These code snippets are used to display the samples from the datasets as shown below:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/334/1*mcTDWRmqLbWRHbou7oSvaw.png" /><figcaption>Figure 2. Sample CIFDAR-10 dataset</figcaption></figure><p>If you want to have the insight of the visualization library please follow the below mention article series:</p><p><a href="https://medium.datadriveninvestor.com/visualisation-libraries-conclusion-e3deae98a807">Visualisation Libraries — Conclusion</a></p><pre>trainY=tf.keras.utils.to_categorical(trainy, num_classes=10) <strong>#Line 9</strong></pre><pre>testY=tf.keras.utils.to_categorical(testy, num_classes=10)  <strong>#Line 10</strong></pre><p><strong>Line 9 and Line 10: </strong>Since we have 10 classes and labels are number from 0 to 9 so we have to hot encoded these labels thgis has been done by the help of this snippets.</p><h4><strong>2.3.2. VGG-16 Fine Tunning</strong></h4><p>In this section we will see how we can implement VGG-16 as a architecture in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_16 = tf.keras.applications.VGG16(include_top=False,weights=None,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_16.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-16 with noweight by specifying<em>weights=None,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-16 model which will be used to extract feature from the image shown below.</p><pre>Model: &quot;vgg16&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_2 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 14,714,688<br>Trainable params: 14,714,688<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will activate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel_VGG_16.layers):  <strong>#Line 5</strong></pre><pre>layer.trainable=True                           <strong>#Line 6</strong></pre><pre>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=True</em>.</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre><strong>Layer Number : 0</strong><strong>Layer Name : input_1 Layer </strong><br><em>Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 1 Layer Name : block1_conv</strong>1<br>L<em>ayer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 1792</em><br><strong>Layer Number : 2</strong><strong>Layer Name : block1_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 36928</em><br><strong>Layer Number : 3</strong><strong>Layer Name : block1_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 4 Layer Name : block2_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 73856</em><br><strong>Layer Number : 5</strong><strong>Layer Name : block2_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 147584</em><br><strong>Layer Number : 6</strong><strong>Layer Name : block2_pool <br></strong><em>Layer</em><strong><em> </em></strong><em>Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 8, 8, 128) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 7 Layer Name : block3_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 128) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 295168</em><br><strong>Layer Number : 8 Layer Name : block3_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 9</strong><strong>Layer Name : block3_conv3</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 10 Layer Name : block3_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 256) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 11</strong><strong>Layer Name : block4_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 1180160</em><br><strong>Layer Number : 12 Layer Name : block4_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 13 Layer Name : block4_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 14 Layer Name : block4_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 15 Layer Name : block5_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 16 Layer Name : block5_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 17 Layer Name : block5_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 18 Layer Name : block5_pool <br></strong><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0</em></pre><p>Since we are using the VGG-16 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_VGG_19.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong></pre><pre>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the VGG-16 network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has VGG-16 architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model_9&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_13 (InputLayer)        [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>_________________________________________________________________<br>flatten_6 (Flatten)          (None, 512)               0         <br>_________________________________________________________________<br>dense_36 (Dense)             (None, 1000)              513000    <br>_________________________________________________________________<br>dense_37 (Dense)             (None, 800)               800800    <br>_________________________________________________________________<br>dense_38 (Dense)             (None, 400)               320400    <br>_________________________________________________________________<br>dense_39 (Dense)             (None, 200)               80200     <br>_________________________________________________________________<br>dense_40 (Dense)             (None, 100)               20100     <br>_________________________________________________________________<br>dense_41 (Dense)             (None, 10)                1010      <br>=================================================================<br>Total params: 16,450,198<br>Trainable params: 16,450,198<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets</p><p><strong>Note:</strong> In this section we have set the parameter of the VGG-16 to true i.e. the loss will bebackward propagated throught these layers where as the fully connected layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><h4><strong>2.3.3 VGG-19 Fine Tunning Fully connected layers</strong></h4><p>In this section we will see how we can implement VGG-19as a Feature extractor in Keras:</p><pre>import tensorflow as tf  <strong>#Line 1</strong></pre><p><strong>Line 1:</strong> The above snippet is used to import the TensorFlow library which we use use to implement Keras.</p><pre>image_input = tf.keras.layers.Input(shape=(32,32, 3)) <strong> #Line 2</strong></pre><pre>baseModel_VGG_19 = tf.keras.applications.VGG19(include_top=False,weights=’imagenet’,input_tensor=image_input)     <strong>#Line 3</strong></pre><pre>baseModel_VGG_19.summary()  <strong>#Line 4</strong></pre><p><strong>Line 2 :</strong> We have specified out datasets to be of shape (32,32,3) i.e. in channel last format where channel number is 3, Height and Width of the Images are 32 respectively.</p><p><strong>Line 3:</strong> We have imported the pre-trained VGG-19 with ImageNet weight by specifying<em>weights=’imagenet’,</em> we have excluded the Dense layer by<em>include_top=False</em> since we have to get the features from the image though there is option available to us where we can use dense layer ti get 1d- feature tensor from this model. also we have used Line 2 in Line 3 to specify the input shape of the model by<em>input_tensor=image_input</em>.</p><p><strong>Line 4: </strong>This snippet is used to display the Summary of the VGG-19 model which will be used to extract featur from the image shown below.</p><pre>Model: &quot;vgg19&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_3 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>=================================================================<br>Total params: 20,024,384<br>Trainable params: 20,024,384<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Since we have loaded the model in our environment with our configuration of the layers its time to set the training parameters of each of the layer to non-trainable. This step will activate the backward propagating strep in the mentioned model as a a result we will extract the features based on the model which was trained on the ImageNet dataset. The code if mentioned below:</p><pre>for i,layer in enumerate(baseModel_VGG_19.layers):  <strong>#Line 5</strong></pre><pre>layer.trainable=True                           <strong>#Line 6</strong></pre><pre>print(“Layer Number :”,i, “Layer Name :”, layer.name, “Layer     <br>    Shape(Input_Shape,Output Shape) : (“,layer.input_shape, <br>    layer.output_shape, “) is Trainable:”, layer.trainable,”No of <br>    Parameter :”,layer.count_params())              <strong>#Line 7</strong></pre><p><strong>Line 5: </strong>This snippet allows us to iterate through the model layer using for loop.</p><p><strong>Line 6: </strong>This snippets is used to set the trainable parameter of each layer to False by<em>layer.trainable=True</em> .</p><p><strong>Line 7:</strong> This snippets prints the layer information as shown below.</p><pre><strong>Layer Number : 0 Layer Name : input_3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( [(None, 32, 32, 3)] [(None, 32, 32, 3)] ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 1 Layer Name : block1_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 3) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 1792</em><br><strong>Layer Number : 2 Layer Name : block1_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 32, 32, 64) ) is Trainable: False No of Parameter : 36928</em><br><strong>Layer Number : 3 Layer Name : block1_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 32, 32, 64) (None, 16, 16, 64) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 4 Layer Name : block2_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 64) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 73856</em><br><strong>Layer Number : 5 Layer Name : block2_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 16, 16, 128) ) is Trainable: False No of Parameter : 147584</em><br><strong>Layer Number : 6 Layer Name : block2_pool</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 16, 16, 128) (None, 8, 8, 128) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 7 Layer Name : block3_conv1</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 128) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 295168</em><br><strong>Layer Number : 8 Layer Name : block3_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 9 Layer Name : block3_conv3</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 10 Layer Name : block3_conv4 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 8, 8, 256) ) is Trainable: False No of Parameter : 590080</em><br><strong>Layer Number : 11 Layer Name : block3_pool Layer </strong><em>Shape(Input_Shape,Output Shape) : ( (None, 8, 8, 256) (None, 4, 4, 256) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 12 Layer Name : block4_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 256) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 1180160</em><br><strong>Layer Number : 13 Layer Name : block4_conv2</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 14 Layer Name : block4_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 15 Layer Name : block4_conv4</strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 4, 4, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 16 Layer Name : block4_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 4, 4, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 0</em><br><strong>Layer Number : 17 Layer Name : block5_conv1 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 18 Layer Name : block5_conv2 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 19 Layer Name : block5_conv3 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 20 Layer Name : block5_conv4 </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 2, 2, 512) ) is Trainable: False No of Parameter : 2359808</em><br><strong>Layer Number : 21 Layer Name : block5_pool </strong><br><em>Layer Shape(Input_Shape,Output Shape) : ( (None, 2, 2, 512) (None, 1, 1, 512) ) is Trainable: False No of Parameter : 0</em></pre><p>Since we are using the VGG-19 as a architechture with our custom dastaset so we have to add our custom dense layer so that we can classify the objects from the datasets objects the snippet is mentioned below:</p><pre>FC_layer_Flatten = tf.keras.layers.Flatten()(baseModel_VGG_19.output)        <strong>#Line 5</strong></pre><pre>Dense=tf.keras.layers.Dense(units=1000,activation=”relu”)(FC_layer_Flatten)    <strong>#Line 6</strong></pre><pre>Dense=tf.keras.layers.Dense(units=800,activation=”relu”)(Dense)<strong>#Line 7</strong></pre><pre>Dense=tf.keras.layers.Dense(units=400,activation=”relu”)(Dense)<strong>#Line 8</strong></pre><pre>Dense=tf.keras.layers.Dense(units=200,activation=”relu”)(Dense) <strong>#Line 9</strong></pre><pre>Dense=tf.keras.layers.Dense(units=100,activation=”relu”)(Dense)<strong>#Line 10</strong></pre><pre>Classification=tf.keras.layers.Dense(units=10,activation=”softmax”)(Dense) <strong>#Line 11</strong></pre><p><strong>Line 5: </strong>This line is used to flatten the layer of the VGG-16 network, already we have output as a form of 1d-tensor, then also i have flatten it for demonstration purpose , which will feed into further layer.</p><p><strong>Line 6 to Line 10:</strong> These followoing mentioned line are artificial neural network with relu activation.</p><p><strong>Line 11:</strong> The line has 10 neurons with Softmax activation fuction which allow us to predict the probabolities of each classes đrom the neural network.</p><pre>model_final = tf.keras.Model(inputs=image_input,outputs=Classification) <strong>#Line 12</strong></pre><pre>model_final.summary()    <strong>#Line 13</strong></pre><p><strong>Line 12:</strong> This line is used to create the custom model which has VGG-16 architechture as well as our custom fully classification layer. We have specified our input layer as<em>image_input </em>and<em> </em>output layer as<em>Classification </em>so that the model is aware of the input and output layer to do further calculations.</p><p><strong>Line 13</strong>: This snippets shows the full summary of the model which is shown below:</p><pre>Model: &quot;model&quot;<br>_________________________________________________________________<br>Layer (type)                 Output Shape              Param #   <br>=================================================================<br>input_1 (InputLayer)         [(None, 32, 32, 3)]       0         <br>_________________________________________________________________<br>block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      <br>_________________________________________________________________<br>block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     <br>_________________________________________________________________<br>block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         <br>_________________________________________________________________<br>block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     <br>_________________________________________________________________<br>block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    <br>_________________________________________________________________<br>block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         <br>_________________________________________________________________<br>block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    <br>_________________________________________________________________<br>block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    <br>_________________________________________________________________<br>block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         <br>_________________________________________________________________<br>block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   <br>_________________________________________________________________<br>block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   <br>_________________________________________________________________<br>block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         <br>_________________________________________________________________<br>block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   <br>_________________________________________________________________<br>block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         <br>_________________________________________________________________<br>flatten (Flatten)            (None, 512)               0         <br>_________________________________________________________________<br>dense (Dense)                (None, 1000)              513000    <br>_________________________________________________________________<br>dense_1 (Dense)              (None, 800)               800800    <br>_________________________________________________________________<br>dense_2 (Dense)              (None, 400)               320400    <br>_________________________________________________________________<br>dense_3 (Dense)              (None, 200)               80200     <br>_________________________________________________________________<br>dense_4 (Dense)              (None, 100)               20100     <br>_________________________________________________________________<br>dense_5 (Dense)              (None, 10)                1010      <br>=================================================================<br>Total params: 21,759,894<br>Trainable params: 21,759,894<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p>Now we have to compile the model which is shown below:</p><pre>base_learning_rate = 0.0001  <strong>#Line 13</strong></pre><pre>model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[&#39;accuracy&#39;])  <strong>#Line 14</strong></pre><p><strong>Line 13</strong>: We have set the learning rate for the optimiser i.e. 0.0001</p><p><strong>Line 14</strong>: In this snippet we have selected our desired parameters such as accuracy, Optimiser : ADam, Loss: CategoricalCrossentrophy.</p><p>Finally we can treain and predict the model by using the following sbippets:</p><pre>history = model_final.fit(trainX,trainY,epochs=10,batch_size=32,validation_data=(testX, testY))     <strong>#Line 15</strong></pre><pre>prediction=model_final.predict(testX) <strong>#Line 16</strong></pre><p><strong>Line 15</strong>: This snippet is used to train the model on train datasets.</p><p><strong>Line 16</strong>: This snippet is used to predict from the model on test datasets.</p><p><strong>Note:</strong> In this section we have set the parameter of the VGG-19 to false i.e. the loss will not backward propagated throught these layers where as the fully connected layer are custom defined by us the loss will be backward propagated throught fully connected layer.</p><p><em>Colab file of each part will be added in the conclusion part of this series</em>. this article we have discussed about the pre-trained VGG-16and VGG-19 models with implementation in Keras. In next article we will discuss VGG-16 and VGG-19 model implementation with Pytorch. Stay Tuned!!!!</p><p><em>Need help ??? Consult with me on DDI :)</em></p><p><a href="https://app.ddichat.com/experts/ravi-shekhar-tiwari/">Ravi Shekhar TIwari - DDIChat</a></p><h3>Special Thanks:</h3><blockquote><em>As we say “</em><strong><em>Car is useless if it doesn’t have a good engine</em></strong><em>” similarly student is useless without proper guidance and motivation. I will like to thank my Guru as well as my Idol “</em><strong><em>Dr. P. Supraja” and “A. Helen Victoria”- guided me throughout the journey, from the bottom of my heart</em></strong><em>. As a Guru, she has lighted the best available path for me, motivated me whenever I encountered failure or roadblock- without her support and motivation this was an impossible task for me.</em></blockquote><h3>References</h3><blockquote>Pytorch: <a href="https://pytorch.org/get-started/locally/#windows-python">Link</a></blockquote><blockquote>Keras: <a href="https://keras.io/">Link</a></blockquote><blockquote>Tensorflow: <a href="https://www.tensorflow.org/guide/keras/sequential_model">Link</a></blockquote><blockquote>VGG Paper: <a href="https://arxiv.org/abs/1409.1556">Link</a></blockquote><blockquote><em>Imagenet Dataset: </em><a href="https://www.image-net.org/"><em>Link</em></a></blockquote><blockquote><em>ILSVRC : </em><a href="https://www.image-net.org/challenges/LSVRC/index.php"><em>Link</em></a></blockquote><p><em>if you have any query feel free to contact me with any of the -below mentioned options:</em></p><blockquote>YouTube : <a href="https://www.youtube.com/channel/UCFG5x-VHtutn3zQzWBkXyFQ">Lin</a>k</blockquote><blockquote>Website: <a href="http://www.rstiwari.com/">www.rstiwari.com</a></blockquote><blockquote>Medium: <a href="https://tiwari11-rst.medium.com/">https://tiwari11-rst.medium.com</a></blockquote><blockquote>Github Pages: <a href="https://happyman11.github.io/">https://happyman11.github.io/</a></blockquote><blockquote><em>Articles: </em><a href="https://laptrinhx.com/author/ravi-shekhar-tiwari/"><em>https://laptrinhx.com/author/ravi-shekhar-tiwari/</em></a></blockquote><blockquote>Google Form: <a href="https://forms.gle/mhDYQKQJKtAKP78V7">https://forms.gle/mhDYQKQJKtAKP78V7</a></blockquote><h3>Don’t forget to give us your 👏 !</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/0*2lvCls4yjxVMfZSR" /></figure><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fupscri.be%2F8f5f8b%3Fas_embed%3Dtrue&amp;dntp=1&amp;url=https%3A%2F%2Fupscri.be%2F8f5f8b&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=upscri" width="800" height="400" frameborder="0" scrolling="no"><a href="https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href">https://medium.com/media/c43026df6fee7cdb1aab8aaf916125ea/href</a></iframe><figure><a href="https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*2f7OqE2AJK1KSrhkmD9ZMw.png" /></a></figure><figure><a href="https://upscri.be/8f5f8b"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*v-PpfkSWHbvlWWamSVHHWg.png" /></a></figure><figure><a href="https://becominghuman.ai/write-for-us-48270209de63"><img alt="" src="https://cdn-images-1.medium.com/max/255/1*Wt2auqISiEAOZxJ-I7brDQ.png" /></a></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=227278e65869" width="1" height="1" alt=""><hr><p><a href="https://becominghuman.ai/transfer-learning-part-4-1-implementing-vgg-16-and-vgg-19-in-keras-227278e65869">Transfer Learning — Part — 4.1!! Implementing VGG-16 and VGG-19 in Keras</a> was originally published in<a href="https://becominghuman.ai">Becoming Human: Artificial Intelligence Magazine</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]>
</content:encoded>
</item>
</channel>
</rss>